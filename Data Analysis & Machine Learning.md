# フレームワーク
## TensorFlow
- 開発：Google
- 開発年：2015年
- 規模が大きいもの向き
- コミュニティが大きい
- 習得に時間かかる

## PyTorch
- 開発：Meta
- 開発年：2016年
- 小規模や研究向き
- コミュニティが大きい
- GPU上
- 人気急上昇でTensorFlowを追い抜かすかも
- 習得に時間かかる

## Keras
- 初心者向き
- 構文が分かりやすい
- ディープラーニングモデルを構築するための高レベルAPI
- 通常、TensorFlow等の低レベルライブラリ上で動作する（まず、TensorFlowのインストールが必要）
### Keras詳細
- Keras ライブラリを使用する前に、データを準備し、正しい形式で整理する必要があります。
- Keras では、わずか数行のコードでニューラル ネットワークを構築およびトレーニングできます。  
- データ セットは予測子とターゲットに分けられます。  
- Keras を使用して分類問題を解決する場合は、ターゲット列をバイナリ値を持つ配列に変換する必要があります。
- Keras ユーティリティ パッケージの 'to_categorical' 関数を使用して、データ セットの列をバイナリ値の配列に変換できます。  
- Keras コードを使用して分類モデルを構築できます。  

# データ探索（EDA）
## データベース・クエリ
- 元になるデータベースとクエリのデータは、別で並べて分析する事。
    - 特徴が異なる事がある
- ラベル毎の特徴を確認する。
    - 例：向きが、右と右上で画像に違いが見られない場合、ラベルを統合するか検討
    - 例：データの欠損と別で「不明」と項目が存在する場合、データの中身を確認して統合したり・再ラベリングを検討

# データの前処理
## 欠損値補完

# 活性化関数
ReLU 関数は
Play video starting at :5: and follow transcript5:00
、 今日のネットワーク設計で最も広く使用されている活性化関数であり、その主な利点は、 すべてのニューロンを同時に活性化しないことです。 softmax 関数は、
Play video starting at :5:11 and follow transcript5:11
各入力のクラスを定義する確率を取得しようとしていた分類器の出力層で使用するのが理想的です。 シグモイド関数と双曲線正接関数は、
Play video starting at :5:18 and follow transcript5:18
勾配が消失する問題につながる可能性があるため、多くの用途で使われていません。 モデルを構築するときは、 まず ReLU 関数を使用し、ReLU
Play video starting at :5:27 and follow transcript5:27
関数のパフォーマンスが良くない場合は、他のアクティベーション関数に切り替えることができます。（courasera IBM)

# データ拡張
## [TensorFlowを使った画像の水増しレシピまとめ](https://gcbgarden.com/2018/02/20/data-augmentation-tf/)
## 注意点
- 何でも使用して良い訳ではなく、データの性質を考えて、どの方法で水増しするかを選択する
    - 例:反転系、意味変わるものも
    - 例:上下反転や回転し過ぎて、地面の概念消えたり。
- 上記と矛盾するが、明らか変だろうと思う事で精度が上がる事もあるらしい。
- 元のデータセットが種類により数に偏りが存在するならば、少ない種類をより水増しするように調整が必要
- 反転系は、他の列ラベルに注意する
    - 例:右手・左手が変わる事で意味が変わる。
    - 例:明確に向きラベルが存在するならば、その意味も反転させる必要がある
- 数値をランダムにするか、一律にするかも検討

# 後で編集
　また、適切な評価方法を設計することも非常に重要です。評価方法の設計で考えるべきことはタスクの内容に強く依存するため、ここではより狭い範囲の具体的なTipsを、3つ目の交差検証（CV）スコアを高めることに絡めてご紹介します。
　信頼性の低いCVスコアを頼りに改善を続けていくと、手元の検証データへの過学習が強くなりすぎてしまいます。これは、ゴールの方向を間違えたまま努力し続けるようなものです。CVの信頼性が下がる要素を取り除くためには、実験でEpoch数を決めたあとにEarly stoppingを使わないことをお勧めします。反対に、CVスコアの信頼性が上がる要素を取り入れる場合には、複数の分割方法でフォールドを作成し、交差検証をするRepeated K-Fold交差検証を使うとよいでしょう。

画像系
補足：解像度について【対象が小さい場合】
解像度は性能に与える影響がまぁまぁ大きく、初心者にとっては最初に意識すべきところではないでしょうか。いつもやるとはいえ、問題に合わせて変えていくところでもあります。個人的な思いとして、怪しいAI系業者は解像度の気持ちがわかっていません。
たとえば画像全体からめちゃくちゃ小さいものを見つけたいときは、むやみに解像度を落とせません。(例：下図からボールを見つけたい)しかし一方で、限られた時間でコンペをやるためには実験効率も重要ですので、序盤から過度に高い解像度は避けたいところです。また、限られた推論時間で実行するコードコンペでは、実行速度もある程度意識したいところです。
たとえばこの例であれば、モノが小さいしコンテクストはそれほど重要ではなさそうなので浅いモデルでさばこうかな、という選択肢がでてきます。こういったトレードオフを意識しつつ戦略を練るのもコンペの醍醐味の一つですね！
補足：解像度について【対象が大きい場合】
逆に対象物が大きい時には画像全体を見渡せるような解像度とモデルが必要になると思います。たとえば、1024x1024のような大きい入力画像を軽量な浅いモデルで処理する場合は、本当に画像全体が見えているのかどうかが考えどころです。解像度をさげるか、モデルを大きくする選択肢を持ちたいところです。
有名なEfficientNet論文でもそのあたりの重要性が主張されました。EfficientNetってもう5年前(2019)なんですね

ドメインを考える例
以下のようなものがあると思います。
特徴量エンジニアリング (←本ページで紹介)
タスク特化のLoss
タスク特化のAugmentation選定や作成
タスク特化のモデルアーキテクチャ
タスク特化のパイプライン
難易度も効果もピンキリですが、順番に紹介していきます。


NNへの優しい特徴量の与え方の例
デプス画像(奥行きを示す画像)一枚でも相当な量の情報があります。これをいちいち深層学習モデルに見つけさせるのは大変なので、重要なものは積極的に入れていくことも検討します。
■　モデルは知らないが、自分は知っていること　⇒　積極的に与える
奥行き0は数値ではなく、正しく数値が取れなかった欠損部分である
奥行き情報とカメラ幾何をうまく活用することで、xyzの三次元表現も可能である
xyzの変化から、モノの向きに関する情報(法線方向など)を抽出できる
■　モデルにとってわかりにくい部分　⇒　優しく加工する
奥行きの広い数値レンジの扱い方。1mと2mの差よりも、0.1mと0.2mの違いの方が重要なケースがある
カラー画像とデプス画像のどちらが重要か
あくまで一例ですが、いろんな工夫をもってNNに召し上がっていただきます。
明示的に与えられていない情報の追加
たとえば画像系のコンペにおいては、画像中の座標位置が明確に意味を持つこともあります。例えば『人は地面を歩く』なども重要な事前知識で、画像における座標系を追加特徴にすることもアリです。Coord Conv, Positional encodingなどに相当するかと思います。車載画像の検出などにpaddingからの位置情報を活用していると話題になったことがありますが、積極的に狙うのであれば、位置情報を入力に加えてもいいです。
画像をクロップすると注視点が変わる(明示的に画像座標を与えなくても、座標情報をつかっている)という話は有名ですね。

■　NNは数値スケールに敏感
連続値であっても、歪な分布や極端な数値が混ざると学習しにくいことはよく知られています。また、0-1分布などにうまく調整したとしても、『0が欠損データで、0.001とは全く意味が違う』などがあればfloat(X==0)ぐらいのマスクを追加特徴にしてもいいと思います。その微小値をNNに見つけてもらうのは大変です。(決定木なら余裕ですが)
■　NNは特徴量の数や強さに敏感
センサ値Aから作った特徴量が50個、センサ値Bから作った特徴量が2個で52chつくると、A系特徴量からの学習の方が進みやすくなります。B系特徴量にすごく自信があってどうしても見てほしい、というときは最初のレイヤで調整することもできます。

物理現象を意識させるLossについて
たとえば、RGB画像から奥行きを予測するタスクではDepth Smoothness Lossと呼ばれるLossがよく活用されていました。これは、『奥行きの変化が起きるのは色味の変化が大きいところ』だという常識をモデルに意識させるためのLossです。入力したRGB画像と予測した奥行き画像との画素間の変化量を用いて、RGBの変化量が少ない箇所での奥行き変化に対して軽いペナルティを与えます。
このように、通常の学習と合わせて制約を与えることで、意図した方向に学習を進めることができます。

サブタスクとしてのLossについて
test dataでは与えられていないけど、train dataには与えられている情報がある場合にはサブタスクを解かせるチャンスです。分類や回帰などの本来解きたいタスクと並列に、そのドメインにとって重要な情報をサブタスク的に学習させることで、メインのタスクに対するパフォーマンスを高めることもできます。
■　ラベルに含まれない追加情報は積極的に活用する 
kaggleでおこなわれたクジラの識別コンペでは、個体識別IDとともに、species(種族)が与えられていました。コンペの目的は個体分類ですので、種族を分類すること自体は求められていませんが、これをサブタスクとして解かせることで精度を上げたチームが多かったようです。(優勝者チームのcharm先生も、補助ロスはやって損なしとおっしゃっていました)

■　ラベルよりリッチな情報は積極的に活用する 
珍しいですが、『セグメンテーションラベルが与えられているが評価対象は分類問題』という例もあります。たとえば、先日のRSNA2024では、医療画像における注視箇所が画像座標で与えられていましたが、予測対象は症状の深刻度でした。
単純な分類ラベルと比べると、位置ラベルは非常に大きな情報源で、十中八九は役に立ちます！『この画像は犬、この画像は猫』と言われるより、『この画像のこの部分が犬、こちらはこの部分が猫』と言われるほうがNNとしても学習が容易なことは想像できると思います。
本コンペでは検出～分類の2stageが強かったのですが、タスクによっては補助ロス的な形も十分に考えられます。
逆に、ラベルよりも情報が少ないタスクを解かせても補助ロスは効きにくいことも多いです。極端な例ですが、犬の画像のセグメンテーションをするときに、画像に犬が含まれるかどうかのサブタスクを解いてもそれほど効果はありません。

search
記事、質問を検索
ログイン新規登録
トレンド
質問
公式イベント
公式コラムopen_in_new
Organization
エンジニアとしての市場価値を測りませんか？PR
無料でForkwellに登録するopen_in_new
また後で
Kaggle
Advent Calendar 2024
@Kmat67916008
Kaggle画像コンペでやっていること③
機械学習
ニューラルネットワーク
Kaggle
最終更新日 2024年12月24日投稿日 2024年12月21日
前々回の記事『Kaggle画像コンペでやっていること①』では、どんなコンペでも大体やることをあげさせていただき、前回の記事『Kaggle画像コンペでやっていること②』ではドメインを考える最初のステップとして特徴量エンジニアリングの話をしました。
kaggle advent calender 2024の21日目の記事は、画像コンペで適用ドメインを考えてLossやAugmentationするお話になります。数回にわけて書かせていただいており、基本的に初級者(Expertぐらい)向けですのでご了承ください。8日目：Kaggle画像コンペでやっていること① (タスク関係なくやること)14日目：Kaggle画像コンペでやっていること② (特徴量まわり)21日目：本記事24日目：Kaggle画像コンペでやっていること④
前回記事の振り返り 
深層学習で解こうとしているタスク固有の特徴を考えたい
自分にとってのあたりまえも、深層学習モデルにとってのあたりまえではない
うまく効かせると精度があがるしカッコいい
いろんな活かし方がある
特徴量エンジニアリング【済】
タスク特化のLoss (←本ページで紹介)
タスク特化のAugmentation選定や作成 (←本ページで紹介)
タスク特化のモデルアーキテクチャ
タスク特化のパイプライン
ドメイン意識②：Lossを工夫する
カスタムAugmentation・カスタムLossは脱NN初心者のはじめの一歩だと思います。そのコンペのタスクだからこそのルールや縛りなんかを入れられると、グッと学習が進むこともあります。
物理現象を意識させるLossについて
たとえば、RGB画像から奥行きを予測するタスクではDepth Smoothness Lossと呼ばれるLossがよく活用されていました。これは、『奥行きの変化が起きるのは色味の変化が大きいところ』だという常識をモデルに意識させるためのLossです。入力したRGB画像と予測した奥行き画像との画素間の変化量を用いて、RGBの変化量が少ない箇所での奥行き変化に対して軽いペナルティを与えます。
このように、通常の学習と合わせて制約を与えることで、意図した方向に学習を進めることができます。
 
別の例としては、先日のKaggle LEAPコンペでは、少し未来の気象(風速や湿度、気温など)を求めるコンペでした。このようなケースでは現在と未来の間での保存則が成立することが多いです。
地球への流入する熱量と流出する熱量の差分は、地球のどこかに蓄えられているので、それらをLossとして定義することができます。たとえばloss = (流入 - 流出 - 地球蓄え)**2のようにペナルティを与えられます
水分量も維持されます。地面に含まれる水が蒸発し、大気や雲に含まれ、降雨して…という循環に含まれる水分量を一定に保つようなlossを定義できます
まぁ、LEAPコンペでは地理情報は使用不可だったこともあり保存則を定義しにくく、使えないアプローチでした
サブタスクとしてのLossについて
test dataでは与えられていないけど、train dataには与えられている情報がある場合にはサブタスクを解かせるチャンスです。分類や回帰などの本来解きたいタスクと並列に、そのドメインにとって重要な情報をサブタスク的に学習させることで、メインのタスクに対するパフォーマンスを高めることもできます。
■　ラベルに含まれない追加情報は積極的に活用する 
kaggleでおこなわれたクジラの識別コンペでは、個体識別IDとともに、species(種族)が与えられていました。コンペの目的は個体分類ですので、種族を分類すること自体は求められていませんが、これをサブタスクとして解かせることで精度を上げたチームが多かったようです。(優勝者チームのcharm先生も、補助ロスはやって損なしとおっしゃっていました)
参照
また、チューリッヒ工科大の論文(CoRL2024)では、扉を開けるタスクの学習において、ロボットの動きとは直接関係のない扉に関する情報を予測させ、それに対してEstimation Lossとして学習させています。この補助的なロスによって結果的にロボットの行動に関わる精度も向上したことが示されています。
扉によっては軽い扉や重い扉、引く扉や押す扉、閉まる方向に荷重がかかるタイプの扉など色々な扉があるので、どのような扉かを予測することが扉開閉の動きを作るうえでの助けになることは想像がつきます。直接最終的な予測をすることが難しいようなタスクで、その判断の助けになるようなものを補助的に学習するときは効きやすいですね。
■　ラベルよりリッチな情報は積極的に活用する 
珍しいですが、『セグメンテーションラベルが与えられているが評価対象は分類問題』という例もあります。たとえば、先日のRSNA2024では、医療画像における注視箇所が画像座標で与えられていましたが、予測対象は症状の深刻度でした。
単純な分類ラベルと比べると、位置ラベルは非常に大きな情報源で、十中八九は役に立ちます！『この画像は犬、この画像は猫』と言われるより、『この画像のこの部分が犬、こちらはこの部分が猫』と言われるほうがNNとしても学習が容易なことは想像できると思います。
本コンペでは検出～分類の2stageが強かったのですが、タスクによっては補助ロス的な形も十分に考えられます。
逆に、ラベルよりも情報が少ないタスクを解かせても補助ロスは効きにくいことも多いです。極端な例ですが、犬の画像のセグメンテーションをするときに、画像に犬が含まれるかどうかのサブタスクを解いてもそれほど効果はありません。
■　ラベルからサブタスクを作ってもいい 
先日の第18回atmaCupでは自車の未来の位置推定問題でしたが、位置だけでなく速度や加速度をサブタスクで学習する人がいました。たしかに、『青信号なら加速』『前に車両がいる場合には避ける』など、速度や加速度を用いることで学習しやすくなる要素がありそうなことが想像できます。
ラベルが位置情報だとしても、それを微分して速度をサブタスクとして学習できる例でした
補助ロスの注意点：残念ながら足を引っ張ることもある
補助ロスのせいでメインタスクの性能が悪化するときもあります。とくにサブタスクのターゲット値が極端に大きかったりすると、メインタスクの学習に悪影響を及ぼすこともあります。
そんなときは…
loss weightを調整するのは手っ取り早いです。補助ロスweightを弱くしても効かないなら他の方法をとってもいいと思います
チャンネル数を増やすなんかも手っ取り早いことがあります
下図のようにサブタスクとメインタスクを遠ざけるのもあると思います。検出器などでもよくありますが、予測対象の特性が異なる場合はブランチを切った方がうまくいきます。
難易度はあがりますが、Lossではなくモデル側の出力として制約をかける方がいいケースは多いです
たとえばx, y, zの3つの予測をするときに互い相関関係を持っている場合、別のv, wの予測問題に置き換えてそこからx, y, zをもとめるようにする
たとえば、x**2 + y**2 < 1のようにxとyの数値レンジが決まっているなら、rとΘの予測問題におきかえて、rをsigmoidみたいなので予測してもいいですね
手前みそですが、Kaggle睡眠コンペでは１日１回以下の入眠＆起床というルールを如何に反映するかという際に、Lossではなくtargetの工夫によって学習したことがあります。ここ最近で一番冴えていたのに2nd placeで悔しかったです
まぁ無理な時は諦めます。「あった方が良いと思うんだけどなぁ」と呟きながら泣く泣く諦めます
Lossの距離感や強弱は難しいですね。モデルへの反映まで考えるとかなり難しく様々なアプローチがあります。

Augmentation
今解こうとしている問題に対して、「このAugmentationって使っていいのか？」と考えることが最初の一歩ではないでしょうか。
■ Augmentaitonによって別ラベルになってしまうケース
たとえば以下の画像から次のアクションを予測するとします。まぁ見ての通りコップをとります。笑
これを学習時にFlip Augmentationで左右反転すると右手が左手になってしまいます。右利きの人の方が多いのでtestに対する予測精度は悪化してしまう可能性があります。であればFlip Augmentationはやめとこうかなと判断できます。
入れるべきAugmentationというのは、どんなコンペでも一回は考えていると思います。先日のRSNA2024の場合は、人の体に対して左右それぞれのラベルを別々に予測させるような問題でした。この場合は画像を左右反転するときにラベルも左右反転しておけばなんとかなりそうに感じますね。
トレンド
質問
公式イベント
公式コラムopen_in_new
Organization
エンジニアとしての市場価値を測りませんか？PR
無料でForkwellに登録するopen_in_new
また後で
Kaggle
Advent Calendar 2024
@Kmat67916008
Kaggle画像コンペでやっていること③
機械学習
ニューラルネットワーク
Kaggle
最終更新日 2024年12月24日投稿日 2024年12月21日
前々回の記事『Kaggle画像コンペでやっていること①』では、どんなコンペでも大体やることをあげさせていただき、前回の記事『Kaggle画像コンペでやっていること②』ではドメインを考える最初のステップとして特徴量エンジニアリングの話をしました。
kaggle advent calender 2024の21日目の記事は、画像コンペで適用ドメインを考えてLossやAugmentationするお話になります。数回にわけて書かせていただいており、基本的に初級者(Expertぐらい)向けですのでご了承ください。8日目：Kaggle画像コンペでやっていること① (タスク関係なくやること)14日目：Kaggle画像コンペでやっていること② (特徴量まわり)21日目：本記事24日目：Kaggle画像コンペでやっていること④
前回記事の振り返り 
深層学習で解こうとしているタスク固有の特徴を考えたい
自分にとってのあたりまえも、深層学習モデルにとってのあたりまえではない
うまく効かせると精度があがるしカッコいい
いろんな活かし方がある
特徴量エンジニアリング【済】
タスク特化のLoss (←本ページで紹介)
タスク特化のAugmentation選定や作成 (←本ページで紹介)
タスク特化のモデルアーキテクチャ
タスク特化のパイプライン
ドメイン意識②：Lossを工夫する
カスタムAugmentation・カスタムLossは脱NN初心者のはじめの一歩だと思います。そのコンペのタスクだからこそのルールや縛りなんかを入れられると、グッと学習が進むこともあります。
物理現象を意識させるLossについて
たとえば、RGB画像から奥行きを予測するタスクではDepth Smoothness Lossと呼ばれるLossがよく活用されていました。これは、『奥行きの変化が起きるのは色味の変化が大きいところ』だという常識をモデルに意識させるためのLossです。入力したRGB画像と予測した奥行き画像との画素間の変化量を用いて、RGBの変化量が少ない箇所での奥行き変化に対して軽いペナルティを与えます。
このように、通常の学習と合わせて制約を与えることで、意図した方向に学習を進めることができます。
 
別の例としては、先日のKaggle LEAPコンペでは、少し未来の気象(風速や湿度、気温など)を求めるコンペでした。このようなケースでは現在と未来の間での保存則が成立することが多いです。
地球への流入する熱量と流出する熱量の差分は、地球のどこかに蓄えられているので、それらをLossとして定義することができます。たとえばloss = (流入 - 流出 - 地球蓄え)**2のようにペナルティを与えられます
水分量も維持されます。地面に含まれる水が蒸発し、大気や雲に含まれ、降雨して…という循環に含まれる水分量を一定に保つようなlossを定義できます
まぁ、LEAPコンペでは地理情報は使用不可だったこともあり保存則を定義しにくく、使えないアプローチでした
サブタスクとしてのLossについて
test dataでは与えられていないけど、train dataには与えられている情報がある場合にはサブタスクを解かせるチャンスです。分類や回帰などの本来解きたいタスクと並列に、そのドメインにとって重要な情報をサブタスク的に学習させることで、メインのタスクに対するパフォーマンスを高めることもできます。
■　ラベルに含まれない追加情報は積極的に活用する 
kaggleでおこなわれたクジラの識別コンペでは、個体識別IDとともに、species(種族)が与えられていました。コンペの目的は個体分類ですので、種族を分類すること自体は求められていませんが、これをサブタスクとして解かせることで精度を上げたチームが多かったようです。(優勝者チームのcharm先生も、補助ロスはやって損なしとおっしゃっていました)
参照
また、チューリッヒ工科大の論文(CoRL2024)では、扉を開けるタスクの学習において、ロボットの動きとは直接関係のない扉に関する情報を予測させ、それに対してEstimation Lossとして学習させています。この補助的なロスによって結果的にロボットの行動に関わる精度も向上したことが示されています。
扉によっては軽い扉や重い扉、引く扉や押す扉、閉まる方向に荷重がかかるタイプの扉など色々な扉があるので、どのような扉かを予測することが扉開閉の動きを作るうえでの助けになることは想像がつきます。直接最終的な予測をすることが難しいようなタスクで、その判断の助けになるようなものを補助的に学習するときは効きやすいですね。
■　ラベルよりリッチな情報は積極的に活用する 
珍しいですが、『セグメンテーションラベルが与えられているが評価対象は分類問題』という例もあります。たとえば、先日のRSNA2024では、医療画像における注視箇所が画像座標で与えられていましたが、予測対象は症状の深刻度でした。
単純な分類ラベルと比べると、位置ラベルは非常に大きな情報源で、十中八九は役に立ちます！『この画像は犬、この画像は猫』と言われるより、『この画像のこの部分が犬、こちらはこの部分が猫』と言われるほうがNNとしても学習が容易なことは想像できると思います。
本コンペでは検出～分類の2stageが強かったのですが、タスクによっては補助ロス的な形も十分に考えられます。
逆に、ラベルよりも情報が少ないタスクを解かせても補助ロスは効きにくいことも多いです。極端な例ですが、犬の画像のセグメンテーションをするときに、画像に犬が含まれるかどうかのサブタスクを解いてもそれほど効果はありません。
■　ラベルからサブタスクを作ってもいい 
先日の第18回atmaCupでは自車の未来の位置推定問題でしたが、位置だけでなく速度や加速度をサブタスクで学習する人がいました。たしかに、『青信号なら加速』『前に車両がいる場合には避ける』など、速度や加速度を用いることで学習しやすくなる要素がありそうなことが想像できます。
ラベルが位置情報だとしても、それを微分して速度をサブタスクとして学習できる例でした
補助ロスの注意点：残念ながら足を引っ張ることもある
補助ロスのせいでメインタスクの性能が悪化するときもあります。とくにサブタスクのターゲット値が極端に大きかったりすると、メインタスクの学習に悪影響を及ぼすこともあります。
そんなときは…
loss weightを調整するのは手っ取り早いです。補助ロスweightを弱くしても効かないなら他の方法をとってもいいと思います
チャンネル数を増やすなんかも手っ取り早いことがあります
下図のようにサブタスクとメインタスクを遠ざけるのもあると思います。検出器などでもよくありますが、予測対象の特性が異なる場合はブランチを切った方がうまくいきます。
難易度はあがりますが、Lossではなくモデル側の出力として制約をかける方がいいケースは多いです
たとえばx, y, zの3つの予測をするときに互い相関関係を持っている場合、別のv, wの予測問題に置き換えてそこからx, y, zをもとめるようにする
たとえば、x**2 + y**2 < 1のようにxとyの数値レンジが決まっているなら、rとΘの予測問題におきかえて、rをsigmoidみたいなので予測してもいいですね
手前みそですが、Kaggle睡眠コンペでは１日１回以下の入眠＆起床というルールを如何に反映するかという際に、Lossではなくtargetの工夫によって学習したことがあります。ここ最近で一番冴えていたのに2nd placeで悔しかったです
まぁ無理な時は諦めます。「あった方が良いと思うんだけどなぁ」と呟きながら泣く泣く諦めます
Lossの距離感や強弱は難しいですね。モデルへの反映まで考えるとかなり難しく様々なアプローチがあります。
ドメイン意識③：Augmentationを工夫する
使うべきAugmentationと使うべきでないAugmentation
今解こうとしている問題に対して、「このAugmentationって使っていいのか？」と考えることが最初の一歩ではないでしょうか。
■ Augmentaitonによって別ラベルになってしまうケース
たとえば以下の画像から次のアクションを予測するとします。まぁ見ての通りコップをとります。笑
これを学習時にFlip Augmentationで左右反転すると右手が左手になってしまいます。右利きの人の方が多いのでtestに対する予測精度は悪化してしまう可能性があります。であればFlip Augmentationはやめとこうかなと判断できます。
入れるべきAugmentationというのは、どんなコンペでも一回は考えていると思います。先日のRSNA2024の場合は、人の体に対して左右それぞれのラベルを別々に予測させるような問題でした。この場合は画像を左右反転するときにラベルも左右反転しておけばなんとかなりそうに感じますね。
■ Augmentaitonによってコンテクストが変わるケース
The Elephant in the Room(見て見ぬふり)の論文で有名ですが、下図のように物体検出器が室内の画像に貼り付けた象を検出できないことがあります。これは物体検出器が象そのものだけでなく、部屋の中という文脈も含めて学習していることになります。賢いですねぇ。
コンペにおいても、この象を検出すべきお題かどうかといったことを考えることができます。この象の例の場合は、Mixup Augmentationやcopy paste Augmentationなどで補強すると検出できるようになります。
とはいえ、NNは人が意識していないような思いもよらないところを(いい意味に)判断材料にすることがよくありますので、補助したつもりが迷惑をかけることもよくあります
■ 対象タスクでよくある状況をAugmentationで再現
この分野ではこの変なノイズがよくのるんだよなってときにはそれを自作してみると楽しいです。自作Augmentationは初心者もとっつきやすく、ちょっとした画像処理の練習にオススメです。
タスクによっては影なんかもよくのりますね。どんな形でのせようかとか、影の強弱をどう表現しようか、など色々考えることがあるので、良い頭の体操になります。
効く効かないを問わず、やってる感があるので妙に達成感が得られることもポイント高いですね。
参照元
タスク固有Augmentationの注意点：残念ながら足を引っ張ることもある
使うべき使わざるべきという話をしましたが、悲しいことに
NGだろというときでも、入れたら効いちゃうときもある
逆に、入れるべきだろってときでも入れない方がいいことがある
たとえば車載動画をみて、「地面は絶対に下なんだから上下反転だめでしょ」と思っていても効いてしまうことはあります。そんなときに有効なテクニックがあります…！
『どっちも試す』
気を付けたほうがいいぞ、と思いながらどっちも試します。ちゃんと理解してAugmentationを試行錯誤できることが強さです
なお、Lossと同じくこちらもモデル構造で反映することもできますが複雑な話になるので省略します。

何重もの層になっている画像から、一部分に着目して症状を判断する場合、最も基本的なアプローチが検出器との組み合わせで、特に検出器＋分類器の2stageはよくあるアプローチです。RSNA2024でも、大まかな場所を特定してから症状を分類するようなソリューションが多くみられました。

ディープラーニングでバッチ単位で学習させる主な理由は以下の通りです。
計算効率バッチサイズ単位で入力すると並列計算しやすくなるので、GPUなどの計算リソースを効率的に利用できるようになります。つまり、バッチ単位で処理することで、学習時間を短縮することができます
メモリ効率バッチサイズを調整することで、GPUのメモリ等を効率よく利用することが可能になります。例えば、バッチサイズをGPUのメモリを最大限に利用できるサイズまで拡大することで、GPUメモリを効果的に利用できます
安定性の向上バッチサイズ単位で学習すると、ノイズや外れ値の影響を軽減する効果があります。これにより、モデルの訓練が安定化します。また、過学習を防ぐ効果もあります
結局のところバッチ単位で学習させる理由は大きく２つになります。１つは学習時間を短縮する狙いです。もう１つは精度を向上させる狙いです。
このバッチサイズは、重要なハイパーパラメータの１つで、精度に影響を与えます
バッチサイズを適切に調整できれば、モデルの訓練を効率的に行え、かつ高い精度をえることができます。

結論から言いますが、残念なことに、どの問題にも共通の「最適なバッチサイズ」はありません
一般的には、バッチサイズは8,16,32,64…といった2のn乗が選ばれることが多いです。
まずは、こういった数値をためしてみると良いでしょう。
ただし、GPUのメモリサイズが小さかったり、モデルが大きい場合は、バッチサイズはGPUのメモリサイズで制限されてしまいます。
言語モデル（transformerなど）は大きめなモデルが多いので、バッチサイズは2とか4しか設定できないこともあります。
一般的にバッチサイズを大きくすると「ノイズや外れ値の影響が軽減され、過学習を抑制するのに役立つ」といわれています。しかし、「バッチサイズを大きくすると汎化性能が落ちた」という論文もあります。
では、小さくすればよいのかというと、小さくすると「モデルが多様なデータに対応することができ汎化性能が向上する」というメリットはありますが、「ノイズや外れ値の影響が高まるため、訓練が不安定になりやすい」という問題があります。
結局、バッチサイズは実験的に決めるしかないというのが実際のところです。


Kaggleは、アクセラーレーター切り替えてGPUとか使用する。
Kaggleでは、コンペ参加者向けにGPUが提供されています。代表的な例としては、P100やT4×2があります。
***よく分からんならシングルの方が良さそう?***
P100:1台の高性能GPUで、単一の処理において非常に高速な計算が可能です。GPUアクセラレーションの恩恵をシングルGPUで受けたい場合におすすめです。
T4×2:こちらは、2枚のT4 GPUが割り当てられる環境です。複数のGPUを並列に使用できる可能性があるため、特定のライブラリやモデルでマルチGPUを活用できる場合、より大規模な計算を効率的に行うことができます。ただし、全てのライブラリがマルチGPUに対応しているわけではありません。
GPUを使用する最大のメリットは処理速度の向上です。特に、データの前処理やモデルの学習において、以下のような状況で効果を実感できます。
大量のデータ処理:膨大なデータを扱う場合、CPUだけで計算すると時間がかかることが多いですが、GPUを使えば大幅に処理が高速化します。
GBDTモデルの学習:XGBoost、LightGBM、CatBoostといったGBDTモデルはGPUをサポートしています。これらのモデルは、設定やコード内でGPU使用のフラグを有効にするだけで、自動的にGPUを活用してくれます。(具体的な設定の仕方はこの後説明します。)

TPUの使い方は、環境・フレームワークによって異なり難しい。
TPUで学習を行なっている場合、バッチサイズが学習途中で変化するとエラーになることがあります。学習途中でバッチサイズが変化するシナリオとしてよくあるのが、Epochの最後のバッチです。
TPUは特定の軸方向の演算や、テンソルのサイズ、形などを変更する演算が得意ではありません。特定の軸方向に関してminをとるreduce_minやテンソルの形を変更するreshapeといった、比較的よく使われる演算においてもaxisやshapeがコンパイル時に判明している定数である必要がある、といった制約がかかっているものが多くあります。

分類でも回帰でも使える評価方法の交差検証とグリッドサーチについて説明します。
交差検証には、いくつかの種類があります。代表的なものは以下の通りです。
k分割交差検証：データセットをk個の部分集合に分割し、k回の評価を行う。
層化k分割交差検証：クラスの分布を考慮してデータセットを分割する。
Leave-one-out交差検証：データ数と同じ回数の評価を行う。

機械学習モデルは、学習データに過剰に適合してしまう過学習の問題を抱えることがあります。過学習が発生すると、モデルは未知のデータに対して適切な予測を行うことができなくなります。交差検証は、過学習の防止とモデルの汎化性能向上に効果的です。
交差検証では、データセットを複数の部分集合に分割し、各部分集合を交互にテストデータとして使用します。 この過程で、モデルは未知のデータに対する予測精度を評価されることになります。 過学習が発生している場合、交差検証の結果は低くなる傾向があります。交差検証の結果を基に、モデルの複雑さを調整したり、正則化手法を適用したりすることで、過学習を防止し、モデルの汎化性能を向上させることができます。
以上が、交差検証の活用事例と効果についての解説です。交差検証は、機械学習モデルの性能評価と改善において非常に重要な役割を果たします。kaggleコンペティションや企業での活用事例からもわかるように、交差検証を適切に行うことで、モデルの汎化性能を向上させ、実運用での有効性を高めることができます。
