# ハッカソン対策用
[Prompt Engineering with Llama 2 & 3]
(https://www.deeplearning.ai/short-courses/prompt-engineering-with-llama-2/)  
[Introducing Multimodal Llama 3.2]
(https://www.deeplearning.ai/short-courses/introducing-multimodal-llama-3-2/)  
[Building with Llama 4]
(https://www.deeplearning.ai/short-courses/building-with-llama-4/)

```Python
# import llama helper function
from utils import llama
```
```Python
# define the prompt
prompt = "Help me write a birthday card for my dear friend Andrew."
```
```Python
# pass prompt to the llama function, store output as 'response' then print
response = llama(prompt)
print(response)

# 同時比較
```Python
prompt = f"""
Given the context `context:`,
Also also given the query (the task): `query:`
and given the name of several models: `mode:<name of model>,
as well as the response generated by that model: `response:`

Provide an evaluation of each model's response:
- Does it answer the query accurately?
- Does it provide a contradictory response?
- Are there any other interesting characteristics of the model's output?

Then compare the models based on their evaluation \
and recommend the models that perform the best.

context: ```{context}```

model: llama-2-7b-chat
response: ```{response_7b_chat}```

model: llama-2-13b-chat
response: ```{response_13b_chat}```

model: llama-2-70b-chat
response: ``{response_70b_chat}```

model: llama-3-8b-chat
response: ```{response_llama3_8b_chat}```

model: llama-3-70b-chat
response: ``{response_llama3_70b_chat}``
"""
```
```Python
response_eval = llama(prompt, 
                      model="META-LLAMA/Llama-3-70B-CHAT-HF")

print(response_eval)
```
# メモ
## 最大トークン>入力トークン+出力トークン
- 入出力のどちらかが長い場合は、もう一方の量が減るので、注意
- max_tokens=で制限すると安全
```Python
# set max_tokens to stay within limit on input + output tokens
prompt = f"""
Give me a summary of the following text in 50 words:\n\n
{text}
"""
response = llama(prompt,
                max_tokens=123)
```

## マルチターン
- 応答の記憶を残して、次の会話に繋げる
- 次の会話の際に、「前回のプロンプト+前回の回答+今回の質問」を合わせて依頼する
```Python
prompt_1 = """
    What are fun activities I can do this weekend?
"""
response_1 = llama(prompt_1)
```
```Python
prompt_2 = """
Which of these would be good for my health?
"""
```
```Python
chat_prompt = f"""
<s>[INST] {prompt_1} [/INST]
{response_1}
</s>
<s>[INST] {prompt_2} [/INST]
"""
print(chat_prompt)
```
```Python
response_2 = llama(chat_prompt,
                 add_inst=False,
                 verbose=True)
```
```Python
print(response_2)
```
```Python
## 出力内容の調整
- モデルにより、学習パラメータ数が異なる。 
  - 大きいほど、推論が遅く、複雑な事に対処可能
### 役割（ロール）
```Python
role = """
Your role is a life coach \
who gives advice to people about living a good life.\
You attempt to provide unbiased advice.
You respond in the tone of an English pirate.
"""

prompt = f"""
{role}
How can I answer this question from my friend:
What is the meaning of life?
"""
response = llama(prompt)
print(response)
```
### その他
ゼロショットや例とか、要約や段階的には、自然言語の時と変わらないみたい

# code llama
プログラミングコードを出力
togethercomputer/CodeLlama-7b
togethercomputer/CodeLlama-13b
togethercomputer/CodeLlama-34b
togethercomputer/CodeLlama-7b-Python
togethercomputer/CodeLlama-13b-Python
togethercomputer/CodeLlama-34b-Python
togethercomputer/CodeLlama-7b-Instruct
togethercomputer/CodeLlama-13b-Instruct
togethercomputer/CodeLlama-34b-Instruct

# Llama Guard
