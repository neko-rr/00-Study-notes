# 注意
データの商用利用禁止
# コンペ参加基準
- メダルあり  
This competitlon counts towards tiers.
- 扱いたいデータ(タグあり)
    - テーブル/tabular data
    - 画像/image data
    - テキスト/nlp,text data
    - その他(音声/sound,audio dataや動画/video)
- 開催期間
    - 通常２-3ヶ月
    - 初心者は、残り数週間-1ヶ月がオススメ
        - notebookやdiscussionが充実してる。
        - Vote数やコメントでどれが有力か分かる。

# Kaggleにおける実験管理の全体像
[目指せ決定！Kaggle実験管理術次第でコンペで成果を上げるためのノウハウ/p.9 図0.3:Kaggleにおける実験管理の全体像](https://github.com/neko-rr/00-Study-notes/blob/main/reading.md#%E7%9B%AE%E6%8C%87%E3%81%9B%E3%83%A1%E3%83%80%E3%83%AA%E3%82%B9%E3%83%88kaggle%E5%AE%9F%E9%A8%93%E7%AE%A1%E7%90%86%E8%A1%93-%E7%9D%80%E5%AE%9F%E3%81%AB%E3%82%B3%E3%83%B3%E3%83%9A%E3%81%A7%E6%88%90%E6%9E%9C%E3%82%92%E5%87%BA%E3%81%99%E3%81%9F%E3%82%81%E3%81%AE%E3%83%8E%E3%82%A6%E3%83%8F%E3%82%A6)
- コンペ理解
    - コンペ概要理解
    - 評価指標
        - 【+αコンペ前】
        - Notionテンプレ
        - 過去の経験の蓄積
        - コードスニペット
        - パイプライン
- EDA
    - データ理解
    - ドメイン知識理解
- ベースライン
    - コード管理
    - アウトプット管理
    - パラメータ管理
    - シード管理
- 提出
    - CV/LB管理
- 改善
    - アイデア管理
    - TODO管理
    - 結果の分析
        - 【+αコンペ後】
        - 振り返り
        - Late Submisiion
        - コード整理

# 実験管理
実験した手法と精度の上下等を管理して、次の実験に活かすためにデータベース化する。
過去の実験に戻れるようにデータを複製して、フォルダ管理。
ハイパーパラメータの管理をして、コードを見なくても何を変更したか分かるようにする。

# コードの再現性
- シードの固定：ランダムシードを固定して結果の一致を保証
- パラメータの保存：すべてのハイパーパラメータや設定を記録
- 独立したコード管理

⇒3つ代表的な方法あり  
- Gitで管理（コミット忘れると終わりだから、やめとこう）
- 1実験1Notebook（Kaggleで一般的）
- 1実験1ディレクトリ（実験数が多い人・慣れてきた人向け）

# 実験結果の整理方法
- 実験IDとファイル名を一致させる
## 管理表の最低必要項目
- 実験ID
- CV(Cross Validation Score)
- LB(Leaderboard Score)
- モデル
- 派生元（コピー元の実験ID）
- 備考（仮説：何をしたかったか）

## 実験結果の可視化
- CV/LB散布図
- 外部ツール利用
    - WandBが一番人気：LightGBMなどの主要な汎用ライブラリに対応しているため、幅広い用途で使用される(2025年1月時点)
        - クラウドベースで、ログは自動的にクラウドに保存される。
        - どこからでもアクセス可能で、チームメンバーと共有できる。
        - プロジェクト管理ツールとしての側面も強い。
    - 僅差でTensorBoard:深層学習特化(2025年1月時点)
        - ローカル環境。
        - 素早く可視化。
        - 元々は、TensorFlowのためにGoogleが開発したが、現在は他のフレームワークでも使用可能。

## ハイパーパラメータの管理
人間が設定する値  
### CFG(Configurationの略)クラスを用いたハイパーパラメータの管理
【メリット】
- 全てのハイパーパラメータを1箇所にまとめて管理しやすくする。
- 1実験1Notebookの人向き

【デメリット】
- パラメータを階層的に構造化できないこと

CFGクラスに全てのハイパーパラメータを集約(リスト1.5)
```Python
class CFG:
    learning_rate = 0.001
    batch_size = 64
    num_epochs = 10
    model_type = 'resnet50'
```
CFGクラスからハイパーパラメータを取得する例(リスト1.6)
```Python
# モデルの定義
model = build_model(model_type = CFG.model_type)

# 学習ループ
for epock in range(CFG.num_epocks):
    for batch in data_loader(CFG.batch_size):
        # 学習ステップ
        optimizer.zero_grad()
        outputs = model(batch['inputs'])
        loss = loss_fn(outputs, batch['labels'])
        loss.backward()
        optimizer.step()
```
### YAMLファイルの利用
### argparseとYAMLの併用によるハイパーパラメータ管理

# 生成AI活用
## 要約・抽出・翻訳
### コンペ概要
```md
あなたは優秀なデータサイエンティスト兼Kagglerです。
入力はKaggleのコンペ概要ページです。
以下のフォーマットに従って、日本語で要約して下さい：

# 出力フォーマット
コンペ背景：
コンペ概要：
評価指標：
コンペ期間：
賞金：
制限事項：

# 入力
（ここにコピーした内容を貼り付ける）
```
### データセットの理解
```md
あなたは優秀なデータサイエンティスト兼Kagglerです。
入力はKaggleのデータセットページです。
以下のフォーマットに従って、日本語で要約して下さい：

# 出力フォーマット
データの概要：
各ファイルの詳細な説明：

# 入力
（ここにコピーした内容を貼り付ける）
```
### ベースラインの理解（他の人のNotebook)
```md
あなたは優秀なデータサイエンティスト兼Kagglerです。
入力はKaggleのベースラインNotebookです。
以下のフォーマットに従って、Notebookでの実施要項を日本語で要約して下さい：

# 出力フォーマット
使用するデータ:
前処理:
モデルの定義:
学習の設定:
その他:

# 入力
（ここにコピーした内容を貼り付ける）
```
- 追加質問も可能
- 「～初学者にも分かるように文章のみで説明してください。」
### Discussionの要約
```md
以下のDiscussionを日本語で要約して下さい。
その上で何がスコア向上にとって重要か、また、効果的ではなかった取り組みについてもまとめて下さい。

（ここにコピーした内容を貼り付ける）
```
⇒改善案のブレスト
```md
Discussionでの議論を受けて、以下のベースラインの改善案をブレストして下さい。

（ベースラインを貼り付ける）
```

# 点数アップ手法
## 最初にコピーするNotebookの選択方法
- 「Most Votes」で並び替えして、人気の高いもの

## シード固定
- 機械学習の実験には乱数が使用されるため、シードを固定しないと、同じコードを実行しても結果が異なる場合がある。
- 実験結果の再現性が保証されないため、アルゴリズムやモデルの正しい評価ができない。

### seed_everything関数
複数の乱数生成器のシードを一括で固定する。
```Python
def seed_everything(seed: int):
    random.seed(seed)
    os.environ["PYTHONHASHSEED"] = str(seed)
    np.random.seed(seed)
```
1. random.seed(seed)
    - Pythonの組み込みモジュールrandomのシードを固定する。
    - randomモジュールを使用した乱数生成が再現可能になる。
2. os.environ["PYTHONHASHSEED"] = str(seed)
    - 環境変数PYTHONHASHSEEDを設定する。
    - Pythonのハッシュ関数のシードを固定し、辞書やセットの順序が再現可能になる。
3. np.random.seed(seed)
    - NumPyの乱数生成器のシードを固定する。
    - NumPyを使用した乱数生成が再現可能になる。
### seed_torch関数
PyTorchを使用する場合は、さらにPyTorch固有の乱数生成器のシードを固定する。
```Python
def seed_torch(seed = 42):
    random.seed(seed)
    os.environ['PYTHONHASHSEED'] = str(seed)
    np.random.seed(seed)
    torch.manual_seed(seed)
    torch.cuda.manual_seed(seed)
    torch.backends.cudnn.daterministic = True
```
この関数は、seed_everythingの機能に加えて以下を行います。
1. torch.manual_seed(seed)
    - PyTorchのCPU上の乱数生成器のシードを固定する。
    - モデルの重みの初期化などに影響。
2. torch.cuda.manual_seed(seed)
    - PyTorchのCPU上の乱数生成器のシードを固定する。
    - GPUを使用した計算での再現性を確保。
3. torch.backends.cudnn.daterministic = True
    - CuDNNの決定論的アルゴリズムを使用。
    - 一部の非決定論的な挙動を排除。

## 複数モデルのアンサンブル
コンペ終盤に実施。
- 初心者でも点数を上げやすい。
- あえて異なる特性を持つモデルを混ぜることで多様性が生まれ点数アップする。

# エラー
## 問題が発生したため、このページはクラッシュしました。:Notebook
問題が解決しない場合は、当社側の問題である可能性があります。

'Node' で 'insertBefore' を実行できませんでした: 新しいノードを挿入する前のノードがこのノードの子ではありません。
NotFoundError: 'Node' で 'insertBefore' を実行できませんでした: 新しいノードを挿入する前のノードは、このノードの子ではありません。
- キャッシュのクリア: ブラウザのキャッシュが影響している可能性があります。キャッシュをクリアしてから再度試してみてください。
- ***ブラウザの拡張機能を確認: 特に広告ブロッカーなどのブラウザの拡張機能が影響を与えている場合があります。シークレットモードで通常は拡張機能が無効になりますが、念のため拡張機能をすべて無効にして正常に動作するか確認してください。***  
  ***⇒該当。自動翻訳を切ると、使用できる(´;ω;｀)***
- 原因でページの読み込みが中断されることがあります。別のネットワークに接続して試してみてください。
- Kaggleに問い合わせる: Kaggleのサポートに問い合わせて、問題が他のユーザーに共通のものであるかどうか確認することもおすすめします。
- 時間を置く: もしKaggle側で一時的な問題が発生している場合、時間を置くことで解決する可能性があります。
