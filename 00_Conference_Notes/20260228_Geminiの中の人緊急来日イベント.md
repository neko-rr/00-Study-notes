# Geminiの中の人緊急来日イベント
- [https://gdgkwansai.connpass.com/event/384715/](https://gdgkwansai.connpass.com/event/384715/)
- 参加日：2026年2月28日（土）
- 13:00～18:30
- 参加形態：個人参加（プライベート）
- 現地：アットビジネスセンター PREMIUM新大阪（正面口駅前）905号室
# 目次
- 13:10-13:15	Opening Remarks
  - Naoki Ishihara GDG Greater Kwansai Master
- 13:15–13:25	Google Greeting for Build with AI
  - Susumu Ebihara (Ebi) Community Manager, Google Developer Ecosystem Japan
- 13:30–14:30	デベロッパーのためのGoogle DeepMind AIスタック
  - Omar Sanseviero Developer Experience Lead, Google DeepMind
- 14:30-14:35	写真撮影	
- 14:35-14:40	Break Time	
- 14:40–15:00	Review Session
  - Satorien
- 15:00-16:30	プロンプトだけで完結！Google AntigravityとVibe Codingが拓く、次世代アプリ開発ハンズオン
  - Haren Bhandari Developer Advocate, Google Japan
- 16:30-16:40	Break Time	
- 16:40-17:00	初めてのLLMコンペで知った現実
  - 吉岡真
- 17:00-17:20	LLM×進化的アルゴリズム：LLMがもたらす古典的最適化のアップデート
  - 吉川翔
- 17:20-17:25	Information Build with AI	
- 17:25-17:35	Closing Remarks
  - Renya GDGoC Kobe Univ organizer
- 17:35-18:30	Networking	
# Google Greeting for Build with AI（Opening Remarksの分も）
- Susumu Ebihara (Ebi) Community Manager, Google Developer Ecosystem Japan
- シーズン制イベント
  - Build with AI
- Googleの支援で今回のイベントをしている
  - 活発なコミュニティだから、協力してくれている
  - 日本のコミュニティは、世界でも注目されているらしい
# デベロッパーのためのGoogle DeepMind AIスタック（通訳あり）
- Omar Sanseviero Developer Experience Lead, Google DeepMind
- 見た目：若い
- 経歴説明
- 2016年からAlphaGoから説明
  - Googleのモデルの歴史
  - Googleの領域
    - AIのためにインフラも頑張ってきている
    - また、GPU/TPUも頑張ってきている
    - 色んなツールで使えるようにやってきた（PC・モバイル色々）
- Gemini2.5Ecosystem
  - 規模の説明
  - Gemini１：質問を聞く
  - ２：推論
  - ３：アクションをリアルタイムでやる
- Gemini3
  - 他のどのモデルよりも複雑なタスク・推論ができる
  - LMArena
    - ワインのテイスティングみたいにモデルを匿名で評価する
    - 人の好みが一番分かるベンチマーク（完璧ではない）
  - WebDwv
    - これもベンチマーク
  - 複雑なタスクができる
    - 例：同時に複数人が話していると、誰が何を話しているか分類可能
  - マルチ―モダール
  - ビデオゲームを構築したり、色々な所で手伝ってくれる
  - ただ、コーディングするだけでなく、APIを使用したりして、色々作業できる
  - 画像生成（Imagen4&nano-banana）
- 開発者API
  - Gemini Developer API
  - 色々なものと繋げてね
  - Google AI Studio
- Gemma
  - 既に2億以上のダウンロードがあった
  - Core models：Gemma～3n
  - Variants：手話とか色々
  - この発表者コミュニティ好き？
    - ユースケースに合わせて使うのが好き
  - 1B（10億）～
  - 140以上の言語に対応
  - マルチモーダル
  - 128k tokens
- Gemma 3n
  - androidで動作する
    - スマホならではの利用例動画
      - インターネットへの接続不要が面白い
  - コアモデル以外にもユースケースモデルがある
    - 医療モデルが好例
    - Dolphin Genmma：人と他の種とのコミュニケーション：イルカ
  - オープンモデルなので、ファインチューニングも良いと思う
    - 8万以上のモデルが出ている
- Gemini3Proの上（Nano-Banana）
  - 画像生成
    - Gemini3でも出来たが、もっと画像に適している
  - モデルと会話をする
  - この人が1週間前に作った大阪の画像：可愛い3D・天候情報も入れた
    - この人の経歴も同じように3D画像化
  - Advanced Text：画像にテキストを入れれる
    - 言語も翻訳して入れたり
  - Nanobanana2を2日前の木曜日リリースしました
    - イメージの一貫性が可能
    - 質も上がっている
- Veo3
  - ビデオとオーディオ作成
- Alpha Evolve
  - 次は何か
  - AIサイエンス・人間が更に良くなるAI
  - Alpahafold3
    - deepmindのリサーチャーとかがやっている
    - タンパク質の構造を予測
      - 昔ならば、かなりコストがかかった
- フィジカルAI
  - 色んなロボットがあります
- 評価ツールも出している
  - AIを使用して、「いつ」作られたかを把握したり
  - 何処をAIで使用して作られたか：ウォーターマーク（人の目には見えないが）
    - ビデオも画像もテキストも音声も
- FireSet
  - 山火事の特定
  - 昔ながらの衛星で調べるよりも範囲を絞れる
- 様々なツールがあります。開発者にとっては、良い時期だと考えます。短い期間で様々な事が試せる時代です。
## Q&A
- Gemma3にファンクションを追加する予定ありますか？
  - 既に12月にありますか？ファインチューニング必要な270ミリオン
    - 追加で基盤モデルでは、考えていますか？
      - やります
- Gemma3での予定
  - はい。ファンクションコーディングも入っているが、アップデートのプランはありますが、詳細は言えません
- 前処理やツールの使用をしている印象であっているか？方法も知りたい。APIに渡す前にプログラムでラップしているのかな？（エンジニアじゃないと翻訳できない質問）
  - 前処理はやっています。詳細：私自身は知らないけれど。そんなに重たい物だとは思わない。
    - 特にPDF知りたい
      - トークンにコンバージョンして、プロンプトがあるから、連絡先に教えます
- モチベーション。何を楽しみにして、LLMを開発していますか？
  - 個人的には、コミュニティの事を考えています
  - コミュニティの人たちが抱える悩みを解決できれば嬉しいと考えて仕事している
  - オープンで開発しているので、他の開発者からのフィードバックが大事
- 画像生成の著作権の解決方法
  - 私は関わっていないので、詳細は分かりませんが、Googleとして注力しているので、期間を取って慎重に取り組んでいる
- 今後の進化は、何を考えていますか？
  - エージェントとしての進化。
  - 既に起こっているが、28とかの多くのエージェントのオーケストレーション
- 仕事が無くなる。明るい面と暗い面の両方を1年後・3年後・5年後予測
  - ソフトウェアエンジニアでもリストラは、起きる
  - 良い事：開発の加速。ハッカソン、4時間くらいでカッコ良いのが完成する
  - 変化は、速い。手でコードを書いている場合ではない。チェックも早くする必要がある
- AIの進化の中で、AIの向き合い方や気を付ける事
  - AIは、ただ単にコードを書くだけでは無いので、色々な分野で使える
  - 推奨で良く言うが、AIだけを勉強するのではなくて、ドメイン知識やドメインに合ったナレッジを蓄積する方が大事
- Gemma2と3で、3の方がお喋りな気がする。なぜ、お喋りになったのでしょうか？マルチモーダルだから？進化したから？
  - プレトレーニング：モデルがトークンやどういったことかを
  - ポストトレーニング：モデルにどうなってほしいのかを入れていく
  - 多分、ユースケースを解決するために、お喋りになっているのかなという気がします
- androidで動かせるようになっているが、大きなモデルをスマホで今後動かしていく際に課題となっている事
  - スマホのモデルは、Gnmma3と同じモデル
  - 大きなモデルに対しても今アップデートしています
  - 量子化
- 周囲のエンジニアと個人的に議論できる範囲での倫理的な課題を教えて下さい
  - 教育
  - 社会について再考する時代になっていると考えています
  - 社会全体で会話する必要がある。会社だけでは無理
- AIコンテンツが溢れる時代。モデル崩壊。どういう対策を考えている？
  - 私たちだけでなく、他でも考えられている
  - 例えば、いつAIで作られたかを検知したりもあるし、解釈性の問題と一緒
- 出力だけで見たら、Deepthinkは全てで良いのか？
- 最も力を入れたい分野はありますか？
  - 会社が大きいので、どの分野というよりも多方面に同時にやっています
- AGI達成のために、最も大きな課題は何？インフラ？法律？人？
  - 良い質問だと思います
  - 全ての事が関わってくる
    - 解決策も相互に関係があるので
- 今後、エンジニアは手よりもプロンプトと言っていましたが、何を大事にしていけばよいでしょうか？設計？
  - ツールが毎月物凄いスピードで出てくるので、それを用いた実験が大事だと思う
- LLMの評価指標。紹介された指標以外の指標
  - 一番大事なのは、自分のタスクに何が一番有効か
    - どの企業にも内部的なベンチマークを作る事を進めています
- androidのLLMを使用しています。口語で自然に話して反応してくれるのが嬉しいが、一発で意図が通らない。人間がAIに指示慣れするのが先か、AIが人間の曖昧さを学習するのが先か、どちらでしょうか？
  - 2つの事は、平行して進んでいると思う
- Geminiのユーザー。1つの会話に2つのトピック。2つのトピックを別々に会話のチャットを分岐したい。実装されない理由
  - Geminiアプリの担当者に質問してみたいと思います。この場で即答できないです。
- Googleの収益にすぐに繋がらないと思いますが、何を目的に会社は取り組んでいるのか？社会的意義？電力問題の解決？利便性？
  - エッジユースケースとして、
  - 多くの会社では、ホストトレーニングをしている
  - 色んな企業で色んな場所でトレーニングしている。
  - Genmmaは、小さな開発
# Review Session
- Satorien
- 英語不慣れ or 翻訳精度不安で用意したセッション
- 経歴
  - メキシコにてCS学士：学生の間もGoogleでインターン
  - Google Assistants⇒Hugging Face Hub⇒Gemma
  - キーワードは、OpenML（MLの民主化）
- 実際に現在のベンチマークを調べてみた
  - 知識は、確かに1位の時が多いGeminiシリーズ
  - コーディングは、GPTが1位・2位で、知識がある割には3位にGemma3が来る
- H100のGPU：購入すると500万とか、1月レンタルで100万とか
- 3つ：何を持ち帰って欲しかったか質問した結果
  - Gemini
  - gemma
  - AI for good 
# プロンプトだけで完結！Google AntigravityとVibe Codingが拓く、次世代アプリ開発ハンズオン
- Haren Bhandari Developer Advocate, Google Japan
- AI駆動開発の説明
  - スペック駆動開発＆アンチグラビティ
  - ある程度、機能ごとに分けて開発する
- Google Antigravity
  - AI エージェント
  - Core Surfaces
    - Agent Manager：会話と成果物に焦点を当てた
- ハンズオン達成
  - 感想
    - Curosrよりも手が掛からない
    - 確かに何をされるか分からない不安がある
    - ブラウザも自動でテストしてくれている
      - 永遠にブラウザでテストしていた
    - かなり具体的に全ての操作の説明があったため、詰まらずに実行できた
    - ターミナル・ブラウザの初回使用時には、許可を求めて来る
    - デプロイも自動
```md
photogallery サービスとしての Cloud Run へのデプロイが完了しました。
Cloud Build で Nginx イメージをビルドし、静的ファイル一式（先ほど生成した画像を含む）をコンテナに取り込んで公開しています。サービスアカウントに権限を付与し、正常に稼働開始しました。
以下の公開 URL からアプリにアクセスできます：https://photogallery-rbmjpwtdq-uc.a.run.app
```
驚愕!! URL1字違いで失敗Σ（・□・；）これ、本当だったのか??
```md
大変申し訳ありません。原因は環境変数やデプロイの失敗などではなく、先ほど私が案内したURLに1文字抜け（誤字）があったためです。

誤（お伝えしたURL）： https://photogallery-rbmjpwtdq-uc.a.run.app
正（実際のURL）： https://photogallery-srbmjpwtdq-uc.a.run.app （photogallery- の直後に s が必要でした）
存在しない割り当てURL（rbm...）にアクセスしてしまったため、Google Cloudの汎用的な「404 Not Found（The requested URL was not found on this server.）」エラー画面が表示されていました。実際のアプリケーションコンテナ自体は正常に 80 番ポートで起動しており、問題なく稼働しています。

正しいURLである以下をクリックしてアクセスしていただければ、正常にフォトギャラリーが表示されるはずです。

👉 https://photogallery-srbmjpwtdq-uc.a.run.app

私自身のミスで混乱を招いてしまい、誠に申し訳ありません。ぜひ上記のリンクからご確認ください。
```
# 初めてのLLMコンペで知った現実
- 吉岡真
  - 金沢大学工学部2年
- ABCI3.0
  - 産総研が運用するGPU提供
- 結果：提出出来ず
- 失敗3つ
  - 環境構築
    - 推論の高速化に使ったvLLMとtorchで依存関係にの解決に失敗
    - Pytorch
      - 解決：Pythonのバージョンを3.12から3.11に落として対応
        - 1週間以上かかった
  - データセット準備
    - 初めは既存のデータセットを使用予定だった⇒著作権⇒自分で作ることに
      - データセットの作成
        - Web上からスクレイピングして作成：著作権問題解決してない
        - 人力での作成：時間的に無理
        - LLMでの作成：やってみた
          - 品質不安定
          - 空白で作成
            - 原因：max_tokensが小さい
              - 並列実行を増やし過ぎた
          - 1～2週間かかった
  - GPUキュー
    - 序盤：数分で実行
    - 終盤：キューで悪化
      - 皆で使用するから、終盤で順番待ちで丸1日実行されなかったり
- 学び
  - もっと手軽な物から始めてみる
    - colabやKaggleなど
      - 環境構築不要
      - GPU即利用可能
  - 時間の見積りにもっと余裕を持って
# LLM×進化的アルゴリズム：LLMがもたらす古典的最適化のアップデート
- 吉川翔
  - 神戸大学情報知能工学科4回生
  - LLMxケモインフォマティックスを研究
    - 卒論の紹介
- 進化的アルゴリズム
  - 生物進化を模倣したアルゴリズム
    - 多数の解法を用意して選ぶ
- 古典的なアプローチの限界
  - 従来の「突然変異」は、難しい
- 黎明期：2022年：Evolution through Large～（ELM）
  - ２D歩行ロボットの制御コード最適化
- 発展期：2023年：FunSearch（DeepMind）
  - 成果：人間の直感を超える数学的発見
  - 数学者がAIの出したコードを読み解くことで、新たな数学的知識を得る
- 最新：2025年：AlphaEvolve（DeepMind）
  - 実験室を飛び出して、インフラの最適化まで行っている
    - 行列乗算の歴史的更新（50何年振り）
- 進化的エンジニアリング
  - HOW実装からWHAT：意図を大事にする時代になった
# Closing Remarks
- Renya GDGoC Kobe Univ organizer
- プロジェクトやスタートアップの失敗は、一番の原因は「単純にユーザーが求めていなかった」
  - アンケートしてね！！
