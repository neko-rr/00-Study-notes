# LLMアプリ開発者のためのフィジカルAI入門―模倣学習・Vision-Language-Action
-[https://studyco.connpass.com/event/379645/](https://studyco.connpass.com/event/379645/)
- 参加日：2026年2月17日（火）
- 19:30～20:30
- 参加形態：個人参加（プライベート）
- オンライン
- ハッシュタグ ：#StudyCo
# 目次
- 19:35	SO-101ロボットアームを組み立てて動かす
- 19:45	ACTモデルの仕組みとフィジカルAIの未来
# SO-101ロボットアームを組み立てて動かす
- 感想：途切れ途切れに鑑賞
- ロボットアームキットの紹介
  - LeRobot：オープンソース
  - ロボットの組み立てと動きの実演
- この人は学習
  - Google Colab環境で学習
  - 条件
    - ポリシー：ACT
# ACTモデルの仕組みとフィジカルAIの未来
- Policy
  - 制御の概念全体を表す
  - 観測（画像・モーターの角度・言語など）
- 模倣学習と初期の課題
  - 古の時代：厳密な制御をしていた時代
    - 座標（x,y,z）に移動・姿勢をこの角度にと厳密に決定
  - 模倣学習
    - Behacior Cloning(BC)：人間のデモンストレーションから直接、行動方針を学習する
    - 課題１：一度の微小なミスが、雪だるま式に大きな破綻へと繋がる（誤差が蓄積する）
    - 課題２：多峰性
      - 同じ状況でも、複数の「正しい行動」が存在する
      - 結果、両方の間の間違ったアクションをする等の問題
  - ACT
    - 課題１⇒解決策１：Action Chunking
      - 一連の動き全部をまとめて決める
      - Temporal Ensemble：毎ステップでを再生成し、未来の同一時間を予測する
        - 美術の線のように、滑らかになる
    - 課題２⇒解決策２：CVAE（Conditional Variational Autoencoder）
      - 複数の回答毎に予測する
    - 損失関数
    - 推論：
      - 「Z=0」に固定
        - 損失関数の一部であるKLダイバージェンスが、潜在空間を整理整頓する「重力」として働く
        - だいたい、上手くいくようになる
        - 動きが、固定化される＝安全性アップ
      - 推論時は、正解の行動列が存在しないため、CVAE Encoderは行われない
- VLA（Vision-Language-Action Models）
  - 言語による指示を受け付ける
- SmolVLA：一般消費者向け
  - 高速化の鍵
    - 視覚トークンの削減
    - レイヤー・スキッピング
      - ロボット制御には、LLMの深層部は不要。後半の層を切り捨てて、推論速度を2倍に。
      - 実は、前半で空間認識が把握できていて、後半は言語理解をしている事が分かってきたから、切り捨てられた
  - Action
    - Diffusion Pokicy（拡散モデル系）
    - Flow Matching/Rectifi  

- Gemini Robotics-ER（Embodied Reasoning）1.5
  - System1・System2の分離の例
  - レイテンシーと高度な推論
- Sim-to-Real：シミュレーションから学習する
- 異なる身体のロボットをまたいでのデータやモデルの流用
- 強化学習、長期実行、経験学習
# Q&A
- データの種類
  - 3種類
- Google Colabのサブスクは、どれ？
  - Pro使用しています。A100のGPUの消費量次第。
- 模倣学習のデータ収集で気を付けるべき点
  - 余計な情報を入れない：撮影者の手とか・人
- 学習のステップ数の適切な判断方法は？
  - 動かして見ながら判断
- ACTでパターン数は、あらかじめ設定が必要ですか？
  - 自動で判断されます
- 試行錯誤
  - 最初は、カメラの位置も違った
