# 【AI×プロダクト開発】RECRUIT TECH CONFERENCE 2026
- [https://recruit-event.connpass.com/event/371908/](https://recruit-event.connpass.com/event/371908/)
- 参加日：2026年2月27日（金）
- 12:00～19:20
- 参加形態：個人参加（プライベート）
- オンライン
- ハッシュタグ ：#recruittc2026
# 目次
- 12:10 - 13:00	和田卓人氏と語る、"開発現場"の未来予測AIの進化はプロダクト開発をどう変えていくのか？
  - （和田 卓人（タワーズ・クエスト株式会社）／鶴谷 誠文／近藤 健司）
- 13:00 - 14:00	開発とPM視点で語る、カスタマー／クライアントサポートの進化AI活用による対応品質向上と業務効率化の取り組み
  - （逵 正伸／山下 雄大／金田 拓）
- 14:00 - 14:30	レバレッジを生み出すデータ戦略リクルートならではのアナリティクスエンジニアリング
  - （森田 順也／林田 祐輝）
- 14:30 - 15:15	Kaggleで鍛えたスキルの実務での活かし方競技とプロダクト開発のリアル
  - （阿内 宏武（インディードリクルートテクノロジーズ）／羽鳥 冬星／中間 康文（インディードリクルートテクノロジーズ））
- 15:30 - 16:00	マッチング技術の進化プロダクトへのLLM実装＆技術基盤刷新の取り組み
  - （上山 彩夏／山本 航平（インディードリクルートテクノロジーズ））
- 16:00 - 17:00	現場の未来を拓くLLM活用、事業実装の全貌
  - 山畠 祥子／池上 顕真（インディードリクルートテクノロジーズ））
- 17:00 - 18:00	LLM活用の本質：「作る視点」と「使う視点」〜PFN 岡野原氏と語る、プロダクト実装へのアプローチ〜
  - （岡野原 大輔（株式会社Preferred Networks）／高橋 諒／三田 雅人）
- 18:00 - 18:30	インフラが熱い！ 高速化を支える水冷の『最前線』
  - （関 竜輔／片岡 歩）
- 18:30- 19:20	プロダクト開発現場におけるAI活用を加速させる土壌づくり
  - （片岡 歩／野村 眞平／阿部 直之）
# 和田卓人氏と語る、"開発現場"の未来予測AIの進化はプロダクト開発をどう変えていくのか？（和田 卓人（タワーズ・クエスト株式会社）／鶴谷 誠文／近藤 健司）
- エンジニアの役割と強調
- 現場でのナレッジ共有
  - 進化し続けるAIに現場は、どう運用するか
- 現状、ナレッジ共有
  - 個人で貯めるのではなくて、チームの共有所有物として管理する
- 今後、AI習熟度のレベル定義を定めたい
- 課題、習熟度の差が開き続けている
  - デリバリーの質とスピードを上げたい
- リクルートのデータ推進室
  - AIは何でもできる
    - 学習にも
  - 新規は早いが、修正が発生して、結局微増の効率化になる
  - AIリテラシーが必要。考える事をやめない
  - 触って学べる環境
    - 希望者にAWSを払い出し
    - 実際に触って、壊して学ぶ
- 3人でディスカッション開始
- １：個人の習熟度の差をどう乗り越えるか？
  - 他社でも問題が起きている
  - 個人に閉じない
    - 個人任せにしない
    - デフォルトだと差が広がるのは、当たり前
  - 仕組みで解決
    - 事例が溜まってきた
    - 実用的な精度が出てきているものがある
    - GitHubの知見の集合体を読み込ませるだけで上手くいったり
  - 手順がテキストの形で揃っている&人にもAIにもその情報が共有されているが、成功の鍵
  - 全員を底上げしていく
  - 再び、ペアプログラミングとか見る事の需要が再び増加している
    - 若手：コードエージェントのやり取りをみたい
- ２：エンジニアの役割は、今後どう変化していくか・
  - AIが書いたコードを人が確認する；全数検査は、今年中に無理になるでしょう
  - コードを書く需要が減るのは、仕方ない
    - そもそも、「プログラミング」の目的は、問題解決
    - 問題解決を重視するのは、変わらない
  - 人が品質を担保する必要があるのは変わらない
    - 但し、その方法が変わるだけ
  - 今まで、手が出せなかったものが出来るようになる
  - リファクタリング
    - 動作を保つが自動的に出来て、大規模なものが出来るようになる
    - また、小さいなリファクタリングを裏で非同期で24時間やらせるとかもできる
- ３：エンジニアとして、AIを活用できるようなるためには（個人）？
  - 進化が早いので、触り続ける
    - 身銭を切って、仕事で使用しないAIも触り続けている
  - ベンチマークでは分からない現場の肌感を大事にしている
  - 丸投げすると、学習効果は散々になる
    - AIが自分が分からない事をやり出すのは良いが、AIに質問して理解するのが大事
# 開発とPM視点で語る、カスタマー／クライアントサポートの進化AI活用による対応品質向上と業務効率化の取り組み（逵 正伸／山下 雄大／金田 拓）
- リクルートのデータ推進室
- 「オペレーターの丁寧な対応」と「安定品質」が、これまでの売り
- 課題：ユーザーにAI生成文をそのまま返答する初の試み
  - LLMを利用したプロジェクトが手探り
- 成功要因１：1000件以上の過去の成功内容を人の目で読み込んで整理
  - 今までの知見を社内から集めた
- 成功要因２：「AIに任せる領域」と「人が担う領域」の見極め
  - 少なくとも最初は、全部をAIに任せないと決めた
  - １：ユーザーの自己解決を促すHPに改造
  - ２：テンプレート対応できるものだけAIに任せる
  - ３：複雑なのは、人
- 成功要因３：継続的な回答精度維持・向上
  - 現在の課題：AIのバージョンアップの速度が速い（精度のためにテストしているが、負担が課題）
- 成功要因４：組織横断の対応
- 技術的な側面の説明
- 多くのユーザーにとって、問合せは「早く脱したい」ネガティブな状況
- 問い合わせの自動化の必要性
  - 人手で全てを即時解決は、「構造的な限界」がある
  - 24/365
- これまで自動化できなかったのは
  - シナリオ・ルールベースでは、対応シナリオが限定される
    - 保守・運用に課題
- LLM
  - キーワード一致で柔軟
  - デメリット：ハルシネーション
    - 網羅的に全部含めると、ユーザーの読み解き文章量が増える
- 情報不足が原因：アプローチ方針の設計
  - 聞き返し（マルチターン）
    - 永遠ループ
    - 複数回答が合致
  - 社内システム・DB接続
    - セキュリティ問題
- 解決
  - 複数エージェントと人の組み合わせ
    - 意図推定・回答生成・判断の3つにエージェントを分ける
  - Router Agent
- Q&A：判断エージェントは、何で判断している
  - 定性・定量の両方で見ている
    - それぞれ良さがあるので、組み合わせている
## 「Airビジネスツールズ」金田 拓
- リクルートのデータ推進室
- Airビジネスツールズとは？
  - 1つで全てを解決
- 利用者の増加に比例して、問合せが増加
  - コスト増大
  - 窓口分散している
- KGI：有人ヘルプデスクへの問い合わせ削減率
- 技術選定
  - Conversational Agents（Googleクラウド）
    - 開発スピードが速い：ノーコード
    - RAG性能：標準機能で高品質
    - 拡張性：サーバーレスでスケーラブル。将来的には電話対応（CCAI）も可能
- BFFパターンによる制御
- Playbook
  - Agentの挙動制御
- Data Store
  - 知識ベース
- 安全性評価：ビジネス固有リスクへの対策
  - BigQuery ML x RAGAS
    - dbt + BigQuery ML
- 運用と改善
  - Looker Studioでモニタリング
  - 改善事例：FAQ返却率の向上
- 効果：目標値を下回る問合せ率を実現
- Q&A：カスタマイズ性は？
  - 十分
  - しかし、新しいから不安定
- Q&A：モデルのバージョンによる精度
  - モデル依存では無くて、前の発表と同様にテストケースの回答度合いで判断している
# レバレッジを生み出すデータ戦略リクルートならではのアナリティクスエンジニアリング（森田 順也／林田 祐輝）
- リクルートのデータ推進室
- AIがもたらす事業貢献
  - リクルートの問い合わせの多くが、AIによるレコメンドで獲得されている
- データの鮮度と品質がレコメンドの効率を左右する
  - あるユーザーのサイト回遊⇒促したい回遊
  - 例；500万円の車を閲覧⇒維持費調べて⇒100万円の車を調べる：70万円の車の広告を出す
- データ鮮度
  - パイプラインを最適化してデータを届ける
  - バッチ連携で全てのデータ鮮度要求を満たそうとすると、運用課題が積みあがる
  - データに応じた適切なETLを敷設し、データ毎の期待する鮮度を最低限の運用不可で実現
    - アクセスログ基盤（行動履歴）：ストリーム
    - マスタ：バッチ連携
    - トランザクション：CDC
- データ品質
  - データは後から綺麗にするのは困難
    - 特にアクセスログ
    - 頻繁に変わる
    - ログが、どのイベントで発生しているか分類した
      - エラーの場所が分かりやすい
  - 貯める前の設計に積極的に関わる
## SaaSのデータマネジメント
- プロダクトによって、収益モデルやどんな事業体に受け入れやすいか違う
- データマネジメント
  - プロダクト最適化
  - 併用分析
- 横断利用を想定した施策
  - プロダクト個別マート
  - データポータルの構築
  - データ基盤の権限管理
- 次のテーマ「効率的なデータ活用管理」
  - 要求の高度化
  - 生成AIの活用
# Kaggleで鍛えたスキルの実務での活かし方競技とプロダクト開発のリアル（阿内 宏武（インディードリクルートテクノロジーズ）／羽鳥 冬星／中間 康文（インディードリクルートテクノロジーズ））
- Master2人とGrandmaster1人
- リクルート
  - 黄色2名
  - 赤色12名～
  - 紫色10名～
  - データコンペ開催実績3回
- コンペを始めたきっかけ
  - 外部で実績を示すものが欲しかった（社会人2年目）
  - 2018年にやっているコンペ内容が業務に近かったから
  - 学生の時にインターンで出会った（大学4年目前に始めて大学院で黄色に）
- 思い出に残るハプニングや印象的な出来事
  - チームで最終日に皆でディスカッションして最終2個を決めようと言っていて、リーターが寝坊して選べずに順位を大きく落とした
  - 初参加で、パブリックが強くて過剰適合していて順位が大きく下がった
  - 締切ギリギリまでチームでバラバラにやっていて、最後にアンサンブルしようとして最後までワイワイ
- HR領域のプロダクトにおけるレコメンド
  - タウンワーク・リクルートエージェント・リクナビ
  - Two-Towerモデルの導入
    - ルールベースの候補生成をTwo-Towerモデルに置き換えた
    - 計算効率の改善と候補生成の精度の改善どちらも狙う
    - 求職者・求人票⇒候補生成
- 近似最近傍探索
  - 各求職者に近い求人票の指定件数だけ取得
- embeddingに変換
- Kaggleで培われるのは、手の速さと手数の多さ
  - 手の速さ
    - ベースライン作成
      - Notebooks Grandmasterなので慣れている＆基本的なコードは流用できる
    - 実績サイクル
      - configで特徴量やパラメータなど根本的な変更以外すぐ実験できる構成を採用
      - 短期的での性能改善が求められた中、数週間でオフライン検証50回以上
    - 手数の多さ
      - ネットワーク構造
        - シンプルなものから始めて改善
      - 特徴量の処理方法
        - 数値特徴量の処理は様々な処理を試す
        - カテゴリ特徴量のembeddingサイズは機械的に決定する
        - 単位のあるカテゴリ特徴量は、重みづけ含めてモデルに反映する
      - 母集団
        - クリックや応募など一通り試す
- オフライン検証
- 成果
  - レコメンド対象の増加に対応
  - 1st-stageのフィルター部分が約25倍高速化
  - 推論全体で約2倍高速化
  - KPI
    - 閲覧数：＋8.4％
    - 応募数：+5.7%
- Q&A：Kaggleと違って、難しいと思ったことありましたか？
  - データが与えられるが、実務は探しに行かないといけない
## 2人目
- Kaggleで勝敗を分けるのが、いかに正しいオフライン評価を行うか
- 正しいオフライン評価とは、オンライン評価と相関するような検証方法を設計＆実行する事
  - オンライン評価＝ビジネスの現場だとA/Bテスト等で実際に得られるデータで行う評価
- この設計にすごく力を入れてきたので、実際もこの観点で指摘できる事は多い
## 3人目
- 「これ怪しい」センサーが働く
  - CVスコアが良すぎる⇒validation設計に誤りがあるかも
- 評価指標の妥当性判断
- アンチパターンの理解
  - Kaggleでハマる事がそのままハマるから避けれる
  - GBDT系
    - 学習率をチューニングパラメータにしない
    - （初手から）欠損埋めをしない
    - （初手から）特徴量を標準化しない
    - （初手から）外れ値の除去をしない
  - Validation構築・評価系
    - 時系列データをシャッフルしてtrain、validation分割しない
    - holdoutを見ながらチューニングしない
  - その他
    - （設計上不適切な場合）IDを特徴量に含めない
    - 本番推論時に使えない特徴量を使わない
    - いきなり複雑なモデルから始めない
- Q&A：Kaggleでしか、やらない事
  - 複数モデルは、まずやらない
    - コストが掛かるから
  - 特徴量で説明性が求められるから、Kaggleよりも制約がある
  - リーダーボードが欲しくなる
    - 自分がダメなのか、他の人もそうなのか知りたくなる
  - Kaggleは計算機で殴りに行く
    - オフラインでは、ファインチューニングやったもん勝ち
― 
# マッチング技術の進化プロダクトへのLLM実装＆技術基盤刷新の取り組み（上山 彩夏／山本 航平（インディードリクルートテクノロジーズ））
- 「カーセンサー」のレコメンドに「なぜこの車がおすすめなのか」という理由文をLLMで生成し、併せて訴求する機能を追加した
  - 中古車販売
- 情報開示しているが、何が違うのか車ごとの違いが分からない
  - 過去：項目の羅列
  - 生成文で具体的に説明
- レイテンシの戦い
  - UXを損なわないように非同期処理による事前生成
  - 事前生成が間に合わなくても、従来通りの表示は出るようにフォールバックを用意した
- LLMの効果
  - 理由の比較文を読む行動が見られた
    - 意思決定に使用されている
## 担当アクスログ
- 人材領域で利用しているアクセス解析ツール
- ログ設計の管理が横断的にできていない
  - 施策ごと（ABテストや、画面改修等）にadhocにログ設計と追加をしているため、プロダクト横断でのログや設計思想がない
  - 施策担当者やプロダクトごとに設計がブレてしまい、データマートでの利用の都度仕様のキャッチアップと検算から入らなければならない
- アクセス解析と機械学習でログを二重取得しており効率が悪い
  - 前ページに記載した制約（2h～3h）かかるから、先に機械学習でログが取られている
- 課題を同時に解決するために、ログ収集基盤の刷新を決定
  - ログの二重管理：一本化
  - ２～3時間：1秒未満
  - AWS
    - アーチテクチャは、資料見よう
  - 分析担当が直接弄るのではなく、どういうログが欲しいかをデータエンジニアに提出して、データエンジニアが一貫して実装するように変更
# 現場の未来を拓くLLM活用、事業実装の全貌山畠 祥子／池上 顕真（インディードリクルートテクノロジーズ））
- リクルートのデータ推進室・機械学習エンジニア
- PoCで終わらせない
- 「スーモカウンター」
  - 注文住宅・新築マンションの相談
- 課題：「申し送り」の作成が大変
  - 録音無し
  - 記憶頼りのメモ起こし
- お客さんの許可の元に録音して、「顧客サマリ自動生成」
- 現場装着をやりきるための工夫
  - プロセス面
    - 立ち上げ期：2か月現場へ当て続ける
      - アドバイザーに商談後すぐに結果を見て、意見をもらう
    - 録音品質も確認して、何が原因かを探る
    - 案件のビジネスメリットを全組織で共有し、協働体制を敷いた
  - システム面
    - 個人情報などのみを高セキュリティ環境に置いた
## 2人目
- キャリアアシスタント
  - キャリア相談サービス
  - いつでもAIに相談を
  - １：現状と価値観の深堀り
  - ２：働き方の方向性の提案
  - ３：転職中の悩み相談
- Router方式
  - INPUT⇒ユーザーの意図を解釈し、最適なAgentをアサイン⇒Agent個別定義による出力の安定化
    - Agent個別定義による出力の安定化：Agent毎に内部処理や出力形式を定義することで、LLM特有の出力の不安定性に対応
- Expert Agent
  - 可能な限り、処理を分割する事で、安定＆エラーが発見しやすい
  - デメリット：開発する量が多い
    - 対策：再利用性を高めるためのPromptのモジュール設計
      - どのプロンプトを何のエージェントで使うか組み合わせれるようにしている
- 「触れる体験」と「試せる環境」の両輪で、価値あるUXを抽出
  - ユーザーヒアリングで、無数にある組み合わせから本当に意味あるものを抽出する
  - 定性データの定量化」LLMによる「会話」の構造化（カテゴリ化）
## Q&A
- PoCの壁を突破する、フィードバック・ループの回し方
  - エージェントを分けているから、小さなリリースがしやすい
- ユーザーヒアリング
  - 仮説も発見できる
  - デザインだけでなくて、UXの動線の確認ができる
- 業務の方：A/Bテストできないがどうしていますか？
  - アンケートで測定
  - 立ち上げ期は、パターンを只管作って当てる
- 現場に溶け込む未来
  - 求職者にとっては、求められる状況が変わってきている
  - 自分が何を大事にしたいか、棚卸が重要
# LLM活用の本質：「作る視点」と「使う視点」〜PFN 岡野原氏と語る、プロダクト実装へのアプローチ〜（岡野原 大輔（株式会社Preferred Networks）／高橋 諒／三田 雅人）
- リクルートにおけるR&D体制
  - R-ICT GPT：既成LLMの事業活用
  - WhaleLM：PoC~事業実装
- LLM活用フェーズが進み、ニーズがシャープに高難易度に
- チャットではなくて、既存UXに組み込み
  - システム性能要件（レイテンシ等）が高い
  - 結果直結の打ち手が明確
- R&Dから施策化⇒横展開
- LLM活用の壁
  - 非機能要件への対応（レイテンシ・スループット・コスト）
  - 出力の制御性・指示追従性
- 例：１生成文表示
  - 前：Gemini-2.5-flash使用
    - 想定リクエスト量（30RPS）を保証するためには約970万円/月
  - 改善：SLM及び推論高速化技術
    - 例：SFT・知識蒸留・投機的デコーディングなど
    - 性能改善しつつ約17.5倍高速化＆運用料金を09.5%削減
- 例：知識蒸留における指示追従性改善
  - 課題：ショートカット学習
  - 改善：Adaptive Z-score Weighting（AZ-Weighting）
- Q&A：勘所として大事な事
  - 必要な所を見極める
  - トレードオフの見極め
    - 平たく言うと、ドメイン知識が重要になる
- 宣伝：純国産フルスクラッチ基盤モデル
  - PLaMo（プラモ）
  - 特化型：PLaMo翻訳
  - 日本語自信あります
# インフラが熱い！ 高速化を支える水冷の『最前線』（関 竜輔／片岡 歩）
- 飛ばした。聞いていない。
# プロダクト開発現場におけるAI活用を加速させる土壌づくり（片岡 歩／野村 眞平／阿部 直之）
- 振り返り
- 上司視点でいつもモデルのレビューする際は、「評価指標」を重視して見ている
  - モデルやドメインに合っているかどうか
  - むしろ、これしか見てない勢い
- 抽象化した所で、よりエンジニアの役割が広がっていると感じる
  - ものを作る人と考えているので
  - 技術的負債とかは、AIに解決させて、人は新しい価値を作る方に集中できるようになるのでは
- リクルートのプロダクト開発組織の取り組み
  - ログはちゃんと取っている
    - ログを元に修正していくのが大事
  - 非構造データがもっと使用できるようになるとワクワクしている
  - 言語関係なく、AIエージェントが使えると逆に差が開いていく
    - 使えれば、基礎知識あれば、どの言語も行ける（知らない言語も）
    - 土台があれば、誰でも
- 責任あるAIガバナンスを決めて取り組んでいます
  - 守りもしっかりやっています
- 昔は、疎結合でデータが繋がっていたから組織も分かれている方が良かった
  - でも、今は、リアルタイムに密接に繋がっているから、組織としてもデータ部隊と開発部隊は協力していく必要がある
  - 実装できないデータエンジニアは価値が無くなる。
    - 整理が大事、コーディングエージェントに投げると出来るから、投げれるまで整理できるか
    - 逆もそうで、お互いに相手のやる事を理解して、お互いに歩み寄って相手の連結を考えて高価値にする必要がある
