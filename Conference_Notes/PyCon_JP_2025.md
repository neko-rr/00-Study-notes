# PyCon_JP_2025参加メモ
# 1日目(9/26)
# 【招待講演】PEP 750 の共同著者 青野高大 氏による Python3.14の新機能の紹介
- フェニックスホール
- 日本語
- 10:30 - 11:00
- 青野　高大
## 講演資料[(https://github.com/koxudaxi/pyconjp_2025.git)](https://github.com/koxudaxi/pyconjp_2025.git)
## Python 3.14 には新機能 t-strings（Template Strings）が導入されます。青野さんは、この仕様をまとめた PEP 750 の共同著者です。
Python 3.14 の最終リリースは 2025 年 10 月に予定されています。青野さんは、OpenAPI／JSON Schema から型安全なコードを生成する datamodel-code-generator や、Ruff・Pydantic 向けの PyCharm プラグイン など、現場で役立つ OSS を数多く開発されています。PyCon US や EuroPython など国際カンファレンスでの登壇実績も豊富です。
Python の文字列機能は、% 演算子、str.format()、f-strings と発展してきました。次の一歩となる t-strings が、あるいは将来の Python が、どんな世界を作ろうとしているのか。私自身もお話を伺うのを楽しみにしています。どうぞご期待ください。
## 個人メモ
- 25/10/7リリース
- 19個新しい機能あり
- 型のアノテーション遅延評価がデフォルトになった（PEP649）
  - 関連して（PEP749）でAPIを提供。
  - 従来の型整理のAPIとか利用していたら動作確認した方が良い
- GIL撤廃構成の正式サポート（PEP797）
- 最近リリースしたサブインタプリタ用のAPIが無かったので作成した（PEP???)
- Tsil-calling Interpreter（実験的なもの。他の言語でも使用しているから、速度が向上するだろうと採用）
- リモートデバッグ接続の安全化(PEP768)
- JIT（実験的な物。高速になる時もならない時もある）
- コードの視認性を向上（配色とか）

- 文字列フォーマットの進化
  - "%s"
  - "
  - f
  - 【例1】理由：SQLやHTMLに値を直埋めすると、SQLインジェクション対策⇒f-string（危険）
    - 安全：t-string + psycopg3：安全なSQLオブジェクトへ変換
  - 【例2】手動エスケープ
    - 安全：
  - 【例3】構造化ログのユースケース
    - 式テキストとフォーマットが残る
  - 【例4】テンプレートの応用：メール通知・設定
  - 内部構造：
    - f-string：即時文字化
    - t-string：一度テンプレート化（コンテナ）。連結は、テンプレート＋Templateのみ：セキュリティ的な理由から。
  - テンプレート自体は何もしない、後でコンテナとして活用できる。
    - 遅延評価すると、かなり複雑になるため、Pythonユーザーの属性（初心者多い）を考えて、即時反映にした。

- まとめ
- セキュリティ：SQLインジェクションやXSSを防止

# Pythonic Finance: Analyze Company Fundamentals with SEC EDGAR APIs(Python ファイナンス: SEC EDGAR API で企業の基礎情報を分析)
- ダリア2
- 初級
- 英語
- 11:15 - 11:45
## Pythonと定量分析を用いて、米国証券取引委員会（SEC）EDGARシステムのファンダメンタル財務データにアクセスし、検証・分析します。SECのJSON APIは、財務報告の国際標準であるeXtensible Business Reporting Language（XBRL）で報告された企業提出書類から抽出された構造化された財務データを提供します。堅牢なデータ検証にはPydanticが用いられます。
参加者は、XBRL 言語の概要、SEC EDGAR の API からデータを取得するための実践的なテクニックcompanyfacts、データ サイエンスとソフトウェア エンジニアリングを組み合わせて Pydantic でデータを検証する方法、API 応答から重要な基本指標を抽出する方法、基本的な財務比率を計算する方法、財務トレンドを視覚化する方法について学習し、国際的な公開財務データ API の操作の詳細について学ぶことができます。
##プレゼンテーションの予定概要：

はじめにと免責事項（約3分）
簡単な自己紹介と重要な免責事項：私はファイナンシャルアドバイザーではなく、この講演はファイナンシャルアドバイスではありません
なぜ Python で企業の基礎を分析するのでしょうか?
データ: SEC EDGAR、XBRL、API (約 4 分)
SEC、EDGAR システム、米国企業の提出書類 (10-K) の概要
構造化データ標準としてのXBRLの簡単な紹介
companyfactsXBRL由来のデータのためのJSON APIに焦点を当てる
実例：Pydantic によるデータ品質の確保（約 3 分）
Pydantic を選ぶ理由と API レスポンスの Pydantic モデルの概要
企業データの取得と検証（約3分）
と を使用してrequests、pydanticサンプルの米国企業のデータを取得および検証します。
潜在的なAPIまたは検証の問題に対処する
財務指標の説明と抽出（約7分）
基本的な中核財務指標の説明: Revenue、、、、、Net IncomeAssetsLiabilitiesEquity
年間データの抽出、データを表示するためのpandasの構築DataFrame
同じ財務概念に対して異なるXBRLタグ（異なる派生JSONプロパティ）を適用すると、企業は同じスキーマを持たない可能性がある。
財務比率の計算（約3分）
財務比率の説明: Net Profit Margin、Debt to Equity Ratio
指標の計算
トレンドの視覚化（約2分）
指標と計算から、プロットを生成して表示するmatplotlib/seaborn
国際化とデータのニュアンス（約2分）
他の国（例：日本EDINET）は異なるシステムを持っていますが、同じXBRLデータ構造を持ち、スキルと知識が移転可能であることを証明します。
主なポイント、要約、まとめ（約2分）
プロセス、ツール、将来の探究に向けた提案の概要
## 個人メモ
- 10Kレポートと20Kレポートがある。
- どちらも年次報告書
- 10Kは、アメリカ企業に提供義務あり。会社向け

- Company Facts API　困難
- 普通の財務用語説明
- WEBスクレイピング

- Google Colab使用
- jsonデータ（API)⇒表に変換⇒グラフ化
  - これなら、私も発表できそう。

# ReactPyを使ってreact likeにUIをPythonで実装する
- ダリア1
- 中級
- 日本語
- 12:00 - 12:30
- モノタロウ勤務
## 1. ReactPyとは何か？
「フロントエンド苦手だけど、こんなのあったら便利だよね」な話
JavaScript書かずにReactっぽいことがPythonでできる
HTMLテンプレートよりもっと柔軟にUIが作れる
ReactPyの特徴を簡単に紹介
Reactのコンポーネント思想をPythonで実現
Python慣れしている人には親しみやすい書き方
2. ReactPyの強みとフロントエンド構築ツールとしての位置づけ
ReactPyの独自の強み
既存のWebアプリケーションに自然に組み込める
Pythonの豊富なライブラリエコシステムとの親和性
ReactPyの技術的特徴
Virtual DOM的な仕組み
状態管理の仕組み
3. ReactPyの導入方法と実践活用
ReactPy単体での使用方法
FastAPI、Flaskなど様々なバックエンドとの組み合わせ
新規プロジェクトでの始め方
既存プロジェクトへの導入パターン
段階的導入戦略（一部のページから始める）
reactpy-djangoを使った既存Djangoプロジェクトでの活用例
実装デモとコード例
従来のHTMLテンプレートとの比較
ReactPyで実装した動的コンポーネントの例

## 個人メモ
- モノタロウ：Reactによる画面開発（ReactPyは、使用してない）。AI工藤開発も積極的にやっている。
- ReactPy：UI構築ツール
  - 他にもStreamlit、Dash、Gradio、Panelと同じ立ち位置
  - PythonでReactのように使用する
  - コンポーネント定義を組み合わせて、画面構築する
  - 実行自体は、Pythonをそのまま実行
  - いくつかバックエンドが採用されていて、それで動く
  - 【メリット】学習コスト削減：JavaScript/TypeScript/等
     - 既存のWebAPIと統合しやすい
     - FastAPI等サポートしている
     - 既存のWebページへの埋め込みが可能
     - JupyterやPlotly-Dashとの公式統合：データサイエンス分野での活用が明確に意図されている
     - サーバーサイドアーキテクチャ：全ての処理がサーバーで実行される（状態管理：画面遷移が簡単にコントロール可能）
       - Pythonエコシステムの直接活用
       - デメリットは、全てサーバーに集中するので、遅くなる
         - VDOM実装：差分だけを
     - WebSocket通信による同期（リアルタイムで同期される）
     - asyncio基盤の非同期処理
     - 統一された状態管理：フロントエンドとバックエンドで状態の分離がない
       
- 【活用例】データ分析ダッシュボード、
- 既存プロジェクトに導入する場合
  - 例：DjangoアプリにReactPyを導入するためのツール
    
   
     - サーバーサイド実行の利点
  
- コンポーネント思想：再利用可能な部品：UIを独立した部品（コンポーネント）として設計
- 関心の分離：各コンポーネントが独自の状態とロジックを持つ
- 組み合わせによる構築：小さなコンポーネントを組み合わせる

- Pythonらしい書き方：コンポーネント宣言は
- 繰り返し処理はｍリスト内包
- スタイルの指定にPythonの辞書を利用できます（Tail？？も使用できる）

# 明日からgraphlib、みんなで使おう
- ダリア2
- 中級
- 日本語
- 13:30 - 14:00
- 東京ガスの人（Goldスポンサー企業）・オライリージャパンの翻訳や監修者
## 講演資料
## 導入
Python 3.9で標準ライブラリにgraphlibが追加されました。
しかし、公式ドキュメントにはgraphlibが導入されたモチベーションや利用例に乏しく、すでにトポロジカルソートの存在を知っている人しか使えないライブラリになっています。
結局、graphlibは何に使えるのか、電池が液漏れする前に（なるべく）すべて解説します。

グラフ理論速習
graphとは数学のグラフ理論におけるグラフを意味します。
グラフとは（大雑把に説明すれば）物事とその関係性を数学的にモデル化したものであり、鉄道網における駅と線路、人間関係における人間と友人関係など、日常生活においてグラフでモデル化できるものはたくさんあります。

グラフとは
無向グラフと有向グラフ（今回扱うのは有向グラフ）
線型順序について（半順序関係、全順序関係）
トポロジカルソート、有向非巡回グラフ（DAG）について
任意のグラフがトポロジカルソートできるわけではありません。
グラフが有向非巡回グラフであることと、グラフがトポロジカルソート可能であることは同義であることを説明します。

有向非巡回グラフの定義
トポロジカルソートの定義
グラフが有向非巡回グラフであることと、グラフがトポロジカルソート可能であることは同義
graphlibの使い方
ここまで理解できれば、明日からgraphlibを使えるようになります。
少なくとも、頭の片隅にgraphlibが入り、必要になった瞬間に思い出せるようになります。

graphlibの使い方
応用例: タスクの処理（タスク処理順序の決定、簡易的なタスクランナーの実装）
## 個人メモ
- （ぐらふぃりぶ）読み
- トポロジカルソート：有向非巡回グラフ：G＝(V,E）。閉路を含まない物。
  - 二項関係：
  - 半順序関係：反射率、反対称率、
  - 線型順序
  - 歩道：グラフG＝(V,E)の頂点からへの長さの
  - 道：グラフGの歩道W。特に閉じた道を「閉路」と言う。
    - いい感じに言うと、有向グラフの頂点をいい感じに順序付けしたもの
  
- グラフ定義：無向グラフ（非順序対）・有向グラフ（順序対）
  - 「関係」を数学的にモデル化したもの
  - 「もの」は、人間、駅、タスク、サーバー
  - 「関係」は、人間関係、線路、依存関係

- 命題（トポロジカルソート可能）：有向グラフGが
  - 有向非巡回グラフ（必要十分条件）⇒トポロジカルソート可能　※証明がアルゴリズムになっていることに注意

- 活用例
  - タスク順序
 
- garphlib：トポロジカルソートが実装された標準ライブラリ
  - 簡易的に利用すると、実行順序を決定する仕組みとして使える
  - タスクランナー：並列実行しやすいアルゴリズム
  - 最適解とは、別問題！？最適解にするには、また別の仕組みが必要

# Beyond Multiprocessing: A Real-World ML Workload Speedup with Python 3.13+ Free-Threading(マルチプロセスを超えて: Python 3.13+ のフリースレッドによる実際の ML ワークロードの高速化)
- ラン
- 中級
- 英語
- 14:15 - 14:45
## PyCon JP 2024では、実験的なフリースレッドモードの素晴らしい導入を目にしました。あれから1年が経ちましたが、実際にこのモードを使って実世界の問題を解決した人はどれくらいいるでしょうか？マルチプロセスのシリアル化ボトルネックに既に悩まされている方、あるいはデータ量の多いタスクが思ったほど速くないことに不満を感じている方、この講演はまさにうってつけです。

風景は変化している
Python 3.13 でのフリースレッドの初期リリースでは、シングルスレッドパフォーマンスのトレードオフが知られていましたが、状況は変化しています。この問題を軽減し、並列ワークロードにおいてフリースレッドをこれまで以上に強力で現実的な選択肢にする Python 3.14 の重要な改善点について詳しく説明します。

理論から実戦で実証されたプレイブックへ
このセッションでは、コアコンセプトから実際のアプリケーションまで、実践で実証されたプレイブックをご紹介します。データ集約型研究分野を加速させるためのオープンソースフレームワークの開発経験を活かし、以下の点について解説します。

フリースレッディングの「なぜ」と「どうやって」：まず、Pythonの新しい並列実行モデルの基礎を理解しましょう。マルチプロセス処理がデータ集約型のタスクで苦労する理由と、フリースレッディングがどのようにして洗練された組み込みソリューションを提供するのかを説明します。

ハードデータを用いた実世界のケーススタディ：次に、 Federated Learningの実世界プロジェクトを詳しく見ていきます。フリースレッディングによって重大なパフォーマンスボトルネックが解消されました。ベンチマークでは、マルチプロセスやRayのような既存のフレームワークと比較して、フリースレッディングの劇的なスループット向上が示されています。

ライブリファクタリングとベストプラクティス：最後に、ライブデモで、低速なデータパイプラインが高性能アプリケーションへと変貌していく様子をご覧ください。実践的なプレイブックと、競合状態などのよくある落とし穴を回避しながら、これらのテクニックを自信を持って適用できるようになります。

この強力な新しいPython が要求の厳しい ML ワークロードとどのように統合され、新しいレベルのパフォーマンスを実現し、コードを真に強化できるかを一緒に見ていきましょう。

## 個人メモ
英語と内容の難しさで分からん。
GILの事

# Django NinjaによるAPI開発の効率化とリプレースの実践
- ラン
- 中級
- 日本語
- 15:00 - 15:30
- Be PROUD社　connpass・PyQ・の開発・運営している人：全てDjango使用している
## 発表の構成（予定）
はじめに

自己紹介・会社紹介
発表の背景とゴール
想定する聞き手
Django Ninjaとは何か

Django REST frameworkやFastAPIとの比較
Django Ninjaの特徴（型ヒント、OpenAPI連携、FastAPI互換の設計思想など）
なぜDjango Ninjaを選んだのか

比較検討した選択肢（独自実装・DRF・FastAPIなど）
パフォーマンス、学習コスト、開発効率、保守性の観点からの選定理由
Django Ninjaを用いた実践例

型ヒントで定義するリクエスト・レスポンススキーマ
自動生成されるOpenAPIドキュメントの活用
認証・認可（API Key, JWT など）の実装方法
スロットリングやページネーションの設計
テスト戦略（ユニット・統合テスト）
段階的なリプレース戦略

既存の独自実装との共存
互換性維持の工夫
移行計画と影響範囲のコントロール
まとめとQ&A

得られた効果と課題
今後の展望（型安全な開発・APIクライアント自動生成など）

## 個人メモ
- 過去django-piston⇒独自実装（サポート切れで）⇒文脈負債
- 要件：型＝ドキュメントの一元管理＆自動化
  - 既存Djangoアプリに最小の影響で導入
  - V1とV2の共存
- django-ninjaの選定理由
  - FastAPIに強く影響を受けたDjangoのREST API
- 【比較】
  - FastAPI
    - メリット：高速でシンプル
    - 一貫した非同期実行が可能（DB接続含む）
    - 型ヒント（Pydantic）を活用したデータ検証＆整形
    - デメリット：Djangoとの親和性が低い
    - ひと手間必要
  - DRF
    - メリット
    - RESTのリソースとDjango Modelが1対1の場合、CRUDを作るのが簡単
    - デメリット：フレームワークが想定していない使い方をすると実装が複雑化する
    - 型ヒント活用が標準では弱い
    - ドキュメントを充実させるためには記述が膨れていく

  - django-ninjaの主要機能
  - OpenAPIドキュメントの自動生成
    - 実装とドキュメントをSqagger UI
    - スキーマ定義を充実させてOpenAPIドキュメントと連携（動いているコードがそのままドキュメント化可能）
      - 開発の動作確認で使いやすい
    - SwafferUIとRedocの使い分け
  - API開発・認証がしやすい
  - ページネーション
  - スロットリング（最近v1.2.0で同梱された）・IPやユーザー単位で使い分け可能
  - モジュール分割（Routerを活用）
    - APIを追加するには、各アプリの
    - NinjaAPIクラスの代わりにRouterを使用
    - 全Routerをimportし、メインのNinjaAPIに取り込む
  - APIのバージョン管理
  - 例外ハンドリング
  - デコレーターの活用
  - CORS対応
  - Appendix：クラスベースでの対応：サードパーティ活用で対応可能
- テスト方法
  - 個人的には、PyTest +
- 懸念事項
  - コミュニティ成熟度（若い）
    - Ninja自体のサードパーティは少ないが、必要な機能は揃っていた
    - 依存しすぎない。
- 移行方法
- 副次的な効果
  - ファットコントローラー気味⇒ビジネスロジックの呼び出しがすっきり
- 結果：開発効率が上がり、


# コーヒーブレイク & ポスターセッション
- サクラ
- 15:30 - 16:15

# OSS≒盆栽 〜個人的趣味として無理なくOSS開発をするときに意識したいこと〜
- ダリア1
- 中級
- 日本語
- 16:15 - 16:45
- ニジボックス(仕事中にこのスライドを作成した) の人：Sphinx大好きの人
## 予定アウトライン
自己紹介
「OSS≒盆栽」とは？
Pythonライブラリにおける利用者規模
個人的活動でOSS開発をするということ
無理をしないための考え方
(下記は予定している一部)
多くの人が使うことを想定しない
機械的に行えることは機械的に
sphinx-revealjsによる事例
プロダクトソースコード上の変化
開発する基盤に起きた変化
周囲にある環境で起こっていた変化
## 個人メモ
- 鑑賞趣味としての盆栽≒個人OSS開発
  - 小さな目標から始められる
  - 意外とランニングコストが低い
- 【影響】
  - GitHubのスターなどが多い⇒大変やから、ここは目指さない。自然となれたら良いなくらい。
- 【趣味の個人OSS開発】
  - 程よい開発経験を得られる：上流から下流まで一通り
  - 失敗しても誰も困らない（周りに迷惑がかからない）
  - PyPIに公開するまでは、大分楽になった
- 【無理をしないための考え方＝本当に頑張るべきところ以外頑張らない】
  - 単機能なものを作る（未完成な多機能より完成済み単機能）
    - 達成感を得るのが遅くなる
    - 使う側もシンプルで分かりやすい（例：qrcode：QRコードを作成するだけ）
    - よくある例：
  - 「自分が普段遣いする」ためのライブライを作る
    - 「欲しいけど見つからない」は、大事なモチベーションの源泉
    - 自分で作成すると、自分で使用したくなり、結果メンテナンスもする事になる
- 機能の担保にこだわらない
  - 精緻なユニットテストを書いておけるのは望ましいのだが、ここにリソースを取られると疲れてしまう。
    - リンターやフォーマッターは導入した方よい。
    - 困ったら、Ruffに全てを委ねよう
- なるべくさっさと公開する
  - 「PyPIにあるか？」は、それなりに重要
  - 数人でも使用してくれたら、有難い
- 「型」を作っておく

# Day 1 Lightning Talks:皆さんから募集するライトニング・トーク (略してLT。5分以内の短い講演)
- フェニックスホール
- 17:00 - 17:45
## 個人メモ
### OWGeoの宣伝
- 地理空間情報
- 実世界での利用例：スマホの地図アプリ、ハザードマップ、配達経路最適化
- 座標系の世界：緯度経度だけじゃない
- ライブラリ：pyproj,py:早すぎて1枚目スクショ撮れず
### キャリアボット
- 研究室でのPython活用事例
  - テーマ：人間とAIの共創
  - Streamlit + Python + Gemma3：求人のレコメンド（自然言語で関連を出す）
  - ffmpeg + whisper.cpp + Llama3：AI面接練習と教師へのアドバイス
- 今後、ハロワークと連携して、他大学に広げたい
### レガシーな制御コードへのasyncioの活用事例
- 個人ソフトウェア開発者：独立
- 天文学者
- 天文観測装置制御
  - AIRTReCS（2009～）
    - 大学の教授が使うので、測定しながら改造できるようにマクロタスク
    - 当時は、複数機で計算
    - ⇒AsyncMacroTask：計算機1つのシンプルな構成に対応するために構成変更
### JetBrains
- Java/Laravel歴10年以上。Python歴1年
- 健康保険組合向けの
- Junie：AI開発アシスタント
  - 成功パターンを蓄積
  - guideline.mdでAIにプロジェクトの開発方針をAIに伝えるための設定ファイル

# 【Day 1 Keynote】　Sebastián Ramírez 氏 Behind the scenes of FastAPI and friends for developers and builders(Sebastián Ramírez 氏 開発者とビルダーのためのFastAPIとその仲間の舞台裏)
- フェニックスホール
- 17:55 - 18:55
## FastAPI作者 Sebastián Ramírez 氏のキーノート / 同時通訳あり：ウーパールーパー大好き
## 個人メモ
- FastAPI
  - WebAPI
  - オープンソース
  - かなり最近使用率の順位上げている
- 作者：コロンビア出身でドイツ在住。幼稚園が最終学歴でそれから在宅学習！？ある段階でオンライン学習を受けまくる
  - 様々な仕事オンラインでやる事で、複雑性を理解して、低減する方法を学びました
  - *問題を解決するのが重要と考える*
- まず、必要な物を構築する。必要じゃない物は、作る意味がない。
  - でも、多くは解決済みなので、探して使用すれば良い。
  - でも、学習コストが高いが、？？？
  - 天秤を傾けるのではなく、天秤を壊せ
- ユーザー体験が重要。デザインはUX　first
- Standards
  - つまらないが、あれば便利
- Reduce info duplication(cache invalidation)
  - コードの重複ではなくて、情報の重複が
    - これを無くてして、コードをすっきりさせる
    - 情報を重複させなければ、いけなければ、近くに置いとく。
    - 同じ名前は、付けない。同じのがあれば、長い説明が必要になる。
    - 綺麗で、trim的な文を書く（最小のコードで、最大の利益を得る）
    - Space,graphics,enojis,notes、あらゆるものを使用して、分かりやすくする
    - 一度使ったら、同じ用語を使い続ける（一貫性）
    - コードのスタイルについても同じ型を使用し続けてください
    - まずは、例示を作成してください。例示があれば、デザインもしやすく、チームで説明しやすくなる。
    - 全てのドキュメンテーションは、メンテナンスしろ。誰でも分かるように。
    - 複雑性と抽象性：エンジニアしてる気になるが、無意味に難しくなる
    - 整然としたアーキテクトが必要
      - Types
      - Tests
      - Limit
        - Magic kwargs
        - Import strings
        - Magic string
    - シンプルは複雑より難しい
    - オープンソースは、実際に作業しているのは1人～2人が管理している。ほとんどの場合、1人で対応している。多くても5人。
      - だから、皆さん、優しくその人たちに接してください
      - なるべく自動化する必要がある
      - 日本語は長いと聞いているから、通訳しやすいようにいつもよりゆっくり話しています！？
      - 90%は、ユーザーエラー
        - ほとんど、質問に答える事がコミュニティの支援
      - 多くの人がプルリクエストを行うが、「No」と言えることを学びましょう
        - ほとんどのプルリクエストは、ケーキor子犬で、子犬（面倒見ないといけない未熟者）である
        - そうしないと、無限に仕事が生まれる
        - 1行しか見る必要が無いのに、何千行も対象にしたりするな
        - 機械的に処理しよう
      - どんどんストレス溜まるが、気にしすぎるな
        - 個人の記事や評判
        - 未熟者の相手
        - 迷惑な人々を説明しようと説得しすぎない。有害な人は、遠ざけて入ってこないようにコミュニティを守りましょう。勝手に落ちていきます。
      - 多くの場合、問題の解決だけに注力すれば良い。
      - ポジティブなフィードバックは、記録に残して、嫌な気分の時に読み返しましょう
      - 意外と金にならない。オープンソースは、無料です。
      - 金を受け取った事で、上手くいったという事は、中々聞きません。
      - Bus ticket factor：作者のオープンソースの例え
        - 運転手は、なぜ運転してくれるのか。ただ、乗っているだけでは、いずれどうなるか。
        - 乗っている側も継続するために、なぜ乗っているかを考えてください
-　Q&A 
  - なぜ、その考えになったのか？
    - 新しいのを作るのを避けていたが、機が熟した
  - モチベーションをどうして保てるのか？コミュニティはあるが、Jangoのように大きな組織ではないですよね？
    - ストレスがある。非常に明確にストレスが伝えられるが、他の場所でツール使用者とやりとりをすると、私にとって大きな価値がある。
    - まだ、やりたい事があります。もっと、生んでいくきっかけになる。
    - 最終的に私は、ファンディングを多くオープンソースに持っていきたい。
  - どの課題が重要と見つけるのは、どのようにやるのですか？
    - 一番良いのは、自分にとって、一番イライラさせられる問題。過去に紙が好きという両親に向けて、システムを色んなものを作成しても結局使用してもらっていなかった。無駄な事にこんなに時間をかけてきたんだなとなった。
    - 「他者のために」となると、フィードバッグはその人から来るから、反応が遅くなる。できるだけ、身近な人、自分のために作成する。
  - オープンソースの経済性について。収入源になっていくか。
    - 私たちとしては、開発者がプライべーどを犠牲にして時間を費やしていて、バランスが取れていない。
    - 常にオープンソースにするか、プレミアムにするか悩むことになる。しかし、プレミアムにすると、行動が制限されて、自分の好きな物を作れない。
    - 少しだけ、私たちが使用して働いている会社にプレシャーをかけていく。会社が、どれくらいオープンソースに時間をかけられるかを聞いてほしい。そして、貢献してほしい。オープンソースという物を当たり前だと思わないでほしい。
  - ウーパールーパーは、何か関係あるのか？
    - 「何かマスコットが必要よ！」と手伝ってくれる人が言うから、使用している。実は、コロンビア関係ない生き物です。

# 2日目
# Python×信号処理入門！スペクトログラムで視る音の世界
- ダリア1
- 初学者向け
- 日本語
- 10:20 - 10:50
- 職業は、電機メーカーの機械設計者（普段、実験やシミュレーションをやっている）
## 目次
自己紹介
このトークについて
Pythonで信号処理をするメリット
豊富なライブラリ群との連携
環境構築
音声分析のために知っておくべき基礎知識
録音する
PyAudioによる録音
ビット数とサンプリングレート
フレーム処理による録音
フーリエ変換
時間波形と周波数波形の関係
リアルワールドの波形例
DFTとFFTのPythonコード
NumPyの.fft
スペクトログラムの描き方
スペクトログラムとは？
スペクトログラムの処理手順
スペクトログラムの分解能について
フレームサイズ
オーバラップ処理
色々な音の可視化結果（複数音源）
この音なんでしょう？
この音はどんな要素でできている？
スペクトログラムの応用
## 個人メモ
- 技術ブログ300記事くらいで書籍化の話が来た
- 世の中は「信号」で溢れている（波形のデータに変換できるもの）
  - 「こんなことができるかな？」と思ったことは、大抵Pythonで可能
- 音声分析のために知っておくべき知識
  - PyAudio：Pythonを使って、オーディオの再生・録音が簡単にできる
    - チャンネル数：1=モノラル　2=ステレオ
    - デバイス番号：環境毎にデバイスに番号が振られているはず(0～）
    - format=ビット数指定…ビット数を上げると縦軸の解像度が増える（点が増える）
    - サンプリングレート…横軸
    - フレームサイズ=録音時間（フレーム単位でループを回して、蓄積して録音する）
  - 周波数分析：フーリエ変換（時間波形⇒周波数波形）
    - 逆フーリエ変換（周波数波形⇒時間波形）
    - 複雑な波も単純な波の重ね合わせで表現できる
    - dB（デシベル）変換：実際の音は大きい振幅や小さい振幅が混ざっている
  - スペクトログラム：音声の可視化（見た目サーモグラフィ）
    - 見る人が見れば、これで音が想像できる
    - フレームサイズが大きい：周波数分解能が上がる
    - フレームサイズが小さい：
    - スペクトログラムの分解能について：オーバーラップ率を上げることで時間方向の分解能が上がる＝スペクトログラムを綺麗に見せるための手法
    - CNNの入力データに使用可能（Kaggleでやった事ある）
  - STFT：全体時間波形からフレームを抽出⇒フレーム単位でフーリエ変換⇒スペクトログラムにデータを蓄積
  - 

# 【招待講演】広島から世界へ ― Pythonで描くデータサイエンスの新しい未来
- フェニックスホール
- 日本語
- 11:05 - 11:35
- 広島での高校生向けPython教育の事例を中心に、学びが地域課題解決へと広がる可能性を示し、教育×Pythonから始まる未来を展望します。
- 作者が広島出身で、企業して地元へ。完全、データ分析畑の女性。
## 個人メモ
- 高校におけるデータサイエンス教育
  - 国際的にデータサイエンス能力が遅れているという結果があった。しかし、数学能力が高いが、自分に自信がない。（2013年頃）
  - 2025年に大学入試共通テストで「情報Ⅰ」が必要に
  - 「総合的な探求の時間」：地域orグローバルorデータサイエンスの発表をしてというのを、必修化
  - 3つの不足
    - 指導者の不足：科目毎に先生が存在するが、横断した存在が居ない
    - 指導方法の不足：新領域であるため指導メソッドも無く。
    - 教材の不足：理論や検定は存在するが、ニューラルネットワークとか数年必要になるような物がない。
      - ⇒産学共同で開発
- データサイエンティスト　3つのスキルセット
  - ビジネス力：学習者に「身近」な題材
  - データサイエンス：「理論」を基礎から学ぶ
  - データエンジニアリング：実践しつつ「考える」ものであること
    - 3つのバランスが重要
    - 実際に使用するもので、学習させて興味を持たせたい
      - 例：りんごとミカンの計算とか意味あるか。アイリスのデータセットなんて、何の役に立つのか分からんとか。
- 大学生のリテラシーレベルで、回帰分析・クラスター分析・t検定・カイ二乗検定をやる！？各種統計分析の手計算・Pythonエンジニアリング！？
- 社会人のリテラシーレベルで、数学アレルギーの回避・クロス集計表・回帰分析・クラスター分析！？手計算・Excel計算！？
- データサイエンティスト：女性の割合10％以内
  - アノテーションとか付ける時にジェンダーが問題になっている事例を見かける事がある
- 高校生学習の事例（1日ワークショップ）：鹿のハンター
  - 紙資料（ハンター書き込み）をデータ化
  - なぜPythonを使うかの説明
  - Google Colab
  - サンプルコードを提供するだけ。可視化。
  - ハンターも参加して、発表時にアドバイス
- 女性活躍推進イベント
- 大事なことは、皆が興味をある事で学んでもらう事が重要
  - 広島人は、野球（カープ）が一番
- データサイエンティスト求人は、東京1極集中が問題！！
    
# タスクって今どうなってるの？3.14の新機能 asyncio ps と pstree でasyncioのデバッグを
- ダリア2
- 中級
- 日本語
- 11:50 - 12:20
## 予定稿
Python asyncio と既存のプロファイラの紹介 10分

pyspy
aiomonitor
IDE でのプロファイリング
ps, pstreeの概要 10分

なぜこの機能が生まれたのか
taskの新しい属性「task_awaited_by」
新しいAPI「capture_call_graph」「print_task_call_graph」
ps, pstreeで何ができるのか 10分

Python Web Frameworkとの連携
グローバルバックエンドである anyio / trio における応用可能性
## 自分メモ
- 3.14に追加される
- オーバーロードがない
- 決定的プロファイル
- 使い方：Python3.14rc3
  - 5つのコルーチン関数（例：レストラン）
  - 名前を付けるのが重要
  - asyncio ps
    - 1行目：料理中
    - 2行目：coroutine stack：自分タスクの状態
    - awaiter：完了を待っている別タスクの状態
  - pstree
    - 何をどうみたいかによって使い分ける
- PyCharm：視覚的にどこまで処理できているか見える
- 可能性
  - 時間のかかりすぎるIOを想定
  - 想定外のルート
    - 問題のある個所を特定できる可能性はありそう
    - しかし、気づきにくそう（私は分からん）
- グローバルバックエンドな話

# Lunch
12:20 - 13:20

# Weaponizing MCP Servers: Production-Ready AI Agent Infrastructure with Python(MCP サーバーの武器化: Python を使用した本番環境対応 AI エージェント インフラストラクチャ)
- ダリア2
- 中級
- 英語
- 13:20 - 13:50
## トーク詳細 / Description
MCPサーバーのチュートリアルの多くは、基本的なサンプルの構築方法を紹介していますが、実際のユーザーがサーバーにアクセスし始めたときに何が起こるかまでは説明していません。この講演では、そのギャップを埋め、MCPサーバーを本番環境で運用可能な状態にするためのPythonパターンとアーキテクチャ上の決定事項を紹介します。

まず、MCPサーバーが高負荷時にクラッシュしたり、メモリリークしたり、応答しなくなったりする原因など、よくある障害要因を検証します。次に、大規模環境でも実際に機能する非同期パターン、連鎖的な障害を防ぐエラー処理、サーバーの応答性を維持するためのパフォーマンス最適化など、実用的な解決策を詳しく見ていきます。

カバーされる主要トピック
実稼働対応の非同期パターン:基本的な asyncio を超えて、接続プール、リクエスト キューイング、MCP サーバーがボトルネックになるのを防ぐリソース管理など、現実世界の複雑さを処理するパターンに移行します。

スマートなエラー処理：依存関係に障害が発生した場合でもMCPサーバーを稼働させ続けるための再試行ロジック、サーキットブレーカー、そしてグレースフルデグラデーションを実装します。部分的な障害に対処し、システムの安定性を維持するためのPython固有のテクニックを探求します。

パフォーマンスとメモリの最適化： MCPサーバーのプロファイリング、ボトルネックの特定、そして持続的な負荷への最適化のための実践的な手法。長時間実行されるMCPプロセスのメモリリークを防止し、ガベージコレクションを調整する方法を学びます。

スケーリング戦略：需要の増加に合わせてMCPインフラストラクチャを拡張するための、水平スケーリング、負荷分散、状態管理のパターンを紹介します。毎日数千件ものリクエストを処理する実際のアーキテクチャを検証します。

セキュリティと監視:リクエストの検証、リソース サンドボックス、包括的なログ記録を実装することで、MCP サーバーの動作を可視化し、悪意のあるリクエストから保護します。

実世界のケーススタディ
詳細な例を通して、データ処理ワークフローからAPI統合サービスまで、実際のアプリケーションを支えるMCPサーバーを検証します。それぞれのサーバーが直面した具体的な課題と、それらを解決したPythonソリューションをご紹介します。

ライブデバッグセッション
障害が発生した MCP サーバーをリアルタイムでデバッグし、問題を特定し、修正を実装し、Python プロファイリングおよび監視ツールを使用して改善を確認する方法を紹介します。

この講演は、単なる例題にとどまらず、実際のワークロードに対応できるMCPインフラストラクチャを構築したいPython開発者を対象としています。実戦で実証されたパターン、実用的なデバッグ手法、そしてプロトタイプから本番環境へのMCPサーバーのスケールアップに向けた明確なロードマップを習得できます。

講演概要（合計30分）
オープニング: MCP サーバーが故障した場合 (3 分)
ライブ障害デモ:
現実のギャップ:チュートリアル用 MCP サーバーが実際の使用に耐えられない理由
一般的な障害パターン:メモリリーク、接続枯渇、未処理のエラー
これらの問題を解決する実用的なパターン
パート 1: 実際に機能する非同期パターン (8 分)
基本的な非同期IOを超えて
接続管理:リソースを漏らさない接続プールの構築
リクエストキューイング:ブロッキングなしで同時エージェントリクエストを処理する
リソース制限:セマフォとガードを使用してリソース枯渇を防ぐ
コードの深掘り  
# Robust async patterns for stable MCP servers
# Connection pooling with proper cleanup
# Request batching and intelligent queuing
パフォーマンスの改善
メトリクスの前後比較:応答時間とメモリ使用量の比較
プロファイリングツール: Python ツールを使用して非同期ボトルネックを特定する
パート2: エラー処理と回復 (7分)
スマートな再試行パターン
サーキットブレーカーの実装: MCP ネットワークにおける連鎖障害の防止
指数バックオフ:障害が発生したサービスに負担をかけないインテリジェントな再試行戦略
グレースフルデグラデーション:依存関係が失敗したときにも MCP サーバーを機能させ続ける
メモリ管理
リーク検出:長時間実行される MCP プロセスにおけるメモリリークの特定と修正
リソースのクリーンアップ:適切な非同期コンテキスト管理とリソースの破棄
GC 最適化:安定したパフォーマンスを実現するためのガベージコレクションのチューニング
ライブデバッグセッション
実際の問題解決: Python プロファイリングツールで障害が発生した MCP サーバーのデバッグ
監視統合: MCP サーバーに監視機能を追加して本番環境の可視性を高める
パート3: スケーリングとアーキテクチャパターン (8分)
水平スケーリング戦略
負荷分散:エージェント要求を複数の MCP サーバーインスタンスに分散する
状態管理:サーバー間でのセッションデータと共有リソースの処理
ヘルスモニタリング:ヘルスチェックと自動フェイルオーバーの実装
ケーススタディ: 実際の MCP インフラストラクチャ
課題:プロトタイプから毎日数千件のリクエストを処理する規模まで拡張
アーキテクチャ:負荷分散と監視を備えたマルチサーバー構成
学んだ教訓:何がうまくいったか、何が失敗したか、そして重要なアーキテクチャ上の決定
セキュリティと検証
入力サニタイズ:悪意のあるエージェントのリクエストから MCP サーバーを保護する
リソースサンドボックス:エージェントのシステムリソースへのアクセスを安全に制限する
監査ログ:デバッグとコンプライアンスのためにエージェントのアクションを追跡します
パート4: 実際のアプリケーションと次のステップ (3分)
生産例
データ処理パイプライン:バッチ処理リクエストを処理するMCPサーバー
API統合サービス: AIエージェントの外部API呼び出しの管理
ファイル管理システム:適切なアクセス制御による安全なファイル操作
即時対応項目
評価チェックリスト:現在の MCP サーバーの実稼働準備状況を評価する
実装ロードマップ:最大の効果を得るために最初に実装するパターン
ツールとリソース: MCP 開発用の Python ライブラリと監視ソリューション
締めくくり: MCP 制作の旅 (1 分)
キーパターン:信頼性の高い MCP サーバーに不可欠なアーキテクチャ上の決定
よくある落とし穴: MCP インフラストラクチャを拡張する際に避けるべき間違い
コミュニティ リソース: MCP 開発へのサポートや貢献を得る場所
## 個人メモ
- AVテスト

# Streamlit は社内ツールだけじゃない！PoCの速さで実現する"商用品質"の分析SaaSアーキテクチャ
- ダリア1
- 中級
- 日本語
- 14:05 - 14:35
## トーク詳細 / Description
イントロダクション

自己紹介
顧客の強いデータ活用ニーズと「2 週間リリース」の背景
Streamlit の爆速 PoC を 商用品質 に高めるミッション
堅牢性 & セキュリティ

例外握りつぶし問題：Decorator で捕捉し安全なエラー表示
WebSocket × Cookie の罠：JWT 検証 Decorator で毎リクエスト再チェック
分析基盤 & パフォーマンス

S3 → Firehose → Athena → awswrangler
SessionState キャッシュによる Athena コスト削減
品質保証 & CI/CD

型安全ファースト：mypy／pyright と Result 型でバグ未然防止
Streamlit Testing API を用いたヘッドレステストを自動化（pytest-xdist 併用）
Jsonnet + GitHub Actions → ECS Fargate：環境差分のないワンコマンドデプロイ
ビジネスインパクト & 学び

公開初日で顧客 10 社 が即利用、データドリブン施策が加速
PoC の速さ × SaaS の品質 を両立する設計Tips
まとめ & Q&A

発表内容のサマリー（持ち帰ってほしいこと）
質疑応答

# PythonとLLMで挑む、4コマ漫画の構造化データ化
- ラン
- 初級
- 日本語
- 14:50 - 15:20
## トーク詳細 / Description
イントロダクション：なぜ 4 コマ漫画なのか？

4 コマ漫画は「画像」「テキスト」「連続性」が凝縮された、非構造化データ処理の格好の題材
最終目標：単行本をスキャンするだけで、コマ、登場人物、セリフ、状況を構造化し、検索・分析可能なデータベースを構築する
アプローチの変遷：LLM 以前の格闘

フェーズ 1: 人力とスプレッドシートの時代
手動でのデータ入力と管理の限界
フェーズ 2: Python と深層学習（DL）による挑戦
コマの自動切り出し（物体検出: YOLO など）
セリフの OCR（Tesseract, Google VisionAPI など）
登場人物の検出（物体検出）
課題：各コンポーネントの連携が難しく、精度も限定的。修正のための UI（アノテーション画面）開発コストが高い。
LLM の衝撃と現実：Gemini 登場で何が変わったか？

期待：「LLM に画像を投げるだけで全部解決！」
セリフ抽出：驚異的な精度。従来の OCR を凌駕。
状況説明・構図の理解：人間のように自然言語で説明を生成。
現実の壁：LLM だけでは越えられない課題
人物座標の曖昧さ：LLM は「左の人物」とは分かっても、正確なバウンディングボックスを返せない。
人物識別の低精度：「A というキャラ」と「B というキャラ」を安定して見分けるのは困難。
話者同定の難しさ：どのセリフを誰が話しているのか、吹き出しと人物の関連付けができない。
ハイブリッド・アプローチ：LLM と Python エコシステムの協調

適材適所な役割分担
LLM (Gemini)：
役割：意味理解、文脈判断、自然言語生成（セリフ、状況説明）
Python/DL (YOLO, DINOv2 など)：
役割：精密な空間認識（コマ、人物、吹き出しの正確な座標検出）
役割：特徴量ベースの識別（顔認識による人物識別）
具体的なパイプライン
コマ切り出し: YOLO で 4 つのコマを正確に検出・切り出し。
並列処理: 各コマ画像を LLM と DL モデルに同時に投入。
LLM → セリフと状況説明を JSON で出力。
DL → 人物と吹き出しの座標リストを出力。 (WIP)3. データ統合: Python スクリプトが、座標情報を元に「どの吹き出しが、どの人物に最も近いか」を計算し、話者を同定。 (WIP)4. 最終構造化データ: 全ての情報を統合して出力。
開発の加速：AI エージェントは最強のペアプログラマー

品質と開発速度の向上
Human-in-the-Loop UI の高速開発: 「検出結果をすぐに確認・修正できる WebUI を作って」と指示するだけで、Flask や FastAPI ベースのツールを自動生成。
LLMとの連携によって開発速度が圧倒的に向上すると、確認のためのツールもそれに追いつく便利さが必要
Colab 学習ノートブックの自動生成: モデルの学習やファインチューニングに必要なコードを対話的に生成。
レガシーコードのモダン化: 煩雑な Python スクリプト群の統合や、ライブラリのアップデートを支援。
プロンプト改善: より良い結果を得るためのプロンプトエンジニアリングを支援する UI の作成。
まとめと今後の展望

LLM は万能ではない。しかし、既存の Python エコシステムと組み合わせることで、これまで不可能だったレベルのデータ構造化が実現可能になる。
「自動化（LLM/DL）」と「人間による確認・修正（UI/UX）」のサイクルをいかに効率的に回すかが、実用的なシステムの鍵。
AI エージェントの活用は、この開発サイクルを劇的に加速させる。
今後の挑戦：動画、音声など、他の非構造化データへの応用。

# Day 2 Poster Session
サクラ
15:20 - 16:05

# Day 2 Lightning Talks
- フェニックスホール
- 16:05 - 16:50

# 【Day 2 Keynote】　プログラミングの未来を駆ける！~2年間の挑戦が見せてくれた、プログラミングのこれから~
- フェニックスホール
- 17:00 - 18:00
- 「生成AIに育てられた第一世代」を掲げ、大学４年時にChatGPTを武器に100日で100本のアプリを公開する“#100日チャレンジ”を完遂。
