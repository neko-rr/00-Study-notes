# PyCon JP 2025参加メモ
- 公式HP[https://2025.pycon.jp/ja](https://2025.pycon.jp/ja)
- 参加日：2025年9月26日（金）・9月27日（土）
- 参加形態：個人参加（プライベート）
- 聴講セッション数：13個（各30分）、2個（各60分）
# 総括
　データ分析者や機械学習をする人は、何らかの簡易Webフレームワークを使用して説明・デモ用のHPを作れるのは必須技能のように感じました。講演者に質問もしましたが、どのWebフレームワークでも目的は同じで作成する難易度や使用感はあまり大差無いとの事でした。簡単な1機能程度ならば、商用利用にも使用できるレベルでPythonだけで作成できます。プライベートの参加でしたが、仕事でも使用できると感じました。見た目にこだわる人には、ExcelよりもWebの方が恐らく抵抗が無いと考えます。  
　プライベート使用想定でのCopilot出力の比較表を下記に記載。
## 個人ブログ向け：Python Webフレームワーク比較表(2025/9/29 Copilot出力)
| 観点 | Streamlit | Dash | Gradio | Panel | ReactPy | Voila |
|------|-----------|------|--------|--------|----------|--------|
| **開発のしやすさ** | ◎ 初心者向け | ○ 柔軟だが複雑 | ◎ 超簡単 | ○ 柔軟だがやや複雑 | △ React知識が必要 | ○ Jupyterベース |
| **デザイン自由度** | △ 自動レイアウト | ◎ CSS/HTML自由 | △ 固定UI中心 | ◎ レイアウト自由 | ◎ React風に自由 | △ Jupyter依存 |
| **複数ページ対応** | △ 限定的 | ◎ ルーティング可能 | △ 単一ページ中心 | ◎ タブ・ルーティング可能 | ◎ React風ルーティング | △ Notebook単位 |
| **ブログとの統合性** | ◎ iframeで簡単 | ◎ 同様に可能 | ◎ iframeで簡単 | ◎ iframe可能 | ○ iframe可能 | ○ iframe可能 |
| **長期メンテナンス性** | ◎ シンプルで保守しやすい | ○ 柔軟だが複雑化しやすい | ◎ 簡単で保守しやすい | ○ 柔軟だが構成が複雑 | △ React知識が必要 | ○ Notebook管理が必要 |
| **ホスティングの簡便さ** | ◎ Streamlit Cloud | ○ Render等 | ◎ Hugging Face Spaces | ○ Panel Server等 | ○ FastAPI等と併用 | ○ Binder等 |
| **SEOやブログ連携** | △ JSベースでSEO弱め | △ 同様 | △ iframe前提 | △ 同様 | △ 同様 | △ 同様 |
| **コミュニティの充実度** | ◎ 活発・資料豊富 | ◎ 活発・Plotly支援あり | ○ 急成長中 | ○ Bokeh系で安定 | △ 小規模 | ○ Jupyter系で安定 |
| **学習コスト** | ◎ 低い | ○ 中程度 | ◎ 非常に低い | ○ 中程度 | △ 高め（React知識） | ○ Jupyter経験あれば低 |
| **開始時期** | 2019年 | 2017年 | 2021年 | 2019年 | 2022年 | 2018年 |

　データ分析に関しては、講演を聴講して中級レベルでも基本的な内容や仕組みは理解できている事が初カンファレンスに参加して分かりました。自身に足りていないと感じたのは、ビジネスに繋げたり、分析対象と解決課題を設定をする発想です。商用利用の完成品しか普段目にしないため大きく考えすぎているようで、趣味的な物でも実務と多少共通点がある事が分かりました。現在、仕事ではPython使用できないため、趣味に全振りしてOutputを増やしていこうと考えています。
# 1日目(9/26)
## 【招待講演】PEP 750 の共同著者 青野高大 氏による Python3.14の新機能の紹介
- 日本語
- 10:30 - 11:00
- 青野　高大
### 講演資料[(https://github.com/koxudaxi/pyconjp_2025.git)](https://github.com/koxudaxi/pyconjp_2025.git)
### 公式事前説明
Python 3.14 には新機能 t-strings（Template Strings）が導入されます。青野さんは、この仕様をまとめた PEP 750 の共同著者です。
Python 3.14 の最終リリースは 2025 年 10 月に予定されています。青野さんは、OpenAPI／JSON Schema から型安全なコードを生成する datamodel-code-generator や、Ruff・Pydantic 向けの PyCharm プラグイン など、現場で役立つ OSS を数多く開発されています。PyCon US や EuroPython など国際カンファレンスでの登壇実績も豊富です。
Python の文字列機能は、% 演算子、str.format()、f-strings と発展してきました。次の一歩となる t-strings が、あるいは将来の Python が、どんな世界を作ろうとしているのか。私自身もお話を伺うのを楽しみにしています。どうぞご期待ください。
### 個人メモ
- 25/10/7リリース
- 19個新しい機能あり
- 型のアノテーション遅延評価がデフォルトになった（PEP649）
  - 関連して（PEP749）でAPIを提供。
  - 従来の型整理のAPIとか利用していたら動作確認した方が良い
- GIL撤廃構成の正式サポート（PEP797）
- 最近リリースしたサブインタプリタ用のAPIが無かったので作成した（PEP???)
- Tsil-calling Interpreter（実験的なもの。他の言語でも使用しているから、速度が向上するだろうと採用）
- リモートデバッグ接続の安全化(PEP768)
- JIT（実験的な物。高速になる時もならない時もある）
- コードの視認性を向上（配色とか）

- 文字列フォーマットの進化
  - "%s"
  - "
  - f
  - 【例1】理由：SQLやHTMLに値を直埋めすると、SQLインジェクション対策⇒f-string（危険）
    - 安全：t-string + psycopg3：安全なSQLオブジェクトへ変換
  - 【例2】手動エスケープ
    - 安全：
  - 【例3】構造化ログのユースケース
    - 式テキストとフォーマットが残る
  - 【例4】テンプレートの応用：メール通知・設定
  - 内部構造：
    - f-string：即時文字化
    - t-string：一度テンプレート化（コンテナ）。連結は、テンプレート＋Templateのみ：セキュリティ的な理由から。
  - テンプレート自体は何もしない、後でコンテナとして活用できる。
    - 遅延評価すると、かなり複雑になるため、Pythonユーザーの属性（初心者多い）を考えて、即時反映にした。

- まとめ
  - セキュリティ：SQLインジェクションやXSSを防止

## Pythonic Finance: Analyze Company Fundamentals with SEC EDGAR APIs(Python ファイナンス: SEC EDGAR API で企業の基礎情報を分析)
- 初級
- 英語
- 11:15 - 11:45
### 講演資料GitHub[https://github.com/lauslim12/analyze-company-fundamentals-with-sec-edgar-api.git](https://github.com/lauslim12/analyze-company-fundamentals-with-sec-edgar-api.git)
### 公式事前説明
Pythonと定量分析を用いて、米国証券取引委員会（SEC）EDGARシステムのファンダメンタル財務データにアクセスし、検証・分析します。SECのJSON APIは、財務報告の国際標準であるeXtensible Business Reporting Language（XBRL）で報告された企業提出書類から抽出された構造化された財務データを提供します。堅牢なデータ検証にはPydanticが用いられます。
参加者は、XBRL 言語の概要、SEC EDGAR の API からデータを取得するための実践的なテクニックcompanyfacts、データ サイエンスとソフトウェア エンジニアリングを組み合わせて Pydantic でデータを検証する方法、API 応答から重要な基本指標を抽出する方法、基本的な財務比率を計算する方法、財務トレンドを視覚化する方法について学習し、国際的な公開財務データ API の操作の詳細について学ぶことができます。
### 個人メモ
- 10Kレポートと20Kレポートがある。
- どちらも年次報告書
- 10Kは、アメリカ企業に提供義務あり。会社向け

- Company Facts API　困難
- 普通の財務用語説明
- WEBスクレイピング

- Google Colab使用
- jsonデータ（API)⇒表に変換⇒グラフ化
  - これなら、私も発表できそう。

## ReactPyを使ってreact likeにUIをPythonで実装する
- 中級
- 日本語
- 12:00 - 12:30
- モノタロウ勤務
### 公式事前説明
1. ReactPyとは何か？
「フロントエンド苦手だけど、こんなのあったら便利だよね」な話
JavaScript書かずにReactっぽいことがPythonでできる
HTMLテンプレートよりもっと柔軟にUIが作れる
ReactPyの特徴を簡単に紹介
Reactのコンポーネント思想をPythonで実現
Python慣れしている人には親しみやすい書き方
2. ReactPyの強みとフロントエンド構築ツールとしての位置づけ
ReactPyの独自の強み
既存のWebアプリケーションに自然に組み込める
Pythonの豊富なライブラリエコシステムとの親和性
ReactPyの技術的特徴
Virtual DOM的な仕組み
状態管理の仕組み
3. ReactPyの導入方法と実践活用
ReactPy単体での使用方法
FastAPI、Flaskなど様々なバックエンドとの組み合わせ
新規プロジェクトでの始め方
既存プロジェクトへの導入パターン
段階的導入戦略（一部のページから始める）
reactpy-djangoを使った既存Djangoプロジェクトでの活用例
実装デモとコード例
従来のHTMLテンプレートとの比較
ReactPyで実装した動的コンポーネントの例

### 個人メモ
- モノタロウ：Reactによる画面開発（ReactPyは、使用してない）。AI工藤開発も積極的にやっている。
- ReactPy：UI構築ツール
  - 他にもStreamlit、Dash、Gradio、Panelと同じ立ち位置
  - PythonでReactのように使用する
  - コンポーネント定義を組み合わせて、画面構築する
  - 実行自体は、Pythonをそのまま実行
  - いくつかバックエンドが採用されていて、それで動く
  - 【メリット】学習コスト削減：JavaScript/TypeScript/等
     - 既存のWebAPIと統合しやすい
     - FastAPI等サポートしている
     - 既存のWebページへの埋め込みが可能
     - JupyterやPlotly-Dashとの公式統合：データサイエンス分野での活用が明確に意図されている
     - サーバーサイドアーキテクチャ：全ての処理がサーバーで実行される（状態管理：画面遷移が簡単にコントロール可能）
       - Pythonエコシステムの直接活用
       - デメリットは、全てサーバーに集中するので、遅くなる
         - VDOM実装：差分だけを
     - WebSocket通信による同期（リアルタイムで同期される）
     - asyncio基盤の非同期処理
     - 統一された状態管理：フロントエンドとバックエンドで状態の分離がない
       
- 【活用例】データ分析ダッシュボード、
- 既存プロジェクトに導入する場合
  - 例：DjangoアプリにReactPyを導入するためのツール
    
   
     - サーバーサイド実行の利点
  
- コンポーネント思想：再利用可能な部品：UIを独立した部品（コンポーネント）として設計
- 関心の分離：各コンポーネントが独自の状態とロジックを持つ
- 組み合わせによる構築：小さなコンポーネントを組み合わせる

- Pythonらしい書き方：コンポーネント宣言は
- 繰り返し処理はｍリスト内包
- スタイルの指定にPythonの辞書を利用できます（Tail？？も使用できる）

## 明日からgraphlib、みんなで使おう
- 中級
- 日本語
- 13:30 - 14:00
- 東京ガスの人（Goldスポンサー企業）・オライリージャパンの翻訳や監修者
### 公式事前説明
導入：
Python 3.9で標準ライブラリにgraphlibが追加されました。
しかし、公式ドキュメントにはgraphlibが導入されたモチベーションや利用例に乏しく、すでにトポロジカルソートの存在を知っている人しか使えないライブラリになっています。
結局、graphlibは何に使えるのか、電池が液漏れする前に（なるべく）すべて解説します。

グラフ理論速習：
graphとは数学のグラフ理論におけるグラフを意味します。
グラフとは（大雑把に説明すれば）物事とその関係性を数学的にモデル化したものであり、鉄道網における駅と線路、人間関係における人間と友人関係など、日常生活においてグラフでモデル化できるものはたくさんあります。

グラフとは：
無向グラフと有向グラフ（今回扱うのは有向グラフ）
線型順序について（半順序関係、全順序関係）
トポロジカルソート、有向非巡回グラフ（DAG）について
任意のグラフがトポロジカルソートできるわけではありません。
グラフが有向非巡回グラフであることと、グラフがトポロジカルソート可能であることは同義であることを説明します。

有向非巡回グラフの定義：
トポロジカルソートの定義
グラフが有向非巡回グラフであることと、グラフがトポロジカルソート可能であることは同義
graphlibの使い方
ここまで理解できれば、明日からgraphlibを使えるようになります。
少なくとも、頭の片隅にgraphlibが入り、必要になった瞬間に思い出せるようになります。

graphlibの使い方：
応用例: タスクの処理（タスク処理順序の決定、簡易的なタスクランナーの実装）
### 個人メモ
- （ぐらふぃりぶ）読み
- トポロジカルソート：有向非巡回グラフ：G＝(V,E）。閉路を含まない物。
  - 二項関係：
  - 半順序関係：反射率、反対称率、
  - 線型順序
  - 歩道：グラフG＝(V,E)の頂点からへの長さの
  - 道：グラフGの歩道W。特に閉じた道を「閉路」と言う。
    - いい感じに言うと、有向グラフの頂点をいい感じに順序付けしたもの
  
- グラフ定義：無向グラフ（非順序対）・有向グラフ（順序対）
  - 「関係」を数学的にモデル化したもの
  - 「もの」は、人間、駅、タスク、サーバー
  - 「関係」は、人間関係、線路、依存関係

- 命題（トポロジカルソート可能）：有向グラフGが
  - 有向非巡回グラフ（必要十分条件）⇒トポロジカルソート可能　※証明がアルゴリズムになっていることに注意

- 活用例
  - タスク順序
 
- garphlib：トポロジカルソートが実装された標準ライブラリ
  - 簡易的に利用すると、実行順序を決定する仕組みとして使える
  - タスクランナー：並列実行しやすいアルゴリズム
  - 最適解とは、別問題！？最適解にするには、また別の仕組みが必要

## Beyond Multiprocessing: A Real-World ML Workload Speedup with Python 3.13+ Free-Threading(マルチプロセスを超えて: Python 3.13+ のフリースレッドによる実際の ML ワークロードの高速化)
- 中級
- 英語
- 14:15 - 14:45
### 講演資料[https://speakerdeck.com/kitsuya0828/beyond-multiprocessing-a-real-world-ml-workload-speedup-with-python-3-dot-13-plus-free-threading](https://speakerdeck.com/kitsuya0828/beyond-multiprocessing-a-real-world-ml-workload-speedup-with-python-3-dot-13-plus-free-threading)
### 公式事前説明
PyCon JP 2024では、実験的なフリースレッドモードの素晴らしい導入を目にしました。あれから1年が経ちましたが、実際にこのモードを使って実世界の問題を解決した人はどれくらいいるでしょうか？マルチプロセスのシリアル化ボトルネックに既に悩まされている方、あるいはデータ量の多いタスクが思ったほど速くないことに不満を感じている方、この講演はまさにうってつけです。

風景は変化している
Python 3.13 でのフリースレッドの初期リリースでは、シングルスレッドパフォーマンスのトレードオフが知られていましたが、状況は変化しています。この問題を軽減し、並列ワークロードにおいてフリースレッドをこれまで以上に強力で現実的な選択肢にする Python 3.14 の重要な改善点について詳しく説明します。

理論から実戦で実証されたプレイブックへ
このセッションでは、コアコンセプトから実際のアプリケーションまで、実践で実証されたプレイブックをご紹介します。データ集約型研究分野を加速させるためのオープンソースフレームワークの開発経験を活かし、以下の点について解説します。

フリースレッディングの「なぜ」と「どうやって」：まず、Pythonの新しい並列実行モデルの基礎を理解しましょう。マルチプロセス処理がデータ集約型のタスクで苦労する理由と、フリースレッディングがどのようにして洗練された組み込みソリューションを提供するのかを説明します。

ハードデータを用いた実世界のケーススタディ：次に、 Federated Learningの実世界プロジェクトを詳しく見ていきます。フリースレッディングによって重大なパフォーマンスボトルネックが解消されました。ベンチマークでは、マルチプロセスやRayのような既存のフレームワークと比較して、フリースレッディングの劇的なスループット向上が示されています。

ライブリファクタリングとベストプラクティス：最後に、ライブデモで、低速なデータパイプラインが高性能アプリケーションへと変貌していく様子をご覧ください。実践的なプレイブックと、競合状態などのよくある落とし穴を回避しながら、これらのテクニックを自信を持って適用できるようになります。

この強力な新しいPython が要求の厳しい ML ワークロードとどのように統合され、新しいレベルのパフォーマンスを実現し、コードを真に強化できるかを一緒に見ていきましょう。

### 個人メモ
英語と内容の難しさで分からん。
GILの事

## Django NinjaによるAPI開発の効率化とリプレースの実践
### 講演資料[[https://speakerdeck.com/kashewnuts/django-ninja-pyconjp2025?slide=4](https://speakerdeck.com/kashewnuts/django-ninja-pyconjp2025?slide=4)
### 公式事前説明
比較検討した選択肢（独自実装・DRF・FastAPIなど）
パフォーマンス、学習コスト、開発効率、保守性の観点からの選定理由
Django Ninjaを用いた実践例

型ヒントで定義するリクエスト・レスポンススキーマ
自動生成されるOpenAPIドキュメントの活用
認証・認可（API Key, JWT など）の実装方法
スロットリングやページネーションの設計
テスト戦略（ユニット・統合テスト）
段階的なリプレース戦略

既存の独自実装との共存
互換性維持の工夫
移行計画と影響範囲のコントロール
まとめとQ&A

得られた効果と課題
今後の展望（型安全な開発・APIクライアント自動生成など）

### 個人メモ
- 過去django-piston⇒独自実装（サポート切れで）⇒文脈負債
- 要件：型＝ドキュメントの一元管理＆自動化
  - 既存Djangoアプリに最小の影響で導入
  - V1とV2の共存
- django-ninjaの選定理由
  - FastAPIに強く影響を受けたDjangoのREST API
- 【比較】
  - FastAPI
    - メリット：高速でシンプル
    - 一貫した非同期実行が可能（DB接続含む）
    - 型ヒント（Pydantic）を活用したデータ検証＆整形
    - デメリット：Djangoとの親和性が低い
    - ひと手間必要
  - DRF
    - メリット
    - RESTのリソースとDjango Modelが1対1の場合、CRUDを作るのが簡単
    - デメリット：フレームワークが想定していない使い方をすると実装が複雑化する
    - 型ヒント活用が標準では弱い
    - ドキュメントを充実させるためには記述が膨れていく

  - django-ninjaの主要機能
  - OpenAPIドキュメントの自動生成
    - 実装とドキュメントをSqagger UI
    - スキーマ定義を充実させてOpenAPIドキュメントと連携（動いているコードがそのままドキュメント化可能）
      - 開発の動作確認で使いやすい
    - SwafferUIとRedocの使い分け
  - API開発・認証がしやすい
  - ページネーション
  - スロットリング（最近v1.2.0で同梱された）・IPやユーザー単位で使い分け可能
  - モジュール分割（Routerを活用）
    - APIを追加するには、各アプリの
    - NinjaAPIクラスの代わりにRouterを使用
    - 全Routerをimportし、メインのNinjaAPIに取り込む
  - APIのバージョン管理
  - 例外ハンドリング
  - デコレーターの活用
  - CORS対応
  - Appendix：クラスベースでの対応：サードパーティ活用で対応可能
- テスト方法
  - 個人的には、PyTest +
- 懸念事項
  - コミュニティ成熟度（若い）
    - Ninja自体のサードパーティは少ないが、必要な機能は揃っていた
    - 依存しすぎない。
- 移行方法
- 副次的な効果
  - ファットコントローラー気味⇒ビジネスロジックの呼び出しがすっきり
- 結果：開発効率が上がり、

## OSS≒盆栽 〜個人的趣味として無理なくOSS開発をするときに意識したいこと〜
- 中級
- 日本語
- 16:15 - 16:45
- ニジボックス(仕事中にこのスライドを作成した) の人：Sphinx大好きの人
### 講演資料[https://slides.attakei.net/pyconjp-2025/](https://slides.attakei.net/pyconjp-2025/)
### 公式事前説明
- 予定アウトライン
- 自己紹介
- 「OSS≒盆栽」とは？
- Pythonライブラリにおける利用者規模
- 個人的活動でOSS開発をするということ
- 無理をしないための考え方
  - (下記は予定している一部)
  - 多くの人が使うことを想定しない
  - 機械的に行えることは機械的に
- sphinx-revealjsによる事例
- プロダクトソースコード上の変化
- 開発する基盤に起きた変化
- 周囲にある環境で起こっていた変化
### 個人メモ
- 鑑賞趣味としての盆栽≒個人OSS開発
  - 小さな目標から始められる
  - 意外とランニングコストが低い
- 【影響】
  - GitHubのスターなどが多い⇒大変やから、ここは目指さない。自然となれたら良いなくらい。
- 【趣味の個人OSS開発】
  - 程よい開発経験を得られる：上流から下流まで一通り
  - 失敗しても誰も困らない（周りに迷惑がかからない）
  - PyPIに公開するまでは、大分楽になった
- 【無理をしないための考え方＝本当に頑張るべきところ以外頑張らない】
  - 単機能なものを作る（未完成な多機能より完成済み単機能）
    - 達成感を得るのが遅くなる
    - 使う側もシンプルで分かりやすい（例：qrcode：QRコードを作成するだけ）
    - よくある例：
  - 「自分が普段遣いする」ためのライブライを作る
    - 「欲しいけど見つからない」は、大事なモチベーションの源泉
    - 自分で作成すると、自分で使用したくなり、結果メンテナンスもする事になる
- 機能の担保にこだわらない
  - 精緻なユニットテストを書いておけるのは望ましいのだが、ここにリソースを取られると疲れてしまう。
    - リンターやフォーマッターは導入した方よい。
    - 困ったら、Ruffに全てを委ねよう
- なるべくさっさと公開する
  - 「PyPIにあるか？」は、それなりに重要
  - 数人でも使用してくれたら、有難い
- 「型」を作っておく

## Day 1 Lightning Talks:皆さんから募集するライトニング・トーク (略してLT。5分以内の短い講演)
- 17:00 - 17:45
### 個人メモ
#### OWGeoの宣伝
- 地理空間情報
- 実世界での利用例：スマホの地図アプリ、ハザードマップ、配達経路最適化
- 座標系の世界：緯度経度だけじゃない
- ライブラリ：pyproj,py:早すぎて1枚目スクショ撮れず
#### キャリアボット
- 研究室でのPython活用事例
  - テーマ：人間とAIの共創
  - Streamlit + Python + Gemma3：求人のレコメンド（自然言語で関連を出す）
  - ffmpeg + whisper.cpp + Llama3：AI面接練習と教師へのアドバイス
- 今後、ハロワークと連携して、他大学に広げたい
#### レガシーな制御コードへのasyncioの活用事例
- 個人ソフトウェア開発者：独立
- 天文学者
- 天文観測装置制御
  - AIRTReCS（2009～）
    - 大学の教授が使うので、測定しながら改造できるようにマクロタスク
    - 当時は、複数機で計算
    - ⇒AsyncMacroTask：計算機1つのシンプルな構成に対応するために構成変更
#### JetBrains
- Java/Laravel歴10年以上。Python歴1年
- 健康保険組合向けの
- Junie：AI開発アシスタント
  - 成功パターンを蓄積
  - guideline.mdでAIにプロジェクトの開発方針をAIに伝えるための設定ファイル

## 【Day 1 Keynote】　Sebastián Ramírez 氏 Behind the scenes of FastAPI and friends for developers and builders(Sebastián Ramírez 氏 開発者とビルダーのためのFastAPIとその仲間の舞台裏)
- 17:55 - 18:55
- FastAPI作者 Sebastián Ramírez 氏のキーノート / 同時通訳あり
### 個人メモ
- FastAPI
  - WebAPI
  - オープンソース
  - かなり最近使用率の順位上げている
- 作者：コロンビア出身でドイツ在住。幼稚園が最終学歴でそれから在宅学習！？ある段階でオンライン学習を受けまくる
  - 様々な仕事オンラインでやる事で、複雑性を理解して、低減する方法を学びました
  - *問題を解決するのが重要と考える*
- まず、必要な物を構築する。必要じゃない物は、作る意味がない。
  - でも、多くは解決済みなので、探して使用すれば良い。
  - でも、学習コストが高いが、？？？
  - 天秤を傾けるのではなく、天秤を壊せ
- ユーザー体験が重要。デザインはUX　first
- Standards
  - つまらないが、あれば便利
- Reduce info duplication(cache invalidation)
  - コードの重複ではなくて、情報の重複が
    - これを無くてして、コードをすっきりさせる
    - 情報を重複させなければ、いけなければ、近くに置いとく。
    - 同じ名前は、付けない。同じのがあれば、長い説明が必要になる。
    - 綺麗で、trim的な文を書く（最小のコードで、最大の利益を得る）
    - Space,graphics,enojis,notes、あらゆるものを使用して、分かりやすくする
    - 一度使ったら、同じ用語を使い続ける（一貫性）
    - コードのスタイルについても同じ型を使用し続けてください
    - まずは、例示を作成してください。例示があれば、デザインもしやすく、チームで説明しやすくなる。
    - 全てのドキュメンテーションは、メンテナンスしろ。誰でも分かるように。
    - 複雑性と抽象性：エンジニアしてる気になるが、無意味に難しくなる
    - 整然としたアーキテクトが必要
      - Types
      - Tests
      - Limit
        - Magic kwargs
        - Import strings
        - Magic string
    - シンプルは複雑より難しい
    - オープンソースは、実際に作業しているのは1人～2人が管理している。ほとんどの場合、1人で対応している。多くても5人。
      - だから、皆さん、優しくその人たちに接してください
      - なるべく自動化する必要がある
      - 日本語は長いと聞いているから、通訳しやすいようにいつもよりゆっくり話しています！？
      - 90%は、ユーザーエラー
        - ほとんど、質問に答える事がコミュニティの支援
      - 多くの人がプルリクエストを行うが、「No」と言えることを学びましょう
        - ほとんどのプルリクエストは、ケーキor子犬で、子犬（面倒見ないといけない未熟者）である
        - そうしないと、無限に仕事が生まれる
        - 1行しか見る必要が無いのに、何千行も対象にしたりするな
        - 機械的に処理しよう
      - どんどんストレス溜まるが、気にしすぎるな
        - 個人の記事や評判
        - 未熟者の相手
        - 迷惑な人々を説明しようと説得しすぎない。有害な人は、遠ざけて入ってこないようにコミュニティを守りましょう。勝手に落ちていきます。
      - 多くの場合、問題の解決だけに注力すれば良い。
      - ポジティブなフィードバックは、記録に残して、嫌な気分の時に読み返しましょう
      - 意外と金にならない。オープンソースは、無料です。
      - 金を受け取った事で、上手くいったという事は、中々聞きません。
      - Bus ticket factor：作者のオープンソースの例え
        - 運転手は、なぜ運転してくれるのか。ただ、乗っているだけでは、いずれどうなるか。
        - 乗っている側も継続するために、なぜ乗っているかを考えてください
-　Q&A 
  - なぜ、その考えになったのか？
    - 新しいのを作るのを避けていたが、機が熟した
  - モチベーションをどうして保てるのか？コミュニティはあるが、Jangoのように大きな組織ではないですよね？
    - ストレスがある。非常に明確にストレスが伝えられるが、他の場所でツール使用者とやりとりをすると、私にとって大きな価値がある。
    - まだ、やりたい事があります。もっと、生んでいくきっかけになる。
    - 最終的に私は、ファンディングを多くオープンソースに持っていきたい。
  - どの課題が重要と見つけるのは、どのようにやるのですか？
    - 一番良いのは、自分にとって、一番イライラさせられる問題。過去に紙が好きという両親に向けて、システムを色んなものを作成しても結局使用してもらっていなかった。無駄な事にこんなに時間をかけてきたんだなとなった。
    - 「他者のために」となると、フィードバッグはその人から来るから、反応が遅くなる。できるだけ、身近な人、自分のために作成する。
  - オープンソースの経済性について。収入源になっていくか。
    - 私たちとしては、開発者がプライべーどを犠牲にして時間を費やしていて、バランスが取れていない。
    - 常にオープンソースにするか、プレミアムにするか悩むことになる。しかし、プレミアムにすると、行動が制限されて、自分の好きな物を作れない。
    - 少しだけ、私たちが使用して働いている会社にプレシャーをかけていく。会社が、どれくらいオープンソースに時間をかけられるかを聞いてほしい。そして、貢献してほしい。オープンソースという物を当たり前だと思わないでほしい。
  - ウーパールーパーは、何か関係あるのか？（ほとんどのスライドページにイラストあり）
    - 「何かマスコットが必要よ！」と手伝ってくれる人が言うから、使用している。実は、コロンビア関係ない生き物です。

# 2日目
## Python×信号処理入門！スペクトログラムで視る音の世界
- 初学者向け
- 日本語
- 10:20 - 10:50
- 職業は、電機メーカーの機械設計者（普段、実験やシミュレーションをやっている）
### 講演資料[https://docs.google.com/presentation/d/184hJzgrZ42vpjbcxcw6HuMguMYc16x78/edit?slide=id.p1#slide=id.p1](https://docs.google.com/presentation/d/184hJzgrZ42vpjbcxcw6HuMguMYc16x78/edit?slide=id.p1#slide=id.p1)
### 公式事前説明
自己紹介
このトークについて
Pythonで信号処理をするメリット
豊富なライブラリ群との連携
環境構築
音声分析のために知っておくべき基礎知識
録音する
PyAudioによる録音
ビット数とサンプリングレート
フレーム処理による録音
フーリエ変換
時間波形と周波数波形の関係
リアルワールドの波形例
DFTとFFTのPythonコード
NumPyの.fft
スペクトログラムの描き方
スペクトログラムとは？
スペクトログラムの処理手順
スペクトログラムの分解能について
フレームサイズ
オーバラップ処理
色々な音の可視化結果（複数音源）
この音なんでしょう？
この音はどんな要素でできている？
スペクトログラムの応用
### 個人メモ
- 技術ブログ300記事くらいで書籍化の話が来た
- 世の中は「信号」で溢れている（波形のデータに変換できるもの）
  - 「こんなことができるかな？」と思ったことは、大抵Pythonで可能
- 音声分析のために知っておくべき知識
  - PyAudio：Pythonを使って、オーディオの再生・録音が簡単にできる
    - チャンネル数：1=モノラル　2=ステレオ
    - デバイス番号：環境毎にデバイスに番号が振られているはず(0～）
    - format=ビット数指定…ビット数を上げると縦軸の解像度が増える（点が増える）
    - サンプリングレート…横軸
    - フレームサイズ=録音時間（フレーム単位でループを回して、蓄積して録音する）
  - 周波数分析：フーリエ変換（時間波形⇒周波数波形）
    - 逆フーリエ変換（周波数波形⇒時間波形）
    - 複雑な波も単純な波の重ね合わせで表現できる
    - dB（デシベル）変換：実際の音は大きい振幅や小さい振幅が混ざっている
  - スペクトログラム：音声の可視化（見た目サーモグラフィ）
    - 見る人が見れば、これで音が想像できる
    - フレームサイズが大きい：周波数分解能が上がる
    - フレームサイズが小さい：
    - スペクトログラムの分解能について：オーバーラップ率を上げることで時間方向の分解能が上がる＝スペクトログラムを綺麗に見せるための手法
    - CNNの入力データに使用可能（Kaggleでやった事ある）
  - STFT：全体時間波形からフレームを抽出⇒フレーム単位でフーリエ変換⇒スペクトログラムにデータを蓄積

## 【招待講演】広島から世界へ ― Pythonで描くデータサイエンスの新しい未来
- 日本語
- 11:05 - 11:35
- 広島での高校生向けPython教育の事例を中心に、学びが地域課題解決へと広がる可能性を示し、教育×Pythonから始まる未来を展望します。
- 作者が広島出身で、企業して地元へ。完全、データ分析畑の女性。
### 個人メモ
- 高校におけるデータサイエンス教育
  - 国際的にデータサイエンス能力が遅れているという結果があった。しかし、数学能力が高いが、自分に自信がない。（2013年頃）
  - 2025年に大学入試共通テストで「情報Ⅰ」が必要に
  - 「総合的な探求の時間」：地域orグローバルorデータサイエンスの発表をしてというのを、必修化
  - 3つの不足
    - 指導者の不足：科目毎に先生が存在するが、横断した存在が居ない
    - 指導方法の不足：新領域であるため指導メソッドも無く。
    - 教材の不足：理論や検定は存在するが、ニューラルネットワークとか数年必要になるような物がない。
      - ⇒産学共同で開発
- データサイエンティスト　3つのスキルセット
  - ビジネス力：学習者に「身近」な題材
  - データサイエンス：「理論」を基礎から学ぶ
  - データエンジニアリング：実践しつつ「考える」ものであること
    - 3つのバランスが重要
    - 実際に使用するもので、学習させて興味を持たせたい
      - 例：りんごとミカンの計算とか意味あるか。アイリスのデータセットなんて、何の役に立つのか分からんとか。
- 大学生のリテラシーレベルで、回帰分析・クラスター分析・t検定・カイ二乗検定をやる！？各種統計分析の手計算・Pythonエンジニアリング！？
- 社会人のリテラシーレベルで、数学アレルギーの回避・クロス集計表・回帰分析・クラスター分析！？手計算・Excel計算！？
- データサイエンティスト：女性の割合10％以内
  - アノテーションとか付ける時にジェンダーが問題になっている事例を見かける事がある
- 高校生学習の事例（1日ワークショップ）：鹿のハンター
  - 紙資料（ハンター書き込み）をデータ化
  - なぜPythonを使うかの説明
  - Google Colab
  - サンプルコードを提供するだけ。可視化。
  - ハンターも参加して、発表時にアドバイス
- 女性活躍推進イベント
- 大事なことは、皆が興味をある事で学んでもらう事が重要
  - 広島人は、野球（カープ）が一番
- データサイエンティスト求人は、東京1極集中が問題！！
    
## タスクって今どうなってるの？3.14の新機能 asyncio ps と pstree でasyncioのデバッグを
- 中級
- 日本語
- 11:50 - 12:20
### 講演資料スライド[https://speakerdeck.com/jrfk/tasukututejin-dounatuteruno-3-dot-14noxin-ji-neng-asyncio-ps-to-pstree-deasyncionodebatuguwo-pycon-jp-2025](https://speakerdeck.com/jrfk/tasukututejin-dounatuteruno-3-dot-14noxin-ji-neng-asyncio-ps-to-pstree-deasyncionodebatuguwo-pycon-jp-2025)
### 講演参考GitHub[https://github.com/jrfk/talk/tree/main/PyConJP2025](https://github.com/jrfk/talk/tree/main/PyConJP2025)
### 公式事前説明
Python asyncio と既存のプロファイラの紹介 10分

pyspy
aiomonitor
IDE でのプロファイリング
ps, pstreeの概要 10分

なぜこの機能が生まれたのか
taskの新しい属性「task_awaited_by」
新しいAPI「capture_call_graph」「print_task_call_graph」
ps, pstreeで何ができるのか 10分

Python Web Frameworkとの連携
グローバルバックエンドである anyio / trio における応用可能性
### 自分メモ
- 3.14に追加される
- オーバーロードがない
- 決定的プロファイル
- 使い方：Python3.14rc3
  - 5つのコルーチン関数（例：レストラン）
  - 名前を付けるのが重要
  - asyncio ps
    - 1行目：料理中
    - 2行目：coroutine stack：自分タスクの状態
    - awaiter：完了を待っている別タスクの状態
  - pstree
    - 何をどうみたいかによって使い分ける
- PyCharm：視覚的にどこまで処理できているか見える
- 可能性
  - 時間のかかりすぎるIOを想定
  - 想定外のルート
    - 問題のある個所を特定できる可能性はありそう
    - しかし、気づきにくそう（私は分からん）
- グローバルバックエンドな話

## Weaponizing MCP Servers: Production-Ready AI Agent Infrastructure with Python(MCP サーバーの武器化: Python を使用した本番環境対応 AI エージェント インフラストラクチャ)
- 中級
- 英語
- 13:20 - 13:50
### 公式事前説明
MCPサーバーのチュートリアルの多くは、基本的なサンプルの構築方法を紹介していますが、実際のユーザーがサーバーにアクセスし始めたときに何が起こるかまでは説明していません。この講演では、そのギャップを埋め、MCPサーバーを本番環境で運用可能な状態にするためのPythonパターンとアーキテクチャ上の決定事項を紹介します。

まず、MCPサーバーが高負荷時にクラッシュしたり、メモリリークしたり、応答しなくなったりする原因など、よくある障害要因を検証します。次に、大規模環境でも実際に機能する非同期パターン、連鎖的な障害を防ぐエラー処理、サーバーの応答性を維持するためのパフォーマンス最適化など、実用的な解決策を詳しく見ていきます。

カバーされる主要トピック
実稼働対応の非同期パターン:基本的な asyncio を超えて、接続プール、リクエスト キューイング、MCP サーバーがボトルネックになるのを防ぐリソース管理など、現実世界の複雑さを処理するパターンに移行します。

スマートなエラー処理：依存関係に障害が発生した場合でもMCPサーバーを稼働させ続けるための再試行ロジック、サーキットブレーカー、そしてグレースフルデグラデーションを実装します。部分的な障害に対処し、システムの安定性を維持するためのPython固有のテクニックを探求します。

パフォーマンスとメモリの最適化： MCPサーバーのプロファイリング、ボトルネックの特定、そして持続的な負荷への最適化のための実践的な手法。長時間実行されるMCPプロセスのメモリリークを防止し、ガベージコレクションを調整する方法を学びます。

スケーリング戦略：需要の増加に合わせてMCPインフラストラクチャを拡張するための、水平スケーリング、負荷分散、状態管理のパターンを紹介します。毎日数千件ものリクエストを処理する実際のアーキテクチャを検証します。

セキュリティと監視:リクエストの検証、リソース サンドボックス、包括的なログ記録を実装することで、MCP サーバーの動作を可視化し、悪意のあるリクエストから保護します。

実世界のケーススタディ
詳細な例を通して、データ処理ワークフローからAPI統合サービスまで、実際のアプリケーションを支えるMCPサーバーを検証します。それぞれのサーバーが直面した具体的な課題と、それらを解決したPythonソリューションをご紹介します。

ライブデバッグセッション
障害が発生した MCP サーバーをリアルタイムでデバッグし、問題を特定し、修正を実装し、Python プロファイリングおよび監視ツールを使用して改善を確認する方法を紹介します。

この講演は、単なる例題にとどまらず、実際のワークロードに対応できるMCPインフラストラクチャを構築したいPython開発者を対象としています。実戦で実証されたパターン、実用的なデバッグ手法、そしてプロトタイプから本番環境へのMCPサーバーのスケールアップに向けた明確なロードマップを習得できます。

講演概要（合計30分）
オープニング: MCP サーバーが故障した場合 (3 分)
ライブ障害デモ:
現実のギャップ:チュートリアル用 MCP サーバーが実際の使用に耐えられない理由
一般的な障害パターン:メモリリーク、接続枯渇、未処理のエラー
これらの問題を解決する実用的なパターン
パート 1: 実際に機能する非同期パターン (8 分)
基本的な非同期IOを超えて
接続管理:リソースを漏らさない接続プールの構築
リクエストキューイング:ブロッキングなしで同時エージェントリクエストを処理する
リソース制限:セマフォとガードを使用してリソース枯渇を防ぐ
コードの深掘り 
```
# Robust async patterns for stable MCP servers
# Connection pooling with proper cleanup
# Request batching and intelligent queuing
```
パフォーマンスの改善
メトリクスの前後比較:応答時間とメモリ使用量の比較
プロファイリングツール: Python ツールを使用して非同期ボトルネックを特定する
パート2: エラー処理と回復 (7分)
スマートな再試行パターン
サーキットブレーカーの実装: MCP ネットワークにおける連鎖障害の防止
指数バックオフ:障害が発生したサービスに負担をかけないインテリジェントな再試行戦略
グレースフルデグラデーション:依存関係が失敗したときにも MCP サーバーを機能させ続ける
メモリ管理
リーク検出:長時間実行される MCP プロセスにおけるメモリリークの特定と修正
リソースのクリーンアップ:適切な非同期コンテキスト管理とリソースの破棄
GC 最適化:安定したパフォーマンスを実現するためのガベージコレクションのチューニング
ライブデバッグセッション
実際の問題解決: Python プロファイリングツールで障害が発生した MCP サーバーのデバッグ
監視統合: MCP サーバーに監視機能を追加して本番環境の可視性を高める
パート3: スケーリングとアーキテクチャパターン (8分)
水平スケーリング戦略
負荷分散:エージェント要求を複数の MCP サーバーインスタンスに分散する
状態管理:サーバー間でのセッションデータと共有リソースの処理
ヘルスモニタリング:ヘルスチェックと自動フェイルオーバーの実装
ケーススタディ: 実際の MCP インフラストラクチャ
課題:プロトタイプから毎日数千件のリクエストを処理する規模まで拡張
アーキテクチャ:負荷分散と監視を備えたマルチサーバー構成
学んだ教訓:何がうまくいったか、何が失敗したか、そして重要なアーキテクチャ上の決定
セキュリティと検証
入力サニタイズ:悪意のあるエージェントのリクエストから MCP サーバーを保護する
リソースサンドボックス:エージェントのシステムリソースへのアクセスを安全に制限する
監査ログ:デバッグとコンプライアンスのためにエージェントのアクションを追跡します
パート4: 実際のアプリケーションと次のステップ (3分)
生産例
データ処理パイプライン:バッチ処理リクエストを処理するMCPサーバー
API統合サービス: AIエージェントの外部API呼び出しの管理
ファイル管理システム:適切なアクセス制御による安全なファイル操作
即時対応項目
評価チェックリスト:現在の MCP サーバーの実稼働準備状況を評価する
実装ロードマップ:最大の効果を得るために最初に実装するパターン
ツールとリソース: MCP 開発用の Python ライブラリと監視ソリューション
締めくくり: MCP 制作の旅 (1 分)
キーパターン:信頼性の高い MCP サーバーに不可欠なアーキテクチャ上の決定
よくある落とし穴: MCP インフラストラクチャを拡張する際に避けるべき間違い
コミュニティ リソース: MCP 開発へのサポートや貢献を得る場所
### 個人メモ
- AVテスト

## Streamlit は社内ツールだけじゃない！PoCの速さで実現する"商用品質"の分析SaaSアーキテクチャ
- 中級
- 日本語
- 14:05 - 14:35
### 講演資料[https://speakerdeck.com/kdash/streamlit-hashe-nei-turudakeziyanai-poc-nosu-sadeshi-xian-surushang-yong-pin-zhi-nofen-xi-saas-akitekutiya](https://speakerdeck.com/kdash/streamlit-hashe-nei-turudakeziyanai-poc-nosu-sadeshi-xian-surushang-yong-pin-zhi-nofen-xi-saas-akitekutiya)
### 公式事前説明
自己紹介
顧客の強いデータ活用ニーズと「2 週間リリース」の背景
Streamlit の爆速 PoC を 商用品質 に高めるミッション
堅牢性 & セキュリティ

例外握りつぶし問題：Decorator で捕捉し安全なエラー表示
WebSocket × Cookie の罠：JWT 検証 Decorator で毎リクエスト再チェック
分析基盤 & パフォーマンス

S3 → Firehose → Athena → awswrangler
SessionState キャッシュによる Athena コスト削減
品質保証 & CI/CD

型安全ファースト：mypy／pyright と Result 型でバグ未然防止
Streamlit Testing API を用いたヘッドレステストを自動化（pytest-xdist 併用）
Jsonnet + GitHub Actions → ECS Fargate：環境差分のないワンコマンドデプロイ
ビジネスインパクト & 学び

公開初日で顧客 10 社 が即利用、データドリブン施策が加速
PoC の速さ × SaaS の品質 を両立する設計Tips
まとめ & Q&A

発表内容のサマリー（持ち帰ってほしいこと）
質疑応答
### 個人メモ
- 業務：ECショップの配送等の後工程を自動化
  - 配送追跡
  - 返品交換
- 社外向け分析コンテンツ
  - 案1：Next.js + FastAPI
  - 案2：Streamlit
    - 決定理由：お客様に早く届けたい
  - 商用品質
    - パフォーマンス：体感速度UPとコストDOWNの両立
      - レスポンスの遅延：AWSのS3 + ：小さく始めて、早く軽く：
        - クエリ発行回数をどう減らすか？
          - 標準でキャッシュ機能あり（大きく3つ）
            - ユーザー/タブ毎のキャッシュ
          - いつクエリを再実行するか
            - 再クエリ条件を明確化
      - データ
        
    - 堅牢性とセキュリティ
      - 例外処理の罠
        - StackTraceは便利だが、お客様に表示されたら、情報漏洩リスク
          - ブラウザに表示させないように設定。設定すると、お客様には理解できない汎用エラーが表示される
        - コードの汚染
        - ⇒Pythonのデコレーターで解決
          - 第一の防衛線：想定内エラーをデコレーターで処理
            - エラーの場合、ブラウザ画面に表示するメッセージをAnyError型に包んでデコレーターに渡す
          - 第二の防衛線：想定外エラー
          - ⇒二段構えのデコレーターをmain関数に適用すれば完成
      - Stremlit標準認証では解決できない問題：テナント毎の
          - 第三の防衛線：認証デコレーター
    - 品質保証：厳格な静的解析（「型」）
      - 静的品質保証
        - 「型」は、制約ではなく、開発を加速させるガイド
          - 安全なリファクタリング
        - Result型：型安全なエラーハンドリング
          - 例外の代わりに型で表現
        - AnyError型：構造化されたエラー情報
          - エラーの階層化と型安全性
          - 任意の文脈情報を持たせることができる
      - Steamlit Testing API
        - 公式のTestingAPI
          - 高速だけど万能ではない：ブラウザレス・UIロジック中心をテストする（見た目のテスト必要な人は、別にする必要がある）
- 結果
  - 開発着手から2週間でリリース
  - 罠
    - 情報漏洩
      - 
    - 誰でもアクセスできる
      - st.session_state()への唯一のアクセスポイントを作る
  - 対話は一度に
 
## PythonとLLMで挑む、4コマ漫画の構造化データ化
- 初級
- 日本語
- 14:50 - 15:20
- 仕事：健康診断の非構造化データのLLM
### 公式事前説明
イントロダクション：なぜ 4 コマ漫画なのか？

4 コマ漫画は「画像」「テキスト」「連続性」が凝縮された、非構造化データ処理の格好の題材
最終目標：単行本をスキャンするだけで、コマ、登場人物、セリフ、状況を構造化し、検索・分析可能なデータベースを構築する
アプローチの変遷：LLM 以前の格闘

フェーズ 1: 人力とスプレッドシートの時代
手動でのデータ入力と管理の限界
フェーズ 2: Python と深層学習（DL）による挑戦
コマの自動切り出し（物体検出: YOLO など）
セリフの OCR（Tesseract, Google VisionAPI など）
登場人物の検出（物体検出）
課題：各コンポーネントの連携が難しく、精度も限定的。修正のための UI（アノテーション画面）開発コストが高い。
LLM の衝撃と現実：Gemini 登場で何が変わったか？

期待：「LLM に画像を投げるだけで全部解決！」
セリフ抽出：驚異的な精度。従来の OCR を凌駕。
状況説明・構図の理解：人間のように自然言語で説明を生成。
現実の壁：LLM だけでは越えられない課題
人物座標の曖昧さ：LLM は「左の人物」とは分かっても、正確なバウンディングボックスを返せない。
人物識別の低精度：「A というキャラ」と「B というキャラ」を安定して見分けるのは困難。
話者同定の難しさ：どのセリフを誰が話しているのか、吹き出しと人物の関連付けができない。
ハイブリッド・アプローチ：LLM と Python エコシステムの協調

適材適所な役割分担
LLM (Gemini)：
役割：意味理解、文脈判断、自然言語生成（セリフ、状況説明）
Python/DL (YOLO, DINOv2 など)：
役割：精密な空間認識（コマ、人物、吹き出しの正確な座標検出）
役割：特徴量ベースの識別（顔認識による人物識別）
具体的なパイプライン
コマ切り出し: YOLO で 4 つのコマを正確に検出・切り出し。
並列処理: 各コマ画像を LLM と DL モデルに同時に投入。
LLM → セリフと状況説明を JSON で出力。
DL → 人物と吹き出しの座標リストを出力。 (WIP)3. データ統合: Python スクリプトが、座標情報を元に「どの吹き出しが、どの人物に最も近いか」を計算し、話者を同定。 (WIP)4. 最終構造化データ: 全ての情報を統合して出力。
開発の加速：AI エージェントは最強のペアプログラマー

品質と開発速度の向上
Human-in-the-Loop UI の高速開発: 「検出結果をすぐに確認・修正できる WebUI を作って」と指示するだけで、Flask や FastAPI ベースのツールを自動生成。
LLMとの連携によって開発速度が圧倒的に向上すると、確認のためのツールもそれに追いつく便利さが必要
Colab 学習ノートブックの自動生成: モデルの学習やファインチューニングに必要なコードを対話的に生成。
レガシーコードのモダン化: 煩雑な Python スクリプト群の統合や、ライブラリのアップデートを支援。
プロンプト改善: より良い結果を得るためのプロンプトエンジニアリングを支援する UI の作成。
まとめと今後の展望

LLM は万能ではない。しかし、既存の Python エコシステムと組み合わせることで、これまで不可能だったレベルのデータ構造化が実現可能になる。
「自動化（LLM/DL）」と「人間による確認・修正（UI/UX）」のサイクルをいかに効率的に回すかが、実用的なシステムの鍵。
AI エージェントの活用は、この開発サイクルを劇的に加速させる。
今後の挑戦：動画、音声など、他の非構造化データへの応用。
###   個人メモ
- 非構造化データをLLMでデータ化したいという例⇒最近は、発達してきてGPTとかでできるようになった（実際、会社でも注文書とか可能だった）
  - レシート
- 実際にシステムで使うなら、生成AIに細かく定義してあげる
- Pythonでやると良いところ
  - 入力する画像に事前画像処理：傾きや明るさ調整、トリミング、ノイズ除去
  - 入力・出力のデータを機械学習で処理：商品名からカテゴリ判定
- 2016年からずっと4コマ漫画の解析ばかりしている。
  - コマ毎に切り抜く手法とか翻訳とか
  - 2024年12月にGoogle Gemini2.0が来て、4コマ漫画に使用できるのでは？
    - 人物と出てくる順番、発言の内容、発言の話者特定をさせたい
      - ⇒いけそうで無理だった
        - 頑張ったプロンプト例：事前情報
- claud Code（MAXプラン）にお願いした
  - YOLO11
  - 人物検出と7キャラクター分類を同時実行
  - 入力サイズ：480x480
  - 処理速度：約40-60ms/画像（CPU）環境
  - それぞれのデータ数：単行本2巻分
- 吹き出し検出＆タイプ認識
  - 14タイプに分類
  - YOLO11
  - 入力サイズ：640x640px
  - 処理速度：
  - ⇒話者推定のために追加情報が欲しい：吹き出しのしっぽ検出＆方向認識
    - シンプルすぎるのかコミック工学の先行研究には、「やってみたが精度が出ない」くらいの説明しかないので、やってみた
      - ⇒安定しなかったり、トーンなどがあると一瞬で破綻する
      - 精度は70～80％程度
      - しっぽのベクトルを伸ばして、人物検出に当たれば話者とした

## Day 2 Lightning Talks
- 16:05 - 16:50
#### Snowflake社の宣伝
#### 2026年卒　Flask5年
- 18言語対応（韓国からアクセス増えて、調子に乗ってやった！？）
- ローカライズ：flask_label
- カーソル
- テキスト抽出
  - HTML
  - Gemini APIやDeeple APIとかで翻訳　＋ polib
#### 宇宙の話
#### ローカルRAGをClaude Codeに作ってもらった（広島のイベント宣伝目的）
- SQLのコマンドのHPを3層読み込んでもらってから、作ってもらった
#### SWE-Bench
- AIモデルベンチマーク結果：Pythonが一番
- AIモデルは英語が良くて、GPTは日本語が良い。

## 【Day 2 Keynote】　プログラミングの未来を駆ける！~2年間の挑戦が見せてくれた、プログラミングのこれから~
- 17:00 - 18:00
- 「生成AIに育てられた第一世代」を掲げ、大学４年時にChatGPTを武器に100日で100本のアプリを公開する“#100日チャレンジ”を完遂。
### 自分メモ
- 教授に褒められ、海外論文が認められ、ソフトウェアエンジニアとして就職できた
- ゲームをするために宿題をさぼるとか怠け者。
  - 教授が「ChatGPTがあるけれど、宿題に使用してはダメ」と言われて、サボれるの！？と使い方を調べ始めた
    - 毎日、十数時間調べて、遡って海外論文まで辿り着いた
  - ある時に自習の時に、教授が内職を覗き込んで、「プロンプト上手いね。学会に出てみない？」となって、教授に怒られないように騙すために「効率化」として学会発表で賞を取る
  - 賞を取ったら、招待講演に呼ばれて、また同じ事したらバレると思い、「100日チャレンジ」を思いついた
- 2023年4月100日チャレンジで学会で賞を取り、エンジニアになっていた
- 2024年3月「Hello World!から始まる退屈な研修。窓の外を眺めながら7カ月間執筆に熱中」：つまんないが、「できる」と言ったら他の事やらせると考えて、やり過ごしつつ、毎週出版社と打ち合わせして執筆（出版社から生成AI禁止されていたから、自力執筆）
  - 先生に懇願されて、仕方なく大手SIerに就職した
  - 研修は、意味ないし、将来に役立つ他の勉強も分からずに、本の出版に誘われて、消去法で行動を選択
  - ログインを無理矢理突破して、日報を毎日生成Aiに書いていた
    - 人事部からは、それをずっと見て好評だった
    - 工夫したのは、誰か偉い人が来て褒められた場合、必ず日報に嬉しかったと書かせた
- 2024年11月本もベストセラーになり【作家xエンジニア】：受注開発に誘われて、インボイスが必要だねという話から「会社設立準備中です」と嘘を付いたので、本当にするために3日日間調べて会社設立した
-生成AIにより、コードを書ける事よりも「問いを作る」事が重要になった
- 2023年春にChatGPT誕生
  - 100行レベルのコードしか書けずに、周りの学生が宿題に使用して怒られていた
- 100日チャレンジ：実際は、Twitterに「いいね」の数だけやりますと言ったら、物凄く「いいね」が付いた。二日連続書いたら、友達から「明日」の内容を質問されて辞めれなくなった
  - 2023年10月28日～2024年2月4日の100日間、毎日ゲームやツールを作成
  - 最初に汎用的な物から作り出した：ボールとか
    - 後で少し変えて、楽できるように。
  - オセロを最初と真ん中と最後に作成しているのは、どれくらい成長したかの比較のため
    - 1日目：Colabで作成した：図で作った（盤面の線を引いて、円で碁石変わり」
    - 100日：Pygame：線形ライス（当時生成AIが弱かったので、自分でその本を見て、コードそのまま書いていた）を使用して、動かした
- 本には、就職活動や会社時代を訴えられたら、ぼかして書いています。
- 論文書く前提だったので、全て日々の記録を残していた。
  - プロンプトとかも全文
  - 毎日夜の6時には、公表できるように習慣化した。
  - 未来に繋がるかどうかで判断して行動した。技術を学ぶだけではなくて、「対外的に見て」評価になるかを重要視した。
  - 100日チャレンジは、最初は本になると思わずに、外から見てエンジニアとしてやっていくために「継続性」・「根性」を目に見えてアピールを示すためにやった。
    - 記事がバズッた。
      - 「役に立たないのでは？」と批判殺到。
      - 見た目も重たそうとか。⇒腹立ったので、本日は30万かけて、本物のダイヤモンドのネックレスとメイクさんも依頼して来ました！
  - この講演は、100日前に告知されたので、何人も100日チャレンジしてくれたが、5日くらいで全部消えた。
- 何かこの講演のために作ろうとして、動かなかった：SNSみたいなの
  - デザインが決まったのは、1週間前
  - 自分が欲しい物が分からない
  - 2日前にメモアプリ作成しました
    - スクショのOCRと音声の文字起こししか要らなかった
    - 友達がline使用してメモしているが、過去を遡れないので、カレンダーを追加
    - 実際に2025/9/27にリリースしました。「メモるん」商標も出願中です。
    - 「何を作った人なの？」と言われて悔しかったので、アプリをリリースしました
      - 本日、駆け出し技術者から個人開発者になりました！
- Q：オセロを1日目に選んだのは、なぜ？
  - A:ChatGPTに初心者が作れる物とオススメされたから
- Q：宿題を真面目にやるよりも遅くないですか？
  - A：サボる事を決めたら、それが目的なって、時間効率に目が向かなくなった。ハッカー精神では？
- Q：4月時点で、就活も院生準備もしていなかった
  - A：このままでは、ニート一直線で。先生の推薦で、就職した。院生に行くには、10月に試験なので、100日チャレンジ中で無理で、就活しか選択肢が無かった。先生から博士課程を進められて、2年間の社会人経験が必要と言われて、現在、2年間の時間潰しをしているだけ。もう、国際学会で賞取っているので、就活前にこのまま博士課程確定している。
- Q：本を見た人は、記録の取り方が凄い。普通の人は、ログ残っていなくて、本を書けない。
  - A：あまりにもフットワークが軽すぎて、自分でも何しているか分からなくなるので、行動前に文字にする習慣を作っている
  - 文字を書いとけば、予定を考えた事は、履歴で残る。感情が動いた事とか、なんでもかんでも記録している
  - 残っている文字の面白い所だけをピックアップして良質の所だけを集めて、本を作った
  - 周りから、教えてと言われてるので、Note書いたけれど、誰も理解してくれない！！だから、自分が欲しいメモアプリ作ったので、同じようにしてみてください
 
# ポスターセッション
## 「まっすぐ行って、右！」って言ってラズパイカーを動かしたい 〜生成AI × Raspberry Pi Pico × Gradioの試作メモ〜
- 初級
### ポスター[https://speakerdeck.com/komofr/pyconjp2025-poster](https://speakerdeck.com/komofr/pyconjp2025-poster)

## そのグラフに「魂」は宿っているか？ ～生成AI全盛期におけるデータ可視化手法とライブラリ比較～
- 初学者向け
### ポスター[https://speakerdeck.com/negi111111/sonogurahuni-hun-hasu-tuteiruka-sheng-cheng-aiquan-sheng-qi-niokerudetake-shi-hua-shou-fa-toraiburaribi-jiao](https://speakerdeck.com/negi111111/sonogurahuni-hun-hasu-tuteiruka-sheng-cheng-aiquan-sheng-qi-niokerudetake-shi-hua-shou-fa-toraiburaribi-jiao)

## GraphRAG：グラフDBで強化したRAGによるLLM生成の実践
- 中級
### デモHP[https://mangagraph.netlify.app/links](https://mangagraph.netlify.app/links)

# 未聴講の気になる資料
### Hello, satellite data! ～Pythonではじめる衛星データ解析～[https://speakerdeck.com/ra0kley/pycon-jp-2025-day1-hello-satellite-data-pythondehazimeruwei-xing-detajie-xi](https://speakerdeck.com/ra0kley/pycon-jp-2025-day1-hello-satellite-data-pythondehazimeruwei-xing-detajie-xi)
