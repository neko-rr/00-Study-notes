# Meta Llama Academy in Japan 2025参加メモ
- 公式HP[https://luma.com/q6q73ztw](https://luma.com/q6q73ztw)
- 参加日：2025年11月20日・21日（木・金）
- 10:00～19:00
- 参加形態：個人参加（プライベート）
- 対面
- スライドの写真をSNSに挙げるの禁止
# 目次
10:00–10:15　オープニング／ゴール共有
10:15–11:00　基調：Llama最新アップデート／Why Open Source
11:00–12:00　アイディエーション講座&AWS Workshop Studio利用方法説明
13:00–14:30　ユースケース講座＋Q&A（海外登壇は通訳予定）
14:30–16:30　チーム編成→アイデア出し
16:30–17:00　Day2開発タスクプランニング

​Day 2 — Mini Hack & Pitch
10:00–16:00　集中開発（常時メンタリング）
（※13:00–14:00頃　各グループとクイックに中間進捗確認）
16:15–17:45　最終ピッチ（3–4分/チーム）＋フィードバック
17:45–19:00　クロージング／交流会（任意）
# 1日目Learn & Design
## 10:00–10:15　オープニング／ゴール共有
- 賞
  - グランプリ：50万円
  - 製造業DX賞
  - ソーシャルインパクト賞
  - テクノロジーイノベーション賞
  - Meta特別賞
- 各賞：賞金20万円を想定
# 10:15–11:00　基調：Llama最新アップデート／Why Open Source
- Llamaのバージョン説明
  - 古いモデルでも優れた活用例がある
- オープンにする事で、イノベーションが促進された
- Llama4：最新
  - 最新は税金関係の利用が多い
- 重要な事
  - 一番は、精度の確認
  - 二番は、コストとレイテンシー
    - 量子化すれば、大規模パラメータでも使用可能
  - セキュリティ
    - Llama Firewall
    - Llama Guard：有害コンテンツを出さないようにする
    - Prom Guard：プロンプトインジェクションを防ぐ
- PromptOps
  - モデルに合わせて、プロンプトを最適化する（GPTとかのをそのまま使用しない）
  - 試行錯誤のプロセス：体系的なツール⇒自動化（5分～30分程度）
    - 例：RAGの精度が70％⇒80％
    - プロンプトを最適化するだけで、ファインチューニング無しに精度は上げられる
- ファインチューニング
  - Ansloth：オープンソース
  - Tochtune：Meta
  - TorchForge：現在、ベータ版で試せる
- ⇒担当が全て手作業する必要は無い
- まとめ
  - 適切なモデルサイズを選択してください
  - 評価用のデータセットを用意し、ベースラインを把握しましょう
  - ファインチューニングの前に、まずプロンプト最適化を行う
  - それでも無理ならば、ファインチューニング
  - 十分なデータが無い場合、シンセティックデータキットを使ってデータを増やしましょう
- Lama Cookbook：GitHubでユースケース紹介している
- プロジェクト紹介
  - Omnilingual ASR：先週リリース。自動音声認識モデルで、サポートされていない言語にローカライズしたい場合もOK
  - Samモデル：セグメント解析モデル
## Q&A
- データの生成において、分野によっては生成されたデータが正確かどうかを確認するのが難しい場合があります。
  - 紹介したのは評価を行ってデータの品質を測定すること
  - 他には、元のデータ分布を分析します。最初のサンプルを元に特徴把握して、その特徴が保持されたままデータが生成されているかを確認する。簡単ではない
  - LoRAを試したり、もっと簡単なのがある。
  - いきなり上位モデルを試すのではなく、小さいモデルから始める
- マルチエージェントモデルの選択
  - MoEアーキテクチャについて
  - Maverickで使う場合、どのモデルを使用するかは、モデルが自動で選ぶ
  - もっと細かく制御したい場合は、マルチエージェントアーキテクチャを使って自分でプロセスを定義可能
  - しかし、プロンプトを工夫すれば、そんなことは必要ないかもしれない
    - 同じエージェントを3回並列したり、デバイスも高度になってきている
  - プロンプト最適化とファインチューニングは、密接に関係がある
    - どちらも、モデルに知識が無ければ出力できない
    - 話者は、ファインチューニングよりも普段はRAGを選ぶ
  - RAGとリトリーバルの違い
    - rec自体も研究が進んでいる分野
    - rec追加情報を取得する
  - 日本語対応
    - 公式に対応できる言語数には限界があります
    - モデルのトレーニング家庭では、公式言語以上で学習しています。実際は200言語以上
    - 追加トレーニングされているモデルがあります。例：インド
    - Hugging Faceで、日本語向けに強化されたLlama派生モデルがあるか確認してください
  - 今後2～3年後を見据えた時、個人的に最も有望だと考える開発の方向性は何でしょうか？
    - モデルをより効率的に学習させること
    - Llama4ではMoEを試した
    - 但し、Denseモデル自体が良くないというわけではない。8億のような小規模には理にかなっている
    - 用途によって様々です。1つを選ぶ必要は無い。
  - Llamaモデルを長期的にどのように共存し、差別化していくと考えていますか？
    - 自社でも積極的に使用しています
- プロンプトオプスを最適化
  - 設定で特定の目標や評価者を選択すると、その基準に基づいてツールが繰り返し処理し、結果を測定します
  - 基本的には、いくつかの例を提示します
# 11:00–12:00　アイディエーション講座&AWS Workshop Studio利用方法説明

# 2日目
