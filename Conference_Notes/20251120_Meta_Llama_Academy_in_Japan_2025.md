# Meta Llama Academy in Japan 2025参加メモ
- 公式HP[https://luma.com/q6q73ztw](https://luma.com/q6q73ztw)
- 参加日：2025年11月20日・21日（木・金）
- 10:00～19:00
- 参加形態：個人参加（プライベート）
- 対面
# 目次
10:00–10:15　オープニング／ゴール共有
10:15–11:00　基調：Llama最新アップデート／Why Open Source
11:00–12:00　アイディエーション講座&AWS Workshop Studio利用方法説明
13:00–14:30　ユースケース講座＋Q&A（海外登壇は通訳予定）
14:30–16:30　チーム編成→アイデア出し
16:30–17:00　Day2開発タスクプランニング

​Day 2 — Mini Hack & Pitch
10:00–16:00　集中開発（常時メンタリング）
（※13:00–14:00頃　各グループとクイックに中間進捗確認）
16:15–17:45　最終ピッチ（3–4分/チーム）＋フィードバック
17:45–19:00　クロージング／交流会（任意）
# 1日目Learn & Design
## 10:00–10:15　オープニング／ゴール共有
- 賞
  - グランプリ：50万円
  - 製造業DX賞
  - ソーシャルインパクト賞
  - テクノロジーイノベーション賞
  - Meta特別賞
- 各賞：賞金20万円を想定
# 10:15–11:00　基調：Llama最新アップデート／Why Open Source
- Llamaのバージョン説明
  - 古いモデルでも優れた活用例がある
- オープンにする事で、イノベーションが促進された
- Llama4：最新
  - 最新は税金関係の利用が多い
- 重要な事
  - 一番は、精度の確認
  - 二番は、コストとレイテンシー
    - 量子化すれば、大規模パラメータでも使用可能
  - セキュリティ
    - Llama Firewall
    - Llama Guard：有害コンテンツを出さないようにする
    - Prom Guard：プロンプトインジェクションを防ぐ
- PromptOps
  - モデルに合わせて、プロンプトを最適化する（GPTとかのをそのまま使用しない）
  - 試行錯誤のプロセス：体系的なツール⇒自動化（5分～30分程度）
    - 例：RAGの精度が70％⇒80％
    - プロンプトを最適化するだけで、ファインチューニング無しに精度は上げられる
- ファインチューニング
  - Ansloth：オープンソース
  - Tochtune：Meta
  - TorchForge：現在、ベータ版で試せる
- ⇒担当が全て手作業する必要は無い
- まとめ
  - 適切なモデルサイズを選択してください
  - 評価用のデータセットを用意し、ベースラインを把握しましょう
  - ファインチューニングの前に、まずプロンプト最適化を行う
  - それでも無理ならば、ファインチューニング
  - 十分なデータが無い場合、シンセティックデータキットを使ってデータを増やしましょう
- Lama Cookbook：GitHubでユースケース紹介している
- プロジェクト紹介
  - Omnilingual ASR：先週リリース。自動音声認識モデルで、サポートされていない言語にローカライズしたい場合もOK
  - Samモデル：セグメント解析モデル
# 2日目
