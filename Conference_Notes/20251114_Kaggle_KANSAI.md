# 関西Kaggler会 交流会 in Osaka 2025#3参加メモ
- 公式HP[https://kansaikaggler.connpass.com/event/360825/](https://kansaikaggler.connpass.com/event/360825/)
- 参加日：2025年11月14日（金）
- 13:20～18:30
- 参加形態：個人参加（プライベート）
- 対面
- 年3の情報交換会⇒年2回に減る（関西2回・関東2回に）
# 目次
第一部（20分枠）
- paoさん&ryushiさん
- bobfromjapanさん
- cpp_takeさん
- ryochinboさんさん
- 20分休憩(~15:40)

第二部（20分枠）
- takaitoさん
- ちゅまじんさん
- kutoさん
- しんちろさん
- 20分休憩(~17:20)

第三部（5分枠）スポンサー枠
- 関西電力さん
- K4 Digital さん
- 松尾研究所さん
- Udemyさん
- Turingさん
- SB Intuitionsさん
- PolarisAIさん
- Panta Rheiさん
- Elithさん
# 総括
過去に応募した企業名ばかりある(´;ω;｀)
ノリが陽キャ？でも、ギャル系では無い。ピクニック的な陽キャ。
飲み会から始まった会！？？
# メモ
# 第一部（20分枠）
## paoさん&ryushiさん(KaggleとJOAI委員会）
- JOAI委員会：国際人口知能オリンピック（第二回）：学生（中高生・大学）
- 日本代表の選抜・育成（設計・育成・運営）
- 関わる人、グランドマスターが3人他色々と豪華
- 規模154人
- 予選：マルチモーダルに対応したコンペ設計
- 2日間で6問
- 育成：4か月かけて、宿題を出して面倒見たり勉強会する感じ
- 「オープン枠」を設けて、講習会（経験の少ない社会人にまで範囲を広げる）
- 関わる理由：Kaggleマスター・ログイン記録が途切れる＆400提出しても銀メダルでやる気切れした所に声掛けあり
- 次回委員長・2026年はアラブ首長国連邦
- ここからpaoさん：理事
- 短期コンペが得意
- 中学生時にエキスパートだった人に、手伝ってくださいと言われた（まだ、学生の人）
- Q&A：今の中高生の雰囲気は？⇒色々。やる気ある系からChatGPTを触って初めて興味出た人から。
## bobfromjapanさん（鯖落ちパーツで安価に機械学習用マシンを作ってみる・大塚製薬勤務）
- 挙手：ローカルPCでやっているのが、半分
- 挙手：Kaggle環境のみ、数人
- 自作PC使ってみたけれど、Kaggleでは、あんまりGPU性能良くなかったよーという話
  - 32コア、256GBメモリ、24GB VRAM GPUが2枚刺さったマシンを20万以内で作れる!今は、同構成で値上がりしている。
  - 実用的ではなかった。結論、金をかけるしかない！
- Kaggle歴3年
- 時間制限や性能で、ローカルが欲しい
  - GPUの値段が上がりすぎている
- ユニファイドメモリ+iGPU系：ローカルLLMなどの推論には使えるかも？
## cpp_takeさん(ボディメイクのコンペティションBEST BODY JAPAN参戦気・K4デジタル)
- Kaggle：2～3年・コンペ　マスター
- ボディビル：BBJ：細マッチョである健康美を競う
- 3ヶ月でムキムキ・2か月日焼けサロンに通ったのに白飛び状態
- Kagglerにボディビルをさせたい！
  - LBが無いから、誘ってもやらないんだ
    - BBJの評価と合わせるのは無理と諦めた（知性があるから）
    - LB作りました！！！皆やるよね！VLM as a Judge
    - スコアベース：評価対象をLLMに入力し、点数を出力させる方法
    - ペアワイズ：
      - ハイブリッド方式：人間に近い評価が出たので、これを今回採用
      - 今回、5つの体の部位を評価する
      - 金曜に作業するのは、やめましょう。動画のアップロードができなかった⇒調整して、1時間仕事そっちのけで修正してローカルで動かします！！
      - ハマった理由：Gpt-4oで評価を実施していると、10回に3～4回程度「評価ができません」といった胸の出力され評価ができないトラブル
        - 可能性：人の比較がヘイト扱いになっているかも・裸だから静的コンテンツ扱いかも
        - Gpt-4o-turboにしたら解決
        - ファインチューニングもしたかったけれど、流石に費用対効果が悪過ぎて辞めました
- 最新技術で馬鹿な事が好きです
## ryochinboさんさん（どこかで読んだのに…をなくしたい！）
- 昨年までは、メーカーの生産技術開発
- 現在は、みんなのDX推進
- 職場に持ち帰ると、LLMって、チャットだけでしょう。自分の業務に関係ない。という反応になる
- 読んだ記憶だけがあるけど思い出せない時にその「情報」を提示するRAG
  - 「くりとらぐ」
  - URLから元文書をとってきて、要約保存
    - 非エンジニアを引き込むためのこだわり
    - Python100％
    - csvでアレンジ可能
    - 1クリック
- 効果
  - 何ができるかのイメージを持ってもらえる
  - 初期費用、基本料金レス
  - LLMやPythonに興味
  - 自己理解（この人）
- デメリット
  - 利用規約やrobots.txtに反していないかの確認が必要
- Q&A：ローカルにデータが溜まりすぎませんか⇒興味を持ってもらうための一時的なツールで、長く使用する事を想定していない
- Q&A：一般人を引っ張るのが面倒くさくないですか？⇒ひたすら、こうすれば一瞬で終わるよーと自己犠牲で流しています
# 第二部（20分枠）
## takaitoさん（未完）Kaggle:corochann
- 仕事：自然言語+金融
- 仕事：大学の非常勤講師を増やした
- Kaggle（金1銀　銅17）とatmaCup（上位）との成績の乖離が不思議で分析
- 開催期間の違い：少なくとも1カ月以上大抵3ヶ月。A：たいてい1週間～10日間程度
  - 短期間コンペが得意？
- 英語か日本語の違い
  - 英語が苦手
- 基本的にはnotebook提出。A:csv形式で提出
- 最近勝ててる：3コンペ金
  - チームを組んだから
  - 1人当たりの投入時間の合算が金圏内に必要な量を上回る事が出来た
  - 各自の得意な部分に集中して取り組むことができた
  - 言語の壁：チームでスラックを組むと、こういう事が書いていたよーとチャットが来る
  - Notebook提出：チームメンバーがライブラリの依存関係や高速化を可能にしてくれた事で、他の取り組みに集中できた
- チームを組む事で、得意な事に集中できて楽しくなる
- アンサンブルも効果ある
- 個々のメンバーの実力も大事
  - 丁寧な復習：過去コンペの解放から学ぶ事ができることが非常に重要
  - 継続が大事
- 来年の自分は、今の自分より忙しい事が大半
  - ほんの少しでも良いので、時間を確保して継続する事が大切
  - 自己研鑽に関しても、Kaggle以外でも良い
- 才能の壁は突破できるのか？
  - 元から能力のある人が、しっかり努力もしている魔境
- 計算資源
  - なくてもできるコンペもある
- まず、3分やる
- やる事リストを只管、飽きたら変更してやっていく
- 書籍執筆
## ちゅまじんさん(起業。そして、Kaggleトップ層の「狂気」と「戦略」）Kaggle:chumajin
- Kaggleで猫アイコンは強い！！！
- Kaggle GMであるだけで、会いたいとか・紹介したいとか言ってくれるお客様がいる（偉い人に説明しやすい）
- 仕事は、Kaggleで培ったスピードとクオリティで勝負（１～３ヶ月かかるところを１～2週間、精度2倍）
- 製造業経験も大きい
- プログラミング教育提供：満足度高い（前職でのKaggleサークルの経験も役に立っている）
- 講演会は、Kagglerの全部紹介
- 良い意味で狂っていると考えている
  - ソロ金目指した時、Googleアカウントを10個持っていた
  - 時間をお金で買う：会社に提出する領収書は100枚超え。最後は予算オーバーして、自腹
  - スクリーン4画面
  - 他の人に聞いてもGoogleアカウントを5とか10個持っているのが普通
  - 他者事例：1000時間LLM
  - 一番やばい：greySnow：データセットが大量：60GBx43=2.58TBをアップロード（考えてもバンされる可能性考えてやれない）
  - 勝つために何でもやる（チート以外）
    - 時間やお金とかどうでもいいやとか吹っ切れる事が重要
    - 金メダルを目指すというのは、こういう人たちを相手にしているということ：1サブ金
- 本当の天才は、それを努力と思わないかもしれない
- Kaggleで急激に強くなれたきっかけ
  - 参加⇒やる⇒復習する⇒outputする
  - 復習は、金メダルをソロで再現するまで１～２か月やることもある
  - outputする環境があった：サークル
  - 2021年の秋：エキスパート銀くらいで、グランドマスターになりたいと本気になった
## kutoさん
- 金３
- モビリティ企業でデータサイエンス（福岡在住）
- 解法を投稿する際にサマリー図を書くようにしている
- しっかり取り組んだコンペは書くようにしている
  - せっかく提出するなら、カッコよくまとめたい
  - Twitterとかの反応が良い（モチベ上昇）
- １：テキストで解法を書き出す。writeupを書くのと同じ
- ２：構成を決める
- 図解テクニック11個
  - 部品作り：ブロック図（ブロックと矢印）・シンプル図形の組み合わせ（モデルのネットワーク図解）・CV戦略も長方形の組み合わせ
  - アイコン：icoon monoを良く使用
  - 画像：分析結果の画像を入れる：特徴量マップ
  - 情報の調整
  - 詳細化
  - 簡略化
  - 近接：関連する情報を近づける
  - 反復：繰り返す事で認知不可を減らす（キーワードごとに同じ色を反復する事で同じものと認識しやすくなる）
  - コントラスト：違う物は、色・形状・大きさを変えて違いを表現する
  - カラー：コンペのテーマカラーに合わせる
- おすすめ本：ノンデザイナーズ・デザインブック
- 作り始めるのは、終了の2日前くらいから開始。6時間くらいかけて、作成している。
## しんちろさん（量子化ｘファインチューニング）Kaggle：sinchir0
- SanSan勤務でファインチューニングが仕事
- 量子化とは：浮動小数点数型で持つモデルの重みや活性を、よりメモリ消費量が少ない整数型に変換する
- 量子化誤差：精度が下がるので誤差を減らしたい
- 校正：校正のために使う校正データを校正という
- KaggleのLLMコンペは、よりパラメーターの大きいモデルのほうがよいスコアが出る可能性が高い
  - Kaggle環境では、Out of memoryになる。対策として、量子化
- 組み合わせを考える観点
  - 順番：2個
  - 量子化手法：4個
  - ファインチューニング手法：4個
  - 組み合わせを考えると、最終4つに絞れる（不可能な組み合わせを取り除くと）
| No | 順番 | 量子化手法 | ファインチューニング | CVスコア |
|----|-----|------------|--------------------|---------|
| 1 | 量子化⇒ファインチューニング | bitsandbytes | LoRA | 0.9364 |
| 2 | ファインチューニング⇒量子化 | GPTQ | フル | 0.9411 |
| 3 | ファインチューニング⇒量子化 |  |  |  |
| 4 | ファインチューニング⇒量子化 |  |  |  |
# 後で表入れる
- 論文探してもどの精度が高いか分からなかったので、実験してみた
  - 今回の実験結果
  - 3番目が精度が目に見えて低い理由：話者のパラメータ調整不足・校正データの可能性が高いらしい
  - 話者結論：今回の実験では、フルファインチューニング⇒量子化の手法が性能が良かった。しかし、別のでは一般的なのが良かったので、一般的なの試してから、場合によってはフル⇒をやろう。
# 第三部（5分枠）スポンサー枠（懇親会の価格下がった理由：いつもは1枠10分で少なかった）
## 関西電力さん& K4 Digital さん
- 会社説明
- 現在、AI一色。現場寄りから、法令チェックのような面倒な事までやっています
## 松尾研究所さん
- 東大の松尾研究室と産学連携する形で会社
- 3構成：データサイエンス：24名・MLシステム・AIコンサル
- DSチームの半分以上は非Kaggler
- 探索的な活動に20%充てる取り組みの幅が広い
- 技術について語り合える文化を求めている
## Udemyさん
- フロアにトレーニング機材置いているよー
- atomacupにコンペを出した：1割くらい参加していたみたい
  - 実践の場が欲しいとの声に答えた
  - 624名参加
  - テーマ：どういう社員が社内公募に手を上げるか
    - 因果関係を追検証しました
## Turingさん
- 自動運転開発のスタートアップ
- 前回から金メダル増加ならず（2024年春から19枚増えた）
- でも、上位に入って、ハワイに発表しに行った人あり
- 東京の一部区間で35分間無介入達成
  - 路上駐車も避ける
  - 前から来た対抗車を待ってから、路上駐車を避けて進むも成功
  - Gaussian Splattingを用いた強化学習
    - 実際に制御実験も成功
  - 難解国際会議AAAI2026に採択（上位10％の難解な論文が選ばれる？）
## SB Intuitionsさん
- Master
- 直感を知性へ
- ソフトバンクのグループ会社で国産LLMを開発
- Sarashina：扇マーク。日本語データセットでフルスクラッチで作っている
- 10000機GPUを持っていて、古い資料なので、もう少し増えているかも
- 東京（フルリモート可）
- 社会人ドクター制度があります
## PolarisAIさん
- 松尾研のAI講座作成を担当
- アニメ見尽したので、オススメ教えて下さい
- Kaggle制度を制定しました
  - 入社時の最低年収保証：マスター：1000万円～。グランドマスター：1500万円～
  - 活動補助
- 生成AI（LLM）を用いた回路図の作成を自動化
- 産業用ロボットの自動化
- 副業も募集中
## Panta Rheiさん
- AIを作成したり、AIが動くための基盤を作っている
- 6期目を迎えました
- 最初は企業検索【中小企業、決算情報少ない問題】
  - 「その他」が無い、業種検索
  - Googleから35万ドル分AIスタートアップでもらって、使い倒す
- 2025年から上記検索技術を他社導入に協力
## Elithさん
- 機械学初心者から2か月でKaggle masterになった経験あり
- AIセーフティプラットフォーム
  - APIを繋ぐだけで、危険性をダッシュボードで分かる
- 4期目で、海外展開戦略あり（アジア中心・並行してアメリカも）
- atomaCupが2週間後くらいにやります
  - 参加者同士で「攻撃」・「防御」で対決
## BMLさん
- AIとデータで臨床試験を変える
- ソニー株⇒㈱ビー・エム・エルに転職2025年
- 現役、Kaggler
- 採決された血液は、臨床検査に多く回される
- 4000種を超える多様な検査項目を実施
- 前処理：標本作成⇒検査：目視・自動⇒３：報告書
- 年間で数億件のデータが集まる
- 優秀な検査技師等がいて、素晴らしいアノテーション
- 病理判定工程へAI導入
- 報告書の誤字脱字チェック
- 本社：東京
- ハイブリッドワーク：週3日程度
- 医療xAIx社会実装
## Sakana AIさん
- 国内最速ユニコーンに
- モデルを大きく・データを大きく・学習を長く・他にも何かできないかがコンセプトのロゴ
- 2025年より事業開発本部を立ち上げ、実用応用
  - 企業向けパートナーシップを結ぶ
  - 実際の業務：社内にドメインエキスパートがいて、エンジニアの成果物に対して逐次フィードバックし、毎日改善をかける
  - リサーチャーとのコラボ：世界各国のトップリサーチャーと話せる
